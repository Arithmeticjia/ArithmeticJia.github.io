<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2020-2.14周报-单沙嘉</title>
    <url>/2020/02/13/2020-2-14%E5%91%A8%E6%8A%A5-%E5%8D%95%E6%B2%99%E5%98%89/</url>
    <content><![CDATA[<p>DA-RNN + Transformer<br><a id="more"></a></p>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p><img src="https://www.guanacossj.com/media/articlebodypics/multi_head_net.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/transf-67-1.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/transf-67-2.jpg" alt=""></p>
<h3 id="DA-RNN"><a href="#DA-RNN" class="headerlink" title="DA-RNN"></a>DA-RNN</h3><p><img src="https://www.guanacossj.com/media/articlebodypics/da-rnn-67-1.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/da-rnn-67-2.jpg" alt=""></p>
]]></content>
      <categories>
        <category>周报</category>
      </categories>
  </entry>
  <entry>
    <title>2020-1-17周报-单沙嘉</title>
    <url>/2020/01/17/2020-1-17%E5%91%A8%E6%8A%A5-%E5%8D%95%E6%B2%99%E5%98%89/</url>
    <content><![CDATA[<p>Django+uwsgi+Nginx<br><a id="more"></a></p>
<h3 id="WSGI"><a href="#WSGI" class="headerlink" title="WSGI"></a>WSGI</h3><p>WSGI Web Server Gateway Interface</p>
<p><img src="https://pic1.zhimg.com/80/v2-6c4572c783816364f2569af961814430_hd.jpg" alt=""></p>
<p>WSGI是一种通信协议，WSGI 不是框架，也不是一个模块，而是介于 Web应用程序（Web框架）与 Web Server 之间交互的一种规范。</p>
<h3 id="uwsgi"><a href="#uwsgi" class="headerlink" title="uwsgi"></a>uwsgi</h3><ul>
<li>二进制协议，可以携带任何类型的数据。一个uwsgi分组的头4个字节描述了这个分组包含的数据类型。</li>
<li>uwsgi是一种线路协议而不是通信协议，在此常用于在uWSGI服务器与其他网络服务器的数据通信。</li>
</ul>
<h3 id="uWSGI"><a href="#uWSGI" class="headerlink" title="uWSGI"></a>uWSGI</h3><p>uWSGI是实现了uwsgi和WSGI两种协议的Web服务器，使用c语言开发。</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">pip <span class="keyword">install</span> uwsgi</span><br></pre></td></tr></table></figure>
<ul>
<li>两级结构 在这种结构里，uWSGI作为服务器，它用到了HTTP协议以及wsgi协议，flask应用作为application，实现了wsgi协议。当有客户端发来请求，uWSGI接受请求，调用flask app得到相应，之后相应给客户端。 这里说一点，通常来说，Flask等web框架会自己附带一个wsgi服务器(这就是flask应用可以直接启动的原因)，但是这只是在开发阶段用到的，在生产环境是不够用的，所以用到了uwsgi这个性能高的wsgi服务器。</li>
<li>三级结构 在这种结构里，uWSGI作为中间件，它用到了uwsgi协议(与nginx通信)，wsgi协议(调用Flask app)。</li>
<li>提高web server性能(uWSGI处理静态资源不如nginx；nginx会在收到一个完整的http请求后再转发给wWSGI)。</li>
<li>nginx可以做负载均衡(前提是有多个服务器)，保护了实际的web服务器(客户端是和nginx交互而不是uWSGI)。</li>
</ul>
<h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="builtin-name">get</span> install nginx</span><br></pre></td></tr></table></figure>
<p>Nginx是一款轻量级的Web服务器、反向代理服务器，由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。</p>
<p><img src="https://pic2.zhimg.com/80/v2-4787a512240b238ebf928cd0651e1d99_hd.jpg" alt=""></p>
<h3 id="Django-uWSGI-Nginx"><a href="#Django-uWSGI-Nginx" class="headerlink" title="Django + uWSGI + Nginx"></a>Django + uWSGI + Nginx</h3><p><img src="https://img-blog.csdnimg.cn/20181216174304355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5bWFpc3ls,size_16,color_FFFFFF,t_70" alt=""></p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">user</span> www-data;</span><br><span class="line"><span class="attribute">worker_processes</span> auto;</span><br><span class="line"><span class="attribute">pid</span> /run/nginx.pid;</span><br><span class="line"><span class="attribute">include</span> /etc/nginx/modules-enabled/<span class="regexp">*.conf</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">	<span class="attribute">worker_connections</span> <span class="number">768</span>;</span><br><span class="line">	<span class="comment"># multi_accept on;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># Basic Settings</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line"></span><br><span class="line">	<span class="section">server</span> &#123;   		<span class="comment"># 这个server标识我要配置了</span></span><br><span class="line">		<span class="attribute">listen</span> <span class="number">80</span>;  <span class="comment"># 我要监听那个端口</span></span><br><span class="line">		<span class="attribute">server_name</span> <span class="number">118.25.79.249</span> ;  <span class="comment"># 你访问的路径前面的url名称</span></span><br><span class="line">		<span class="attribute">charset</span>  utf-<span class="number">8</span>; <span class="comment"># Nginx编码</span></span><br><span class="line">		<span class="attribute">gzip</span> <span class="literal">on</span>;  <span class="comment"># 启用压缩,这个的作用就是给用户一个网页,比如3M压缩后1M这样传输速度就会提高很多</span></span><br><span class="line">		<span class="attribute">gzip_types</span> text/plain application/x-javascript text/css text/javascript application/x-httpd-php application/json text/json image/jpeg image/gif image/png application/octet-stream;  <span class="comment"># 支持压缩的类型</span></span><br><span class="line"></span><br><span class="line">		<span class="attribute">error_page</span>  <span class="number">404</span>           		/<span class="number">404</span>.html;  <span class="comment"># 错误页面</span></span><br><span class="line">		<span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;  <span class="comment"># 错误页面</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># 指定项目路径uwsgi</span></span><br><span class="line">		<span class="attribute">location</span> / &#123;        <span class="comment"># 这个location就和咱们Django的url(r'^admin/', admin.site.urls),</span></span><br><span class="line">			<span class="attribute">include</span> uwsgi_params;  <span class="comment"># 导入一个Nginx模块他是用来和uWSGI进行通讯的</span></span><br><span class="line">			<span class="attribute">uwsgi_connect_timeout</span> <span class="number">30</span>;  <span class="comment"># 设置连接uWSGI超时时间</span></span><br><span class="line">			<span class="attribute">uwsgi_pass</span>  <span class="number">127.0.0.1:8000</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 指定静态文件路径</span></span><br><span class="line">		<span class="attribute">location</span> /static/ &#123;</span><br><span class="line">			<span class="attribute">alias</span>  /home/mysite/static/;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="attribute">sendfile</span> <span class="literal">on</span>;</span><br><span class="line">	<span class="attribute">tcp_nopush</span> <span class="literal">on</span>;</span><br><span class="line">	<span class="attribute">tcp_nodelay</span> <span class="literal">on</span>;</span><br><span class="line">	<span class="attribute">keepalive_timeout</span> <span class="number">65</span>;</span><br><span class="line">	<span class="attribute">types_hash_max_size</span> <span class="number">2048</span>;</span><br><span class="line">	<span class="comment"># server_tokens off;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># server_names_hash_bucket_size 64;</span></span><br><span class="line">	<span class="comment"># server_name_in_redirect off;</span></span><br><span class="line"></span><br><span class="line">	<span class="attribute">include</span> /etc/nginx/mime.types;</span><br><span class="line">	<span class="attribute">default_type</span> application/octet-stream;</span><br><span class="line"></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># SSL Settings</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line"></span><br><span class="line">	<span class="attribute">ssl_protocols</span> TLSv1 TLSv1.<span class="number">1</span> TLSv1.<span class="number">2</span>; <span class="comment"># Dropping SSLv3, ref: POODLE</span></span><br><span class="line">	<span class="attribute">ssl_prefer_server_ciphers</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># Logging Settings</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line"></span><br><span class="line">	<span class="attribute">access_log</span> /var/log/nginx/access.log;</span><br><span class="line">	<span class="attribute">error_log</span> /var/log/nginx/error.log;</span><br><span class="line"></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># Gzip Settings</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line"></span><br><span class="line">	<span class="attribute">gzip</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment"># gzip_vary on;</span></span><br><span class="line">	<span class="comment"># gzip_proxied any;</span></span><br><span class="line">	<span class="comment"># gzip_comp_level 6;</span></span><br><span class="line">	<span class="comment"># gzip_buffers 16 8k;</span></span><br><span class="line">	<span class="comment"># gzip_http_version 1.1;</span></span><br><span class="line">	<span class="comment"># gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># Virtual Host Configs</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line"></span><br><span class="line">	<span class="attribute">include</span> /etc/nginx/conf.d/<span class="regexp">*.conf</span>;</span><br><span class="line">	<span class="attribute">include</span> /etc/nginx/sites-enabled/*;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#mail &#123;</span></span><br><span class="line"><span class="comment">#	# See sample authentication script at:</span></span><br><span class="line"><span class="comment">#	# http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#	# auth_http localhost/auth.php;</span></span><br><span class="line"><span class="comment">#	# pop3_capabilities "TOP" "USER";</span></span><br><span class="line"><span class="comment">#	# imap_capabilities "IMAP4rev1" "UIDPLUS";</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#	server &#123;</span></span><br><span class="line"><span class="comment">#		listen     localhost:110;</span></span><br><span class="line"><span class="comment">#		protocol   pop3;</span></span><br><span class="line"><span class="comment">#		proxy      on;</span></span><br><span class="line"><span class="comment">#	&#125;</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#	server &#123;</span></span><br><span class="line"><span class="comment">#		listen     localhost:143;</span></span><br><span class="line"><span class="comment">#		protocol   imap;</span></span><br><span class="line"><span class="comment">#		proxy      on;</span></span><br><span class="line"><span class="comment">#	&#125;</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">[uwsgi] </span><br><span class="line">chdir = /home/mysite</span><br><span class="line">module = mysite.wsgi:application</span><br><span class="line">socket = 127.0.0.1:8000</span><br><span class="line">master = true </span><br><span class="line">processes = 1</span><br><span class="line">threads = 2</span><br><span class="line">max-requests = 6000</span><br><span class="line">chmod-socket = 666</span><br><span class="line">buffer-size = 65535</span><br><span class="line">logto = /var/log/mysite.log</span><br><span class="line">async</span><br><span class="line">ugreen =''</span><br><span class="line">http-timeout = 300</span><br><span class="line"><span class="comment">#plugins=python</span></span><br></pre></td></tr></table></figure>
<h3 id="Activemq"><a href="#Activemq" class="headerlink" title="Activemq"></a>Activemq</h3><p>ActiveMQ 是 Apache 出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持 JMS1.1 和 J2EE 1.4 规范的 JMS Provider 实现。</p>
<h4 id="queue"><a href="#queue" class="headerlink" title="queue"></a>queue</h4><p><img src="https://pic4.zhimg.com/80/v2-b7edcfa850af9627bed67ef9e89f8d3f_hd.jpg" alt=""></p>
<h4 id="topic"><a href="#topic" class="headerlink" title="topic"></a>topic</h4><p><img src="https://pic2.zhimg.com/80/v2-b1874d392a6119fb4e497425dcc58609_hd.jpg" alt=""></p>
]]></content>
      <categories>
        <category>周报</category>
      </categories>
  </entry>
  <entry>
    <title>2020-1-10周报-单沙嘉</title>
    <url>/2020/01/07/2020-1-10%E5%91%A8%E6%8A%A5-%E5%8D%95%E6%B2%99%E5%98%89/</url>
    <content><![CDATA[<p>“All you need is attention”<br><a id="more"></a></p>
<h3 id="LSTM-Attention"><a href="#LSTM-Attention" class="headerlink" title="LSTM + Attention"></a>LSTM + Attention</h3><p>FEED-FORWARD NETWORKS WITH ATTENTION CAN SOLVE SOME LONG-TERM MEMORY PROBLEMS</p>
<h4 id="FEED-FORWARD-ATTENTION"><a href="#FEED-FORWARD-ATTENTION" class="headerlink" title="FEED-FORWARD ATTENTION"></a>FEED-FORWARD ATTENTION</h4><p><img src="https://www.guanacossj.com/media/articlebodypics/FEED-FORWARD-ATTENTION.jpg" alt=""></p>
<script type="math/tex; mode=display">e_{t} = a(h_{t})</script><script type="math/tex; mode=display">\alpha_{t} = \frac{exp(e_{t})}{\sum_{k=1}^{T}exp(e_{k})}</script><script type="math/tex; mode=display">c = \sum_{t=1}^{T}\alpha_{t}h_{t}</script><h4 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h4><p><img src="https://www.guanacossj.com/media/articlebodypics/all-lstmattention.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/test-lstmattention.png" alt=""></p>
<h3 id="Seq2Seq-Attention"><a href="#Seq2Seq-Attention" class="headerlink" title="Seq2Seq + Attention"></a>Seq2Seq + Attention</h3><p><img src="https://www.guanacossj.com/media/articlebodypics/all-seq2seqattention.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/test-seq2seqattention.png" alt=""></p>
<h3 id="DA-RNN"><a href="#DA-RNN" class="headerlink" title="DA-RNN"></a>DA-RNN</h3><p><img src="https://www.guanacossj.com/media/articlebodypics/nasdaq-gru.jpg" alt=""></p>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><h4 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h4><p>顾名思义，指的不是Target和Source之间的Attention机制，而是Source内部元素之间或者Target内部元素之间发生的Attention机制，也可以理解为Target=Source这种特殊情况下的注意力计算机制</p>
<p>给出信息输入：用X = [x1, · · · , xN ]表示N 个输入信息；通过线性变换得到为查询向量序列，键向量序列和值向量序列，其中$W^{Q}$,$W^{K}$,$W^{V}$是我们模型训练过程学习到的合适的参数</p>
<script type="math/tex; mode=display">Q = W^{Q}X</script><script type="math/tex; mode=display">K = W^{K}X</script><script type="math/tex; mode=display">V = W^{V}X</script><script type="math/tex; mode=display">Attention(Q,K,V) = softmax(\begin{bmatrix}
v_{1}\\ 
v_{2}\\ 
...\\ 
v_{n}
\end{bmatrix}*[v^{T}_{1},v^{T}_{2},...,v^{T}_{n}])*\begin{bmatrix}
v_{1}\\ 
v_{2}\\ 
...\\ 
v_{n}
\end{bmatrix} = softmax(QK^{T})V</script><p><img src="https://pic2.zhimg.com/v2-07c4c02a9bdecb23d9664992f142eaa5_r.jpg" alt=""></p>
<p>Source中的构成元素想象成是由一系列的<Key,Value>数据对构成<br>Target中的某个元素Query<br>(在Seq2Se2中，Q是Decoder的隐藏态，K和V都是Encoder的隐藏态)</p>
<ul>
<li>1、根据Query和Key计算权重系数，常用的相似度函数有点积，拼接，感知机等</li>
<li>2、使用softmax函数对这些权重进行归一化</li>
<li>3、根据权重系数对Value进行加权求和得到attention</li>
</ul>
<h4 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h4><p>防止Q和K点乘积结果过大，会除以一个尺度标度 </p>
<script type="math/tex; mode=display">Attention(Q,K,V) = sofrmax(\frac{QK^{T}}{\sqrt{d_{k}}})V</script><h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><ul>
<li>$Q$，$K$，$V$首先进过一个线性变换，然后输入到放缩点积attention</li>
<li>每次$Q$，$K$，$V$进行线性变换的参数$W$是不一样的</li>
<li>通过$h$个不同的线性变换对$Q$，$K$，$V$进行投影，最后将不同的attention结果拼接起来</li>
</ul>
<script type="math/tex; mode=display">Multihead(Q,K,V) = Concat(head_{1},...,head_{h})W^{O}</script><script type="math/tex; mode=display">head_{i} = Attention(QW^{Q}_{i},KW^{K}_{i},VW^{V}_{i})</script><h4 id="Experiment-1"><a href="#Experiment-1" class="headerlink" title="Experiment"></a>Experiment</h4><p><img src="https://www.guanacossj.com/media/articlebodypics/all-transformer.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/test-transformer.png" alt=""></p>
]]></content>
      <categories>
        <category>周报</category>
      </categories>
  </entry>
  <entry>
    <title>说说LSTM</title>
    <url>/2019/12/29/%E8%AF%B4%E8%AF%B4LSTM/</url>
    <content><![CDATA[<p>Long Short Term Memory<br><a id="more"></a></p>
<h4 id="从RNN开始"><a href="#从RNN开始" class="headerlink" title="从RNN开始"></a>从RNN开始</h4><p>RNN(Recurrent Neural Network)是一类用于处理序列数据的神经网络，擅长对序列数据进行建模处理。LSTM(Long Short-Term Memory) 在传统的 RNN 的基础上增加了状态$c$，称为记忆单元态 (cell state)，用以取代传统的隐含神经元节点。它负责把记忆信息从序列的初始位置，传递到序列的末端。</p>
<h4 id="LSTM的组成"><a href="#LSTM的组成" class="headerlink" title="LSTM的组成"></a>LSTM的组成</h4><p>在$t$时刻，当前神经元的输入有三个：当前时刻输入值$x_{t}$、前一时刻输出值$s_{t-1}$,和前一时刻的记忆单元状态$c_{t-1}$, 输出有两个，当前时刻LSTM的输出值$s_{t}$和当前时刻的记忆单元状态$c_{t}$。<br>LSTM通过三个门控开关传递记忆状态。</p>
]]></content>
      <categories>
        <category>LSTM</category>
      </categories>
      <tags>
        <tag>lstm</tag>
        <tag>deeplearning</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode78Pascal-Triangle-2-Java</title>
    <url>/2019/12/29/Leetcode78Pascal-Triangle-2-Java/</url>
    <content><![CDATA[<p>Java 找规律法<br><a id="more"></a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">getRow</span><span class="params">(<span class="keyword">int</span> rowIndex)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;Integer&gt;();</span><br><span class="line">        <span class="keyword">long</span> k = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(rowIndex &gt;= <span class="number">0</span>)</span><br><span class="line">            res.add(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= rowIndex + <span class="number">1</span>; i++) &#123;</span><br><span class="line">            k = k * (rowIndex + <span class="number">2</span> - i) / (i-<span class="number">1</span>);</span><br><span class="line">            res.add((<span class="keyword">int</span>)k);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这里用到了杨辉三角的规律，第n行m个数等于</p>
<p>譬如第三行第二个数</p>
<script type="math/tex; mode=display">C_{3-1}^{2-1} = C_{2}^{1} = 2</script><p>譬如第四行第三个数</p>
<script type="math/tex; mode=display">C_{4-1}^{3-1} = C_{3}^{2} = 3</script><p>那这个对我们的算法有啥帮助呢？</p>
<p>举个栗子，看第四行</p>
<p>应该是1 3 3 1</p>
<p>在本题中是1 4 6 4 1</p>
<p>$C_{5-1}^{1-1} = C_{4}^{0} = 1$，$C_{5-1}^{2-1} = C_{4}^{1} = 4$，$C_{5-1}^{3-1} = C_{4}^{2} = 6$，$C_{5-1}^{4-1} = C_{4}^{3} = 4$，$C_{5-1}^{5-1} = C_{4}^{4} = 1$</p>
<p>找规律如下：</p>
<p>第一个数：<script type="math/tex">C_{5-1}^{1-1} = C_{4}^{0} = 1</script></p>
<p>第二个数：<script type="math/tex">C_{5-1}^{2-1} = C_{4}^{1} = C_{5-1}^{1-1} * \frac{(rowIndex-2+2)}{2-1}</script></p>
<p>第n行m个数：第m-1个数 × $ \frac{(rowIndex-m+2)}{m-1} $，第n行第一个数永远是1</p>
<p>晚安~~~</p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode[78]Pascal&#39;s Triangle II</title>
    <url>/2019/12/28/Leetcode78Pascal-Triangle-2/</url>
    <content><![CDATA[<p>python3 最优雅解法<br><a id="more"></a><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getRow</span><span class="params">(self, rowIndex)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type rowIndex: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = [<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, rowIndex + <span class="number">1</span>):</span><br><span class="line">            res.insert(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="comment"># j循环每次算出r[0]...r[j-1]，再加上最后一个永远存在的1，正好是rowIndex+1个数</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i):</span><br><span class="line">                res[j] = res[j] + res[j + <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>2019-12-27周报-单沙嘉</title>
    <url>/2019/12/27/2019-12-27%E5%91%A8%E6%8A%A5-%E5%8D%95%E6%B2%99%E5%98%89/</url>
    <content><![CDATA[<p>RNN -&gt; LSTM -&gt; GRU -&gt; Seq2Seq -&gt; Attention -&gt; Transformer<br><a id="more"></a></p>
<h3 id="Encoder-Decoder-Seq2Seq"><a href="#Encoder-Decoder-Seq2Seq" class="headerlink" title="Encoder-Decoder(Seq2Seq)"></a>Encoder-Decoder(Seq2Seq)</h3><p><img src="https://pic4.zhimg.com/80/v2-77e8a977fc3d43bec8b05633dc52ff9f_hd.jpg" alt=""></p>
<ul>
<li>Encoder-Decoder结构先将输入数据编码成一个上下文向量$c$</li>
<li>把Encoder的最后一个隐状态赋值给$c$,还可以对最后的隐状态做一个变换得到$c$，也可以对所有的隐状态做变换</li>
<li>拿到c之后，就用另一个RNN网络对其进行解码(Decoder),将c当做之前的初始状态$h_{0}$输入到Decoder中</li>
<li>还有一种做法是将$c$当做每一步的输入</li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-e0fbb46d897400a384873fc100c442db_hd.jpg" alt=""></p>
<h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><ul>
<li>在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征$c$再解码，因此，$c$中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈</li>
<li>Attention机制通过在每个时间输入不同的$c$来解决这个问题</li>
</ul>
<p><img src="https://www.guanacossj.com/media/articlebodypics/v2-8da16d429d33b0f2705e47af98e66579_hd_gaitubao_525x551_gaitubao_345x362.jpg" alt=""></p>
<ul>
<li>每一个$c$会自动去选取与当前所要输出的$y$最合适的上下文信息。具体来说，我们用$\alpha_{ij}$衡量Encoder中第$j$阶段的$h_{j}$和解码时第$i$阶段的相关性，最终Decoder中第$i$阶段的输入的上下文信息$c_{i}$就来自于所有$h_{j}$对$\alpha_{ij}$的加权和。</li>
<li>$\alpha_{ij}$和Decoder的第$i$阶段的隐藏状态、Encoder第$j$个阶段的隐藏状态有关</li>
<li>在Encoder的过程中保留每个RNN单元的隐藏状态(hidden state)得到($h_{1}$…$h_{N}$)，取$h_{j}$，表示Encoder层的隐层第$j$时刻的输出</li>
<li>在Decoder的过程中根据$x_{i}$和$h’_{i-1}$(这里和Encoder的$h_{i}$区分一下)得到$h’_{i}$，设为$s_{i}$</li>
<li>注：最开始的论文在Encoder-Decoder里面的当前Decoder的attention得分用的是$s_{i-1}$和$h_{j}$来算，但斯坦福教材上图上确实是画的$s_{i}$和$h_{j}$来算，而且后续论文大多是用的这种方式，即当前步的attention score用的当前步的隐藏状态$s_{i}$和前面的$h_{j}$去算的</li>
<li>通过Decoder的hidden states加上Encoder的hidden states来计算一个分数，用于计算权重<script type="math/tex; mode=display">e_{ij} = score(s_{i},h_{j})</script></li>
<li>注：这里有很多计算方式<script type="math/tex; mode=display">score(s_{i},h_{j}) = \left\{\begin{matrix}
s^{T}_{i}h_{j}\\ 
s^{T}_{i}W_{a}h_{j}\\ 
v^{T}_{a}tanh(W_{a}[s^{T}_{i};h_{j}])
\end{matrix}\right.</script></li>
<li>softmax权重归一化<script type="math/tex; mode=display">\alpha_{ij} = \frac{exp(e_{ij})}{\sum_{k=1}^{T_{x}}exp(e_{ik})}</script></li>
<li>计算$c$<script type="math/tex; mode=display">c_{i} = \sum_{j=1}^{T_{x}}\alpha_{ij}h_{j}</script></li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-8ddf993a95ee6e525fe2cd5ccd49bba7_hd.jpg" alt=""></p>
<p>(1)$h_{t} = RNN_{enc}(x_{t},h_{t-1})$, Encoder方面接受的是每一个单词word embedding，和上一个时间点的hidden state。输出的是这个时间点的hidden state。</p>
<p>(2)$s_{t} = RNN_{dnc}(y_{t},s_{t-1})$, Decoder方面接受的是目标句子里单词的word embedding，和上一个时间点的hidden state。</p>
<p>(3)$c_{i} = \sum_{j=1}^{T_{x}}\alpha _{ij}h_{j}$, context vector是一个对于encoder输出的hidden states的一个加权平均。</p>
<p>(4)$\alpha_{ij} = \frac{exp(e_{ij})}{\sum_{k=1}^{T_{x}}exp(e_{ik})}$, 每一个encoder的hidden states对应的权重。</p>
<p>(5)$e_{ij} = score(s_{i},h_{j})$, 通过decoder的hidden states加上encoder的hidden states来计算一个分数，用于计算权重(4)</p>
<p>(6)$\hat{s}_{t}=tanh(W_{c}[c_{t};s_{t}])$, 将context vector 和 decoder的hidden states 串起来。</p>
<p>(7)$p(y_{t}|y_{&lt;t},x) = softmax(W_{s}\hat{s}_{t})$, 计算最后的输出概率。</p>
<h3 id="Transformer—-Attention-Is-All-You-Need"><a href="#Transformer—-Attention-Is-All-You-Need" class="headerlink" title="Transformer—-Attention Is All You Need"></a>Transformer—-Attention Is All You Need</h3><p><img src="https://pic1.zhimg.com/80/v2-4b53b731a961ee467928619d14a5fd44_hd.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/v2-4b53b731a961ee467928619d14a5fd44_r.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/4155986-208004e73fb93c97.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/4155986-e7fd5fcf3acc00a3.png" alt=""></p>
<ul>
<li>Transformer 的 Encoder 由 6 个编码器叠加组成，Decoder 也由 6 个解码器组成，在结构上都是相同的，但它们不共享权重。</li>
<li>Encoder的每一层有两个操作，分别是Self-Attention和Feed Forward；</li>
<li>Decoder的每一层有三个操作，分别是Self-Attention、Encoder-Decoder Attention以及Feed Forward操作。</li>
<li>这里的Self-Attention和Encoder-Decoder Attention都是用的是Multi-Head Attention机制</li>
</ul>
<p><img src="https://www.guanacossj.com/media/articlebodypics/v2-df2ca1b7a60d829245b7b7c37f80a3aa_r.jpg" alt=""></p>
<h4 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self Attention"></a>Self Attention</h4><ul>
<li>RNN的循环特性导致其不利于并行计算，模型训练时间较长</li>
<li>在传统的seq2seq中，我们通过RNN获取hidden state去做attention，那么当我们完全抛弃RNN的时候，怎么去做attention呢？</li>
<li>对每个input做embedding，代替hidden state，embedding通过三个不同的线性层生成$Q$，$K$，$V$。</li>
<li>Q: query;K: key; V: value</li>
<li>K = V = Q</li>
</ul>
<script type="math/tex; mode=display">Q = W_{Q}X</script><script type="math/tex; mode=display">K = W_{K}X</script><script type="math/tex; mode=display">V = W_{V}X</script><script type="math/tex; mode=display">Attention(Q,K,V) = softmax(\begin{bmatrix}
v_{1}\\ 
v_{2}\\ 
...\\ 
v_{n}
\end{bmatrix}*[v^{T}_{1},v^{T}_{2},...,v^{T}_{n}])*\begin{bmatrix}
v_{1}\\ 
v_{2}\\ 
...\\ 
v_{n}
\end{bmatrix} = softmax(QK^{T})V</script><p>举个栗子</p>
<p><img src="https://pic1.zhimg.com/80/v2-087b831f622f83e4529c1bbf646530f0_hd.jpg" alt=""></p>
<ul>
<li>假如我们要翻译一个词组Thinking Machines，其中Thinking的输入的embedding vector用$x_{1}$表示，Machines的embedding vector用$x_{2}$表示</li>
<li>$W^{Q}$，$W^{K}$，$W^{V}$是我们模型训练过程学习到的合适的参数</li>
<li>$x$与$W^{Q}$，$W^{K}$，$W^{V}$相乘获得$q$，$k$，$v$</li>
<li>如上图中所示我们分别得到了$q_{1}$与$k_{1}$，$k_{2}$的点乘积，然后我们进行尺度缩放与softmax归一化</li>
</ul>
<h4 id="Scaled-Dot-Product-Attention-缩放了的点乘注意力"><a href="#Scaled-Dot-Product-Attention-缩放了的点乘注意力" class="headerlink" title="Scaled Dot-Product Attention(缩放了的点乘注意力)"></a>Scaled Dot-Product Attention(缩放了的点乘注意力)</h4><script type="math/tex; mode=display">Attention(Q,K,V) = sofrmax(\frac{QK^{T}}{\sqrt{d_{k}}})V</script><ul>
<li>输入包含$d_{k}$维的query和key，以及$d_{v}$维的value。通过计算query和各个key的点积，除以$\sqrt{d_{k}}$归一化，然后经过softmax激活变成权重，最后再乘value。点积注意力机制的优点是速度快、占用空间小。</li>
</ul>
<h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><ul>
<li>$Q$，$K$，$V$首先进过一个线性变换，然后输入到放缩点积attention</li>
<li>每次$Q$，$K$，$V$进行线性变换的参数$W$是不一样的</li>
<li>通过$h$个不同的线性变换对$Q$，$K$，$V$进行投影，最后将不同的attention结果拼接起来</li>
</ul>
<script type="math/tex; mode=display">Multihead(Q,K,V) = Concat(head_{1},...,head_{h})W^{O}</script><script type="math/tex; mode=display">head_{i} = Attention(QW^{Q}_{i},KW^{K}_{i},VW^{V}_{i})</script><h4 id="Position-wise-feed-forward-networks-位置全链接前馈网络"><a href="#Position-wise-feed-forward-networks-位置全链接前馈网络" class="headerlink" title="Position-wise feed-forward networks(位置全链接前馈网络)"></a>Position-wise feed-forward networks(位置全链接前馈网络)</h4><ul>
<li>由两个线性变换（Wx+b）和一个ReLU（relu的数学表达式就是f(x)=max(0,x)）<script type="math/tex; mode=display">FFN(x) = max(0,xW_{1} + b_{1})W_{2} + b_{2}</script></li>
</ul>
<h4 id="Positional-Encoding-位置编码"><a href="#Positional-Encoding-位置编码" class="headerlink" title="Positional Encoding(位置编码)"></a>Positional Encoding(位置编码)</h4><h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">1115<span class="string">-1120</span> after data smoothing</span><br><span class="line">T = 10</span><br><span class="line">features = 70</span><br><span class="line">train = all * 0.7</span><br><span class="line"><span class="keyword">test </span>= all * 0.3</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/da-rnn-1115-1120-all.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/da-rnn-1115-1120-test-m.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/da-rnn-1115-1120-test.jpg" alt=""></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 3.955</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.289</span><br></pre></td></tr></table></figure>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">nasdaq100_padding</span><br><span class="line">T = 10</span><br><span class="line">features = 81</span><br><span class="line">train = all * 0.7</span><br><span class="line"><span class="keyword">test </span>= all * 0.3</span><br></pre></td></tr></table></figure>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Encoder:</span> LSTM</span><br><span class="line"><span class="symbol">Decoder:</span> LSTM</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/nasdaq-lstm.jpg" alt=""><br><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 0.579</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.105</span><br></pre></td></tr></table></figure></p>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Encoder:</span> BiLSTM</span><br><span class="line"><span class="symbol">Decoder:</span> LSTM</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/nasdaq-bi-lstm.jpg" alt=""><br><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 0.384</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.069</span><br></pre></td></tr></table></figure></p>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Encoder:</span> GRU</span><br><span class="line"><span class="symbol">Decoder:</span> LSTM</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/nasdaq-gru.jpg" alt=""><br><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 0.252</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.046</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>周报</category>
      </categories>
  </entry>
  <entry>
    <title>Leetcode38Count-and-Say</title>
    <url>/2019/12/24/Leetcode38Count-and-Say/</url>
    <content><![CDATA[<p>Nothing<br><a id="more"></a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">countAndSay</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"1"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        String str = countAndSay(n-<span class="number">1</span>) + <span class="string">"*"</span>;<span class="comment">// 这样末尾的数才能被循环处理到</span></span><br><span class="line">        <span class="keyword">char</span>[] str_c = str.toCharArray();</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">        StringBuilder temp = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt; str_c.length-<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span>(str_c[i] == str_c[i+<span class="number">1</span>])&#123;</span><br><span class="line">                count++;  <span class="comment">//遇到相同的计数器加</span></span><br><span class="line">                i++;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                temp.append(Integer.toString(count)+ str_c[i]);</span><br><span class="line">                <span class="comment">// 遇到不同的，先append计数器的值，再append最后一个相同的值</span></span><br><span class="line">                <span class="comment">// temp.append("" + count + str_c[i]);</span></span><br><span class="line">                count = <span class="number">1</span>;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> temp.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Seq2seq模型及注意力机制模型</title>
    <url>/2019/12/22/Seq2seq%E6%A8%A1%E5%9E%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>对于处理输出序列为不定长情况的问题，例如机器翻译，例如英文到法语的句子翻译，输入和输出均为不定长。前人提出了seq2seq模型，basic idea是设计一个encoder与decoder，其中encoder将输入序列编码为一个包含输入序列所有信息的context vector $ c $，decoder通过对$ c $的解码获得输入序列的信息，从而得到输出序列。encoder及decoder都通常为RNN循环神经网络<br><a id="more"></a></p>
<h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><ul>
<li>input: 当前时刻输入值$x_{t}$,上一时刻LSTM的输出值$h_{t-1}$,上一时刻的单元状态$c_{t-1}$</li>
<li>output: 当前时刻LSTM的输出值$h_{t}$,当前时刻的单元状$c_{t}$</li>
<li>forget gate:</li>
</ul>
<script type="math/tex; mode=display">f_{t} = \sigma (W_{f}[h_{t-1};x_{t}]+b_{f})</script><p>$W_{f}$是遗忘门的权重矩阵，$[h_{t-1};x_{t}]$表示把两个向量连接成一个更长的向量，$b_{f}$是遗忘门的偏置项，$\sigma$是sigmoid函数<br>如果输入的维度是$d_{x}$，隐藏层的维度是$d_{h}$，单元状态的维度是$d_{c}$（通常$d_{c} = d_{h}$），则遗忘门的权重矩阵$W_{f}$的维度是$d_{c}×(d_{h}+d_{x})$</p>
<ul>
<li><p>input gate:</p>
<script type="math/tex; mode=display">i_{t} = \sigma (W_{i}[h_{t-1};x_{t}]+b_{i})</script></li>
<li><p>output gate:</p>
<script type="math/tex; mode=display">o_{t} = \sigma (W_{o}[h_{t-1};x_{t}]+b_{o})</script></li>
<li><p>final out:</p>
<script type="math/tex; mode=display">\tilde{c}_{t}= tanh(W_{c}[h_{t-1};x_{t}]+b_{c})</script><script type="math/tex; mode=display">c_{t} = f_{t} * c_{t-1} + i_{t} * \tilde{c}_{t}</script><script type="math/tex; mode=display">h_{t} = o_{t} * tanh(c_{t})</script></li>
<li><p>前向计算每个神经元的输出值，对于LSTM来说就是$f_{t}$,$i_{t}$,$c_{t}$,$o_{t}$,$h_{t}$ 5个向量的值</p>
</li>
<li>反向计算每个神经元的误差项$\delta$，包括两个方向，一是沿时间的反向传播，即从当前t时刻开始，计算每个时刻的误差项；另一个是将误差项向上一层传播</li>
<li>根据相应的误差项，计算每个权重的梯度</li>
<li>sigmoid</li>
</ul>
<script type="math/tex; mode=display">\delta (x) = \frac{1}{1+e^{-x}}</script><script type="math/tex; mode=display">\delta^{'} (x) = \frac{e^{-x}}{(1+e^{-x})^{2}}=\delta(x)(1-\delta(x))</script><ul>
<li>tanh</li>
</ul>
<script type="math/tex; mode=display">tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}</script><script type="math/tex; mode=display">tanh^{'}(x) = 1 - tanh^{2}(x)</script><p>LSTM需要学习的参数共有8组，分别是：</p>
<ul>
<li>遗忘门的权重矩阵$W_{f}$和偏置项$b_{f}$</li>
<li>输入门的权重矩阵$W_{i}$和偏置项$b_{i}$</li>
<li>输出门的权重矩阵$W_{o}$和偏置项$b_{o}$</li>
<li>计算单元状态的权重矩阵$W_{c}$和偏置项$b_{c}$</li>
</ul>
<h4 id="seq2seq模型"><a href="#seq2seq模型" class="headerlink" title="seq2seq模型"></a>seq2seq模型</h4><h5 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h5><p>编码器的作用是把一个不定长的输入序列$ x_{1},x_{2},…,x_{T} $转化成一个定长的context vector $c$. 该context vector编码了输入序列$ x_{1},x_{2},…,x_{T} $的序列。回忆一下循环神经网络，假设该循环神经网络单元为$f$（可以为vanilla RNN, LSTM, GRU)，那么hidden state为</p>
<script type="math/tex; mode=display">h_{t} = f(x_{t},h_{t-1})</script><p>编码器的context vector是所有时刻hidden state的函数，即：</p>
<script type="math/tex; mode=display">c=q(h_{1},...,h_{T})</script><p>简单地，我们可以把最终时刻的hidden state[公式]作为context vecter。当然我们也可以取各个时刻hidden states的平均，以及其他方法。</p>
<h5 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h5><p>编码器最终输出一个context vector $c$，该context vector编码了输入序列$ x_{1},x_{2},…,x_{T} $的信息。</p>
<p>假设训练数据中的输出序列为$y_{1}y_{2},…,y_{T}^{‘}$,我们希望每个$t$时刻的输出即取决于之前的输出也取决于context vector，即估计$P(y_{t’}|y_{1},…,y_{t’-1},c)$，从而得到输出序列的联合概率分布：</p>
<script type="math/tex; mode=display">P(y_{1},...,y_{T'})=\prod_{t'-1}^{T'}P(y_{t'}|y_{1},...,y_{t'-1},c)</script><p>并定义该序列的损失函数loss function</p>
<script type="math/tex; mode=display">-\log P(y_{1},...,y_{T'})</script><p>通过最小化损失函数来训练seq2seq模型。</p>
<p>那么如何估计$ P(y_{t’}|y_{1},…,y_{t’-1},c) $？</p>
<p>我们使用另一个循环神经网络作为解码器。解码器使用函数$p$来表示$t’$时刻输出$y_{t’}$的概率</p>
<script type="math/tex; mode=display">P(y_{t'}|y_{1},...,y_{t'-1},c) = p(y_{t'-1},s_{t'},c)</script><p>为了区分编码器中的hidden state[公式]，其中[公式]为[公式]时刻解码器的hidden state。区别于编码器，解码器中的循环神经网络的输入除了前一个时刻的输出序列[公式]，和前一个时刻的hidden state[公式]以外，还包含了context vector[公式]。即：</p>
<script type="math/tex; mode=display">s_{t'} = g(y_{t'-1},s_{t'-1},c)</script><p>其中函数g为解码器的循环神经网络单元。</p>
<h4 id="DA-RNN"><a href="#DA-RNN" class="headerlink" title="DA-RNN"></a>DA-RNN</h4><h5 id="第一阶段，使用注意力机制自适应地提取每个时刻的相关feature"><a href="#第一阶段，使用注意力机制自适应地提取每个时刻的相关feature" class="headerlink" title="第一阶段，使用注意力机制自适应地提取每个时刻的相关feature"></a>第一阶段，使用注意力机制自适应地提取每个时刻的相关feature</h5><script type="math/tex; mode=display">e_{t}^{k}=v_{e}^{T}tanh(W_{e}[h_{t-1};c_{t-1}]+U_{e}x^{k})</script><ul>
<li>用softmax函数将其归一化<script type="math/tex; mode=display">\alpha _{t}^{k}=\frac{exp(e_{t}^{k})}{\sum_{i-1}^{n}exp(e_{t}^{i})}</script></li>
<li>得到更新后的x<script type="math/tex; mode=display">\tilde{x} = (\alpha _{t}^{1}x_{t}^{1}, \alpha _{t}^{2}x_{t}^{2},...,\alpha _{t}^{n}x_{t}^{n})</script></li>
</ul>
<p><img src="https://www.guanacossj.com/media/articlebodypics/lstm.jpg" alt=""></p>
<ul>
<li><p>选取LSTM作为编码器<script type="math/tex">f_{1}</script></p>
<script type="math/tex; mode=display">h_{t} = f_{1}(h_{t-1},  \tilde{x})</script></li>
<li><p>Encoder方面接受的是每一个输入，和上一个时间点的隐藏态。输出的是当前时间点的隐藏态</p>
</li>
</ul>
<h5 id="第二阶段，使用另一个注意力机制选取与之相关的encoder-hidden-states"><a href="#第二阶段，使用另一个注意力机制选取与之相关的encoder-hidden-states" class="headerlink" title="第二阶段，使用另一个注意力机制选取与之相关的encoder hidden states"></a>第二阶段，使用另一个注意力机制选取与之相关的encoder hidden states</h5><ul>
<li><p>Decoder方面接受的是目标输入，和上一个时间点的隐藏态</p>
</li>
<li><p>对所有时刻的$h_{t’}$取加权平均，即：</p>
</li>
</ul>
<script type="math/tex; mode=display">c_{t}^{'} = \sum_{t-1}^{T}\beta _{t^{'}}^{t}h_{t}</script><ul>
<li><script type="math/tex">\beta _{t^{'}}^{t}</script>的设计类似于Bahanau的工作，基于前一个时刻解码器的hidden state $ d_{t’-1} $和cell state$s_{t’-1}^{‘}$计算得到：</li>
</ul>
<script type="math/tex; mode=display">l_{t}^{t}=v_{d}^{T}tanh(W_{d}[d_{t-1};s_{t-1}^{'}]+U_{d}h_{t})</script><script type="math/tex; mode=display">\beta _{t}^{i}=\frac{exp(l_{t}^{i})}{\sum_{j=1}^{T}exp(l_{t}^{j})}</script><script type="math/tex; mode=display">c_{t}=\sum_{i=1}^{T}\beta _{t}^{i}h_{i}</script><ul>
<li>解码器的输入是上一个时刻的目标序列$y_{t’-1}$和hidden state$d_{t’-1}$以及context vector $c_{t’-1}$，即<script type="math/tex; mode=display">d_{t'}=f_{2}(y_{t'-1},c_{t'-1},d_{t'-1})</script></li>
<li>这里设计了$\tilde{y}_{t’-1}$来combie$y_{t’-1}$与$c_{t’-1}$的信息，即<script type="math/tex; mode=display">\tilde{y}_{t'-1} = \tilde{\omega }^{T}[y_{t'-1};c_{t'-1}]+\tilde{b}</script></li>
<li>然后<script type="math/tex; mode=display">d_{t}=f_{2}(d_{t-1},\tilde{y}_{t-1})</script></li>
</ul>
]]></content>
      <tags>
        <tag>seq2seq</tag>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title>da-rnn-bug-fix</title>
    <url>/2019/12/21/da-rnn-bug-fix/</url>
    <content><![CDATA[<p>Bugs fix for<br><a href="https://github.com/chandlerzuo/chandlerzuo.github.io/blob/master/codes/da_rnn/DA_RNN.py" target="_blank" rel="noopener" title="https://github.com/chandlerzuo/chandlerzuo.github.io/blob/master/codes/da_rnn/DA_RNN.py">https://github.com/chandlerzuo/chandlerzuo.github.io/blob/master/codes/da_rnn/DA_RNN.py</a><br><a id="more"></a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> open</span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> concatenate</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">filename = <span class="string">'nasdaq100_padding.csv'</span></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line">dataset = pd.read_csv(filename)</span><br><span class="line"><span class="comment"># print(dataset.values)</span></span><br><span class="line"></span><br><span class="line">features = dataset.values.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 82</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderAtt</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, T)</span>:</span></span><br><span class="line">        <span class="comment"># input size: number of underlying factors (81)</span></span><br><span class="line">        <span class="comment"># T: number of time steps (10)</span></span><br><span class="line">        <span class="comment"># hidden_size: dimension of the hidden state</span></span><br><span class="line">        super(EncoderAtt, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.T = T</span><br><span class="line"></span><br><span class="line">        self.lstm_layer = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=<span class="number">1</span>)</span><br><span class="line">        self.attn_linear = nn.Linear(in_features=<span class="number">2</span> * hidden_size + T - <span class="number">1</span>, out_features=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_data)</span>:</span></span><br><span class="line">        <span class="comment"># input_data: batch_size * T - 1 * input_size</span></span><br><span class="line">        input_weighted = Variable(input_data.data.new(input_data.size(<span class="number">0</span>), self.T - <span class="number">1</span>, self.input_size).zero_())</span><br><span class="line">        input_encoded = Variable(input_data.data.new(input_data.size(<span class="number">0</span>), self.T - <span class="number">1</span>, self.hidden_size).zero_())</span><br><span class="line">        <span class="comment"># hidden, cell: initial states with dimention hidden_size</span></span><br><span class="line">        hidden = self.init_hidden(input_data) <span class="comment"># 1 * batch_size * hidden_size</span></span><br><span class="line">        cell = self.init_hidden(input_data)</span><br><span class="line">        <span class="comment"># hidden.requires_grad = False</span></span><br><span class="line">        <span class="comment"># cell.requires_grad = False</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(self.T - <span class="number">1</span>):</span><br><span class="line">            <span class="comment"># Eqn. 8: concatenate the hidden states with each predictor</span></span><br><span class="line">            x = torch.cat((hidden.repeat(self.input_size, <span class="number">1</span>, <span class="number">1</span>).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>),</span><br><span class="line">                           cell.repeat(self.input_size, <span class="number">1</span>, <span class="number">1</span>).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>),</span><br><span class="line">                           input_data.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)), dim = <span class="number">2</span>) <span class="comment"># batch_size * input_size * (2*hidden_size + T - 1)</span></span><br><span class="line">            <span class="comment"># Eqn. 9: Get attention weights</span></span><br><span class="line">            x = self.attn_linear(x.view(<span class="number">-1</span>, self.hidden_size * <span class="number">2</span> + self.T - <span class="number">1</span>)) <span class="comment"># (batch_size * input_size) * 1</span></span><br><span class="line">            attn_weights = F.softmax(x.view(<span class="number">-1</span>, self.input_size)) <span class="comment"># batch_size * input_size, attn weights with values sum up to 1.</span></span><br><span class="line">            <span class="comment"># Eqn. 10: LSTM</span></span><br><span class="line">            weighted_input = torch.mul(attn_weights, input_data[:, t, :]) <span class="comment"># batch_size * input_size</span></span><br><span class="line">            <span class="comment"># Fix the warning about non-contiguous memory</span></span><br><span class="line">            <span class="comment"># see https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282</span></span><br><span class="line">            self.lstm_layer.flatten_parameters()</span><br><span class="line">            _, lstm_states = self.lstm_layer(weighted_input.unsqueeze(<span class="number">0</span>), (hidden, cell))</span><br><span class="line">            hidden = lstm_states[<span class="number">0</span>]</span><br><span class="line">            cell = lstm_states[<span class="number">1</span>]</span><br><span class="line">            <span class="comment"># Save output</span></span><br><span class="line">            input_weighted[:, t, :] = weighted_input</span><br><span class="line">            input_encoded[:, t, :] = hidden</span><br><span class="line">        <span class="keyword">return</span> input_weighted, input_encoded</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_hidden</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># No matter whether CUDA is used, the returned variable will have the same type as x.</span></span><br><span class="line">        <span class="keyword">return</span> Variable(x.data.new(<span class="number">1</span>, x.size(<span class="number">0</span>), self.hidden_size).zero_()) <span class="comment"># dimension 0 is the batch dimension</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderAtt</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder_hidden_size, decoder_hidden_size, T)</span>:</span></span><br><span class="line">        super(DecoderAtt, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.T = T</span><br><span class="line">        self.encoder_hidden_size = encoder_hidden_size</span><br><span class="line">        self.decoder_hidden_size = decoder_hidden_size</span><br><span class="line"></span><br><span class="line">        self.attn_layer = nn.Sequential(nn.Linear(<span class="number">2</span> * decoder_hidden_size + encoder_hidden_size, encoder_hidden_size),</span><br><span class="line">                                        nn.Tanh(), nn.Linear(encoder_hidden_size, <span class="number">1</span>))</span><br><span class="line">        self.lstm_layer = nn.LSTM(input_size=<span class="number">1</span>, hidden_size=decoder_hidden_size)</span><br><span class="line">        self.fc = nn.Linear(encoder_hidden_size + <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.fc_final = nn.Linear(decoder_hidden_size + encoder_hidden_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.fc.weight.data.normal_()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_encoded, y_history)</span>:</span></span><br><span class="line">        <span class="comment"># input_encoded: batch_size * T - 1 * encoder_hidden_size</span></span><br><span class="line">        <span class="comment"># y_history: batch_size * (T-1)</span></span><br><span class="line">        <span class="comment"># Initialize hidden and cell, 1 * batch_size * decoder_hidden_size</span></span><br><span class="line">        hidden = self.init_hidden(input_encoded)</span><br><span class="line">        cell = self.init_hidden(input_encoded)</span><br><span class="line">        <span class="comment"># hidden.requires_grad = False</span></span><br><span class="line">        <span class="comment"># cell.requires_grad = False</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(self.T - <span class="number">1</span>):</span><br><span class="line">            <span class="comment"># Eqn. 12-13: compute attention weights</span></span><br><span class="line">            <span class="comment">## batch_size * T * (2*decoder_hidden_size + encoder_hidden_size)</span></span><br><span class="line">            x = torch.cat((hidden.repeat(self.T - <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>),</span><br><span class="line">                           cell.repeat(self.T - <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>), input_encoded), dim=<span class="number">2</span>)</span><br><span class="line">            x = F.softmax(self.attn_layer(x.view(<span class="number">-1</span>, <span class="number">2</span> * self.decoder_hidden_size + self.encoder_hidden_size</span><br><span class="line">                                                 )).view(<span class="number">-1</span>, self.T - <span class="number">1</span>))  <span class="comment"># batch_size * T - 1, row sum up to 1</span></span><br><span class="line">            <span class="comment"># Eqn. 14: compute context vector</span></span><br><span class="line">            context = torch.bmm(x.unsqueeze(<span class="number">1</span>), input_encoded)[:, <span class="number">0</span>, :]  <span class="comment"># batch_size * encoder_hidden_size</span></span><br><span class="line">            <span class="keyword">if</span> t &lt; self.T - <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># Eqn. 15</span></span><br><span class="line">                y_tilde = self.fc(torch.cat((context, y_history[:, t].unsqueeze(<span class="number">1</span>)), dim=<span class="number">1</span>))  <span class="comment"># batch_size * 1</span></span><br><span class="line">                <span class="comment"># Eqn. 16: LSTM</span></span><br><span class="line">                self.lstm_layer.flatten_parameters()</span><br><span class="line">                _, lstm_output = self.lstm_layer(y_tilde.unsqueeze(<span class="number">0</span>), (hidden, cell))</span><br><span class="line">                hidden = lstm_output[<span class="number">0</span>]  <span class="comment"># 1 * batch_size * decoder_hidden_size</span></span><br><span class="line">                cell = lstm_output[<span class="number">1</span>]  <span class="comment"># 1 * batch_size * decoder_hidden_size</span></span><br><span class="line">        <span class="comment"># Eqn. 22: final output</span></span><br><span class="line">        y_pred = self.fc_final(torch.cat((hidden[<span class="number">0</span>], context), dim=<span class="number">1</span>))</span><br><span class="line">        <span class="comment"># self.logger.info("hidden %s context %s y_pred: %s", hidden[0][0][:10], context[0][:10], y_pred[:10])</span></span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_hidden</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> Variable(x.data.new(<span class="number">1</span>, x.size(<span class="number">0</span>), self.decoder_hidden_size).zero_())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_data</span><span class="params">(dat, col_names)</span>:</span></span><br><span class="line">    scale = StandardScaler().fit(dat)</span><br><span class="line">    proc_dat = scale.transform(dat)</span><br><span class="line"></span><br><span class="line">    mask = np.ones(proc_dat.shape[<span class="number">1</span>], dtype=bool)</span><br><span class="line">    dat_cols = list(dat.columns)</span><br><span class="line">    <span class="keyword">for</span> col_name <span class="keyword">in</span> col_names:</span><br><span class="line">        mask[dat_cols.index(col_name)] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    feats = proc_dat[:, mask]</span><br><span class="line">    targs = proc_dat[:, ~mask]</span><br><span class="line">    <span class="keyword">return</span> feats, targs, scale</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">da_rnn</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, file_data, encoder_hidden_size=<span class="number">64</span>, decoder_hidden_size=<span class="number">64</span>, T=<span class="number">10</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 learning_rate=<span class="number">0.01</span>, batch_size=<span class="number">128</span>, parallel=True, debug=False)</span>:</span></span><br><span class="line">        self.T = T</span><br><span class="line">        dat = pd.read_csv(file_data, nrows=<span class="number">100</span> <span class="keyword">if</span> debug <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line">        <span class="comment"># read first 100 rows</span></span><br><span class="line">        <span class="comment"># self.logger.info("Shape of data: %s.\nMissing in data: %s.", dat.shape, dat.isnull().sum().sum())</span></span><br><span class="line">        <span class="comment"># scale = StandardScaler().fit(dat.values)</span></span><br><span class="line">        <span class="comment"># dat = pd.DataFrame(scale.transform(dat.values))</span></span><br><span class="line">        <span class="comment"># self.X = dat.loc[:, [x for x in dat.columns.tolist() if x != 'NDX']].as_matrix()</span></span><br><span class="line">        self.X, self.y, self.scaler = preprocess_data(dat, (<span class="string">"NDX"</span>,))</span><br><span class="line">        <span class="comment"># select matrix without NDX</span></span><br><span class="line">        <span class="comment"># (ndarray:(40560,81))</span></span><br><span class="line">        self.y = (self.y).reshape((self.y).shape[<span class="number">0</span>],)</span><br><span class="line">        <span class="comment"># self.y = np.array(dat.NDX)</span></span><br><span class="line">        <span class="comment"># (ndarray:(40560,))</span></span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        <span class="comment"># 128</span></span><br><span class="line">        self.encoder = EncoderAtt(input_size=self.X.shape[<span class="number">1</span>], hidden_size=encoder_hidden_size, T=T).to(device)</span><br><span class="line">        self.decoder = DecoderAtt(encoder_hidden_size=encoder_hidden_size, decoder_hidden_size=decoder_hidden_size, T=T).to(device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> parallel:</span><br><span class="line">            self.encoder = nn.DataParallel(self.encoder)</span><br><span class="line">            self.decoder = nn.DataParallel(self.decoder)</span><br><span class="line">        <span class="comment">#  multiple GPU training</span></span><br><span class="line"></span><br><span class="line">        self.encoder_optimizer = optim.Adam(params=filter(<span class="keyword">lambda</span> p: p.requires_grad, self.encoder.parameters()),</span><br><span class="line">                                           lr=learning_rate)</span><br><span class="line">        self.decoder_optimizer = optim.Adam(params=filter(<span class="keyword">lambda</span> p: p.requires_grad, self.decoder.parameters()),</span><br><span class="line">                                           lr=learning_rate)</span><br><span class="line">        <span class="comment"># self.learning_rate = learning_rate</span></span><br><span class="line"></span><br><span class="line">        self.train_size = int(self.X.shape[<span class="number">0</span>] * <span class="number">0.7</span>)</span><br><span class="line">        <span class="comment"># &#123;int&#125; 28392</span></span><br><span class="line">        <span class="comment"># self.y = self.y - np.mean(self.y[:self.train_size])</span></span><br><span class="line">        <span class="comment"># self.y = (self.y - np.mean(self.y[:self.train_size])) / np.std(self.y[:self.train_size])</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Question: why Adam requires data to be normalized?</span></span><br><span class="line">        <span class="comment"># self.logger.info("Training size: %d.", self.train_size)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, n_epochs=<span class="number">10</span>)</span>:</span></span><br><span class="line">        iter_per_epoch = int(np.ceil(self.train_size * <span class="number">1.</span> / self.batch_size))</span><br><span class="line">        print(<span class="string">"Iterations per epoch: %3.3f ~ %d."</span>, self.train_size * <span class="number">1.</span> / self.batch_size, iter_per_epoch)</span><br><span class="line">        self.iter_losses = np.zeros(n_epochs * iter_per_epoch)</span><br><span class="line">        self.epoch_losses = np.zeros(n_epochs)</span><br><span class="line"></span><br><span class="line">        self.loss_func = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">        n_iter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        learning_rate = <span class="number">1.</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">            perm_idx = np.random.permutation(self.train_size - self.T)</span><br><span class="line">            j = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> j &lt; self.train_size:</span><br><span class="line">                batch_idx = perm_idx[j:(j + self.batch_size)]</span><br><span class="line">                X = np.zeros((len(batch_idx), self.T - <span class="number">1</span>, self.X.shape[<span class="number">1</span>]))</span><br><span class="line">                y_history = np.zeros((len(batch_idx), self.T - <span class="number">1</span>))</span><br><span class="line">                y_target = self.y[batch_idx + self.T]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> range(len(batch_idx)):</span><br><span class="line">                    X[k, :, :] = self.X[batch_idx[k] : (batch_idx[k] + self.T - <span class="number">1</span>), :]</span><br><span class="line">                    y_history[k, :] = self.y[batch_idx[k]: (batch_idx[k] + self.T - <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">                loss = self.train_iteration(X, y_history, y_target)</span><br><span class="line">                self.iter_losses[int(i * iter_per_epoch + j / self.batch_size)] = loss</span><br><span class="line">                <span class="comment">#if (j / self.batch_size) % 50 == 0:</span></span><br><span class="line">                <span class="comment">#    self.logger.info("Epoch %d, Batch %d: loss = %3.3f.", i, j / self.batch_size, loss)</span></span><br><span class="line">                j += self.batch_size</span><br><span class="line">                n_iter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> n_iter % <span class="number">10000</span> == <span class="number">0</span> <span class="keyword">and</span> n_iter &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">for</span> param_group <span class="keyword">in</span> self.encoder_optimizer.param_groups:</span><br><span class="line">                        param_group[<span class="string">'lr'</span>] = param_group[<span class="string">'lr'</span>] * <span class="number">0.9</span></span><br><span class="line">                    <span class="keyword">for</span> param_group <span class="keyword">in</span> self.decoder_optimizer.param_groups:</span><br><span class="line">                        param_group[<span class="string">'lr'</span>] = param_group[<span class="string">'lr'</span>] * <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">            self.epoch_losses[i] = np.mean(self.iter_losses[range(i * iter_per_epoch, (i + <span class="number">1</span>) * iter_per_epoch)])</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"Epoch %d, loss: %3.3f."</span> % (i, self.epoch_losses[i]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                y_train_pred = self.predict(on_train=<span class="literal">True</span>)  <span class="comment"># 28383</span></span><br><span class="line">                y_test_pred = self.predict(on_train=<span class="literal">False</span>)  <span class="comment"># 12168</span></span><br><span class="line">                y_pred = np.concatenate((y_train_pred, y_test_pred))    <span class="comment"># 40551</span></span><br><span class="line">                <span class="comment"># X (40560,)</span></span><br><span class="line">                <span class="comment"># y (40560,)</span></span><br><span class="line">                print(y_train_pred.shape, y_test_pred.shape, y_pred.shape)</span><br><span class="line">                print((self.y).shape,(self.X).shape)</span><br><span class="line">                <span class="comment"># (40560,) (40560, 81)</span></span><br><span class="line">                true = concatenate(((self.y).reshape(self.y.shape[<span class="number">0</span>], <span class="number">1</span>), self.X), axis=<span class="number">1</span>)</span><br><span class="line">                true = self.scaler.inverse_transform(true)</span><br><span class="line">                self.y = true[:, <span class="number">0</span>]</span><br><span class="line">                <span class="comment"># true [1,40560] len = 40560</span></span><br><span class="line">                print(self.T, len(y_train_pred) + self.T)</span><br><span class="line">                <span class="comment"># 10 28393</span></span><br><span class="line">                print(self.T + len(y_train_pred), len(self.y) + <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 28393 40561</span></span><br><span class="line">                <span class="comment"># y_train_pred = concatenate((y_train_pred.reshape(y_train_pred.shape[0], 1), self.X[self.T-1: len(y_train_pred) + self.T-1]), axis=1)</span></span><br><span class="line">                y_train_pred = concatenate((y_train_pred.reshape(y_train_pred.shape[<span class="number">0</span>], <span class="number">1</span>),</span><br><span class="line">                                            self.X[: len(y_train_pred)]), axis=<span class="number">1</span>)</span><br><span class="line">                y_train_pred = self.scaler.inverse_transform(y_train_pred)</span><br><span class="line">                y_train_pred = y_train_pred[:, <span class="number">0</span>]</span><br><span class="line">                <span class="comment"># y_train_pred [10,28392] len = 28383</span></span><br><span class="line">                <span class="comment"># y_test_pred = concatenate((y_test_pred.reshape(y_test_pred.shape[0], 1), self.X[self.T + len(y_train_pred)-1:]), axis=1)</span></span><br><span class="line">                y_test_pred = concatenate(</span><br><span class="line">                    (y_test_pred.reshape(y_test_pred.shape[<span class="number">0</span>], <span class="number">1</span>), self.X[len(y_train_pred):len(y_train_pred)+len(y_test_pred)]), axis=<span class="number">1</span>)</span><br><span class="line">                y_test_pred = self.scaler.inverse_transform(y_test_pred)</span><br><span class="line">                y_test_pred = y_test_pred[:, <span class="number">0</span>]</span><br><span class="line">                <span class="comment"># y_test_pred [28393,40560] len = 12168</span></span><br><span class="line">                plt.figure()</span><br><span class="line">                plt.plot(range(<span class="number">1</span>, <span class="number">1</span> + len(self.y)), self.y, label=<span class="string">"True"</span>)</span><br><span class="line">                plt.plot(range(self.T, len(y_train_pred) + self.T), y_train_pred, label = <span class="string">'Predicted - Train'</span>)</span><br><span class="line">                plt.plot(range(self.T + len(y_train_pred), len(self.y) + <span class="number">1</span>), y_test_pred, label = <span class="string">'Predicted - Test'</span>)</span><br><span class="line">                plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">                plt.savefig(<span class="string">'./resultpic/epoch_%d.jpg'</span> % i)</span><br><span class="line">                plt.show()</span><br><span class="line"></span><br><span class="line">        y_train_pred = self.predict(on_train=<span class="literal">True</span>)</span><br><span class="line">        y_test_pred = self.predict(on_train=<span class="literal">False</span>)</span><br><span class="line">        y_pred = np.concatenate((y_train_pred, y_test_pred))</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(range(<span class="number">1</span>, <span class="number">1</span> + len(self.y)), self.y, label=<span class="string">"True"</span>)</span><br><span class="line">        plt.plot(range(self.T, len(y_train_pred) + self.T), y_train_pred, label=<span class="string">'Predicted - Train'</span>)</span><br><span class="line">        plt.plot(range(self.T + len(y_train_pred), len(self.y) + <span class="number">1</span>), y_test_pred, label=<span class="string">'Predicted - Test'</span>)</span><br><span class="line">        plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">        plt.savefig(<span class="string">'./resultpic/final.jpg'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_iteration</span><span class="params">(self, X, y_history, y_target)</span>:</span></span><br><span class="line">        self.encoder_optimizer.zero_grad()</span><br><span class="line">        self.decoder_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        input_weighted, input_encoded = self.encoder(Variable(torch.from_numpy(X).type(torch.FloatTensor).to(device)))</span><br><span class="line">        y_pred = self.decoder(input_encoded, Variable(torch.from_numpy(y_history).type(torch.FloatTensor).to(device)))</span><br><span class="line">        y_pred = y_pred.view(<span class="number">-1</span>)</span><br><span class="line">        <span class="comment"># print('y_pred', y_pred.shape)</span></span><br><span class="line">        y_true = Variable(torch.from_numpy(y_target).type(torch.FloatTensor).to(device))</span><br><span class="line">        <span class="comment"># print('y_true', y_true.shape)</span></span><br><span class="line">        loss = self.loss_func(y_pred, y_true)</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        self.encoder_optimizer.step()</span><br><span class="line">        self.decoder_optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss.item()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, on_train = False)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> on_train:</span><br><span class="line">            y_pred = np.zeros(self.train_size - self.T + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            y_pred = np.zeros(self.X.shape[<span class="number">0</span>] - self.train_size)</span><br><span class="line"></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; len(y_pred):</span><br><span class="line">            batch_idx = np.array(range(len(y_pred)))[i : (i + self.batch_size)]</span><br><span class="line">            X = np.zeros((len(batch_idx), self.T - <span class="number">1</span>, self.X.shape[<span class="number">1</span>]))</span><br><span class="line">            y_history = np.zeros((len(batch_idx), self.T - <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(len(batch_idx)):</span><br><span class="line">                <span class="keyword">if</span> on_train:</span><br><span class="line">                    X[j, :, :] = self.X[range(batch_idx[j], batch_idx[j] + self.T - <span class="number">1</span>), :]</span><br><span class="line">                    y_history[j, :] = self.y[range(batch_idx[j],  batch_idx[j]+ self.T - <span class="number">1</span>)]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    X[j, :, :] = self.X[range(batch_idx[j] + self.train_size - self.T, batch_idx[j] + self.train_size - <span class="number">1</span>), :]</span><br><span class="line">                    y_history[j, :] = self.y[range(batch_idx[j] + self.train_size - self.T,  batch_idx[j]+ self.train_size - <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">            y_history = Variable(torch.from_numpy(y_history).type(torch.FloatTensor).to(device))</span><br><span class="line">            _, input_encoded = self.encoder(Variable(torch.from_numpy(X).type(torch.FloatTensor).to(device)))</span><br><span class="line">            y_pred[i:(i + self.batch_size)] = self.decoder(input_encoded, y_history).cpu().data.numpy()[:, <span class="number">0</span>]</span><br><span class="line">            i += self.batch_size</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">io_dir = <span class="string">'nasdaq100_padding.csv'</span></span><br><span class="line"></span><br><span class="line">model = da_rnn(file_data=<span class="string">'&#123;&#125;'</span>.format(io_dir), parallel=<span class="literal">False</span>, learning_rate=<span class="number">.001</span>)</span><br><span class="line"></span><br><span class="line">model.train(n_epochs=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">y_pred = model.predict()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.semilogy(range(len(model.iter_losses)), model.iter_losses)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.semilogy(range(len(model.epoch_losses)), model.epoch_losses)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(y_pred, label = <span class="string">'Predicted'</span>)</span><br><span class="line">plt.plot(model.y[model.train_size:], label = <span class="string">"True"</span>)</span><br><span class="line">plt.legend(loc = <span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>Learn-Pytorch-Variable</title>
    <url>/2019/12/10/Learn-Pytorch-Variable/</url>
    <content><![CDATA[<p>Tensor是Pytorch的一个完美组件(可以生成高维数组)，但是要构建神经网络还是远远不够的，我们需要能够计算图的Tensor，那就是Variable。Variable是对Tensor的一个封装，操作和Tensor是一样的，但是每个Variable都有三个属性，Varibale的Tensor本身的.data，对应Tensor的梯度.grad，以及这个Variable是通过什么方式得到的.grad_fn<br><a id="more"></a></p>
<h4 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h4><p>autograd.Variable 是包的核心类. 它包装了张量, 并且支持几乎所有的操作. 一旦你完成了你的计算, 你就可以调用 .backward() 方法, 然后所有的梯度计算会自动进行.你还可以通过 .data 属性来访问原始的张量, 而关于该 variable（变量）的梯度会被累计到 .grad上去.还有一个针对自动求导实现来说非常重要的类 - Function.Variable 和 Function 是相互联系的, 并且它们构建了一个非循环的图, 编码了一个完整的计算历史信息. 每一个 variable（变量）都有一个 .grad_fn 属性, 它引用了一个已经创建了 Variable 的 Function （除了用户创建的 Variable <code>之外 - 它们的</code>grad_fn is None ）.如果你想计算导数, 你可以在 Variable 上调用 .backward() 方法. 如果 Variable 是标量的形式（例如, 它包含一个元素数据）, 你不必指定任何参数给 backward(), 但是, 如果它有更多的元素. 你需要去指定一个 grad_output 参数, 该参数是一个匹配 shape（形状）的张量.</p>
<h4 id="创建一个2×2的变量"><a href="#创建一个2×2的变量" class="headerlink" title="创建一个2×2的变量"></a>创建一个2×2的变量</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">View more, visit my tutorial page: https://arithmeticjia.github.io</span></span><br><span class="line"><span class="string">My Blog: https://www.guanacossj.com</span></span><br><span class="line"><span class="string">Dependencies:</span></span><br><span class="line"><span class="string">torch: 1.3.0</span></span><br><span class="line"><span class="string">matplotlib</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="comment"># Variable in torch is to build a computational graph,</span></span><br><span class="line"><span class="comment"># but this graph is dynamic compared with a static graph in Tensorflow or Theano.</span></span><br><span class="line"><span class="comment"># So torch does not have placeholder, torch can just pass variable to the computational graph.</span></span><br><span class="line"></span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])            <span class="comment"># build a tensor</span></span><br><span class="line">variable = Variable(tensor, requires_grad=<span class="literal">True</span>)      <span class="comment"># build a variable, usually for compute gradients</span></span><br><span class="line"></span><br><span class="line">print(tensor)       <span class="comment"># [torch.FloatTensor of size 2x2]</span></span><br><span class="line">print(variable)     <span class="comment"># [torch.FloatTensor of size 2x2]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tensor([[1., 2.],</span><br><span class="line">        [3., 4.]])</span><br><span class="line">tensor([[1., 2.],</span><br><span class="line">        [3., 4.]], requires_grad=True)</span><br></pre></td></tr></table></figure>
<h4 id="计算变量的点乘积、梯度"><a href="#计算变量的点乘积、梯度" class="headerlink" title="计算变量的点乘积、梯度"></a>计算变量的点乘积、梯度</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">View more, visit my tutorial page: https://arithmeticjia.github.io</span></span><br><span class="line"><span class="string">My Blog: https://www.guanacossj.com</span></span><br><span class="line"><span class="string">Dependencies:</span></span><br><span class="line"><span class="string">torch: 1.3.0</span></span><br><span class="line"><span class="string">matplotlib</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="comment"># Variable in torch is to build a computational graph,</span></span><br><span class="line"><span class="comment"># but this graph is dynamic compared with a static graph in Tensorflow or Theano.</span></span><br><span class="line"><span class="comment"># So torch does not have placeholder, torch can just pass variable to the computational graph.</span></span><br><span class="line"></span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])            <span class="comment"># build a tensor</span></span><br><span class="line">variable = Variable(tensor, requires_grad=<span class="literal">True</span>)      <span class="comment"># build a variable, usually for compute gradients</span></span><br><span class="line"></span><br><span class="line">print(tensor)       <span class="comment"># [torch.FloatTensor of size 2x2]</span></span><br><span class="line">print(variable)     <span class="comment"># [torch.FloatTensor of size 2x2]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># till now the tensor and variable seem the same.</span></span><br><span class="line"><span class="comment"># However, the variable is a part of the graph, it's a part of the auto-gradient.</span></span><br><span class="line"></span><br><span class="line">t_out = torch.mean(tensor*tensor)       <span class="comment"># x^2</span></span><br><span class="line">v_out = torch.mean(variable*variable)   <span class="comment"># x^2</span></span><br><span class="line">print(t_out)</span><br><span class="line">print(v_out)                            <span class="comment"># 7.5</span></span><br><span class="line"></span><br><span class="line">print(variable*variable)</span><br><span class="line"><span class="comment"># 点乘操作</span></span><br><span class="line">print(torch.mm(variable,variable))</span><br><span class="line"><span class="comment"># 矩阵相乘</span></span><br><span class="line">v_out.backward()    <span class="comment"># backpropagation from v_out</span></span><br><span class="line"><span class="comment"># v_out = 1/4 * sum(variable*variable)</span></span><br><span class="line"><span class="comment"># the gradients w.r.t the variable, d(v_out)/d(variable) = 1/4*2*variable = variable/2</span></span><br><span class="line">print(variable.grad)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string"> 0.5000  1.0000</span></span><br><span class="line"><span class="string"> 1.5000  2.0000</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tensor([[1., 2.],</span><br><span class="line">        [3., 4.]])</span><br><span class="line">tensor([[1., 2.],</span><br><span class="line">        [3., 4.]], requires_grad=True)</span><br><span class="line">tensor(7.5000)</span><br><span class="line">tensor(7.5000, grad_fn=&lt;MeanBackward0&gt;)</span><br><span class="line">tensor([[ 1.,  4.],</span><br><span class="line">        [ 9., 16.]], grad_fn=&lt;MulBackward0&gt;)</span><br><span class="line">tensor([[ 7., 10.],</span><br><span class="line">        [15., 22.]], grad_fn=&lt;MmBackward&gt;)</span><br><span class="line">tensor([[0.5000, 1.0000],</span><br><span class="line">        [1.5000, 2.0000]])</span><br></pre></td></tr></table></figure>
<p>注意这里的变量的点乘和相乘的区别</p>
<h4 id="查看变量的数据"><a href="#查看变量的数据" class="headerlink" title="查看变量的数据"></a>查看变量的数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(variable)     <span class="comment"># this is data in variable format</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Variable containing:</span></span><br><span class="line"><span class="string"> 1  2</span></span><br><span class="line"><span class="string"> 3  4</span></span><br><span class="line"><span class="string">[torch.FloatTensor of size 2x2]</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">print(variable.data)    <span class="comment"># this is data in tensor format</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"> 1  2</span></span><br><span class="line"><span class="string"> 3  4</span></span><br><span class="line"><span class="string">[torch.FloatTensor of size 2x2]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tensor([[1., 2.],</span><br><span class="line">        [3., 4.]], requires_grad=True)</span><br><span class="line">tensor([[1., 2.],</span><br><span class="line">        [3., 4.]])</span><br></pre></td></tr></table></figure>
<h4 id="Variable转numpy"><a href="#Variable转numpy" class="headerlink" title="Variable转numpy"></a>Variable转numpy</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(variable.data.numpy())    <span class="comment"># numpy format</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">[[ 1.  2.]</span></span><br><span class="line"><span class="string"> [ 3.  4.]]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[[1. 2.]</span><br><span class="line"> [3. 4.]]</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>2019-12-13周报</title>
    <url>/2019/12/10/2019-12-13%E5%91%A8%E6%8A%A5-%E5%8D%95%E6%B2%99%E5%98%89/</url>
    <content><![CDATA[<p>Work between 2019/12/07-2019/12/13<br><a id="more"></a></p>
<h4 id="A-Dual-Stage-Attention-Based-Recurrent-Neural-Network-for-Time-Series-Prediction"><a href="#A-Dual-Stage-Attention-Based-Recurrent-Neural-Network-for-Time-Series-Prediction" class="headerlink" title="A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction"></a>A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction</h4><h5 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h5><p><img src="https://www.guanacossj.com/media/articlebodypics/lstm-attention.jpg" alt=""></p>
<ul>
<li>Bi-LSTM + Attention 就是在Bi-LSTM的模型上加入Attention层，在Bi-LSTM中我们会用最后一个时序的输出向量 作为特征向量，然后进行softmax分类。Attention是先计算每个时序的权重，然后将所有时序 的向量进行加权和作为特征向量，然后进行softmax分类</li>
<li>sigmoid把一个real value映射到(0,1)的区间(当然也可以是(-1,1)),这样可以用来做二分类</li>
<li>softmax把一个k维的real value向量(a1,a2,a3,a4…)映射成一个(b1,b2,b3,b4…)其中bi是一个0-1的常数，然后可以根据bi的大小来进行多分类的任务，如取权重最大的一维</li>
<li>传统的注意力机制只用在解码器的输入阶段，即对不同时刻产生不同的context vector不同，该文还在编码器的输入阶段引入了注意力机制，从而同时实现了选取特征因子(feature selection)和把握长期时序依赖关系(long-term temporal dependencies)</li>
<li>第一阶段，使用注意力机制自适应地提取每个时刻的相关feature<script type="math/tex; mode=display">e_{t}^{k}=v_{e}^{T}tanh(W_{e}[h_{t-1};s_{t-1}]+U_{e}x^{k})</script></li>
<li>用softmax函数将其归一化<script type="math/tex; mode=display">\alpha _{t}^{k}=\frac{exp(e_{t}^{k})}{\sum_{i-1}^{n}exp(e_{t}^{i})}</script></li>
<li>得到更新后的x<script type="math/tex; mode=display">\tilde{x} = (\alpha _{t}^{1}x_{t}^{1}, \alpha _{t}^{2}x_{t}^{2},...,\alpha _{t}^{n}x_{t}^{n})</script></li>
<li>选取LSTM作为编码器<script type="math/tex">f_{1}</script><script type="math/tex; mode=display">h_{t} = f_{1}(h_{t-1},  \tilde{x})</script></li>
<li><p>第二阶段，使用另一个注意力机制选取与之相关的encoder hidden states</p>
<script type="math/tex; mode=display">c_{t}^{'} = \sum_{t-1}^{T}\beta _{t^{'}}^{t}h_{t}</script></li>
<li><p><script type="math/tex">\beta _{t^{'}}^{t}</script>的设计类似于Bahanau的工作，基于前一个时刻解码器的hidden state[公式]和cell state[公式]计算得到：</p>
</li>
</ul>
<h5 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 10</span><br><span class="line"><span class="keyword">Test </span>RMSE: 0.259</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.056</span><br><span class="line"><span class="keyword">Test </span>Data: all</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/pred_0.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/final_predicted_reloaded.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/final_predicted_reloaded_standard.png" alt=""></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 10</span><br><span class="line"><span class="keyword">Test </span>RMSE: 0.327</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.275</span><br><span class="line"><span class="keyword">Test </span>Data: all * 0.3</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/final_predicted.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/final_predicted_standard.png" alt=""></p>
<h4 id="Vm1-Power-Matrix-From-Paper"><a href="#Vm1-Power-Matrix-From-Paper" class="headerlink" title="Vm1-Power-Matrix-From-Paper"></a>Vm1-Power-Matrix-From-Paper</h4><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 10</span><br><span class="line"><span class="keyword">Test </span>RMSE: 2.602</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.207</span><br><span class="line"><span class="keyword">Test </span>Data: all<span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/all_server_final_predicted_reloaded-larger.png" alt=""></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 10</span><br><span class="line"><span class="keyword">Test </span>RMSE: 3.057</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.361</span><br><span class="line"><span class="keyword">Test </span>Data: 49000<span class="string">-50000</span><span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/49000_50000_server_final_predicted_reloaded.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/49000_50000_server_final_predicted_reloaded-larger.png" alt=""><br><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 10</span><br><span class="line"><span class="keyword">Test </span>RMSE: 2.949</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.259</span><br><span class="line"><span class="keyword">Test </span>Data: 32000<span class="string">-33000</span><span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure><br><img src="https://www.guanacossj.com/media/articlebodypics/32000_33000_server_final_predicted_reloaded-larger.png" alt=""></p>
<h4 id="Vm1-Power-Matrix-From-Jia"><a href="#Vm1-Power-Matrix-From-Jia" class="headerlink" title="Vm1-Power-Matrix-From-Jia"></a>Vm1-Power-Matrix-From-Jia</h4><h5 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Training Data: 1111<span class="string">-1115</span></span><br><span class="line"><span class="keyword">Testing </span>Data: 1116<span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="params">(n,m)</span> -&gt;</span> <span class="function"><span class="params">(n,m * timestamp)</span> -&gt;</span> (n,timestamp,m)</span><br></pre></td></tr></table></figure>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">    var1(t<span class="number">-60</span>)  var2(t<span class="number">-60</span>)  var3(t<span class="number">-60</span>)  ...   var5(t)   var6(t)   var7(t)</span><br><span class="line"><span class="number">60</span>    <span class="number">0.655771</span>   <span class="number">-1.060919</span>   <span class="number">-0.735941</span>  ... <span class="number">-0.447461</span> <span class="number">-0.217168</span> <span class="number">-0.030555</span></span><br><span class="line"><span class="number">61</span>    <span class="number">0.560612</span>   <span class="number">-1.060919</span>   <span class="number">-0.735941</span>  ... <span class="number">-0.023654</span> <span class="number">-0.222058</span> <span class="number">-0.030555</span></span><br><span class="line"><span class="number">62</span>    <span class="number">0.655771</span>   <span class="number">-1.060919</span>   <span class="number">-0.735941</span>  ... <span class="number">-0.222916</span> <span class="number">-0.207537</span> <span class="number">-0.030555</span></span><br><span class="line"><span class="number">63</span>    <span class="number">0.465453</span>   <span class="number">-1.060919</span>   <span class="number">-0.735941</span>  ... <span class="number">-0.638782</span> <span class="number">-0.222058</span> <span class="number">-0.030555</span></span><br><span class="line"><span class="number">64</span>   <span class="number">-0.010342</span>   <span class="number">-1.047501</span>   <span class="number">-0.735941</span>  ...  <span class="number">1.133103</span> <span class="number">-0.222058</span> <span class="number">-0.030555</span></span><br></pre></td></tr></table></figure>
<h5 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h5><ul>
<li>Mean Normaliztion(均值归一化)</li>
</ul>
<script type="math/tex; mode=display">
x^{*} = \frac{x-\mu}{\sigma }</script><ul>
<li>Min-Max Normalization</li>
</ul>
<script type="math/tex; mode=display">
x^{*} = \frac{x-min}{max-min }</script><h5 id="Bi-GRU-Attention"><a href="#Bi-GRU-Attention" class="headerlink" title="Bi-GRU + Attention"></a>Bi-GRU + Attention</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 20</span><br><span class="line"><span class="keyword">Test </span>RMSE: 3.054</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.243</span><br><span class="line"><span class="keyword">Test </span>Data: all<span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/gru-bi-20-all-att-1620.jpg" alt=""></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 20</span><br><span class="line"><span class="keyword">Test </span>RMSE: 3.458</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.418</span><br><span class="line"><span class="keyword">Test </span>Data: 49000<span class="string">-50000</span><span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/49000_50000_n_final_gru_pro_attention_bi_20.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/mark_49000_50000_n_final_gru_pro_attention_bi_20.png" alt=""></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 20</span><br><span class="line"><span class="keyword">Test </span>RMSE: 3.196</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.287</span><br><span class="line"><span class="keyword">Test </span>Data: 32000<span class="string">-33000</span><span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/32000_33000_n_final_gru_pro_attention_bi_20.png" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/mark_32000_33000_n_final_gru_pro_attention_bi_20.png" alt=""></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 20</span><br><span class="line"><span class="keyword">Test </span>RMSE: 4.573</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.45</span><br><span class="line"><span class="keyword">Test </span>Data: 70000<span class="string">-70500</span><span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/70000-70500-gru-bi-att-20-1620.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/mark_70000-70500-gru-bi-att-20-1620.jpg" alt=""></p>
<h5 id="Bi-LSTM-Attention"><a href="#Bi-LSTM-Attention" class="headerlink" title="Bi-LSTM + Attention"></a>Bi-LSTM + Attention</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 20</span><br><span class="line"><span class="keyword">Test </span>RMSE: 2.776</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.221</span><br><span class="line"><span class="keyword">Test </span>Data: all<span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/lstm-bi-20-att-all-1620.jpg" alt=""></p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 20</span><br><span class="line"><span class="keyword">Test </span>RMSE: 4.596</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.460</span><br><span class="line"><span class="keyword">Test </span>Data: 70000<span class="string">-70500</span><span class="string">-1116</span><span class="string">-1120</span></span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/70000-70500-lstm-bi-att-20-01-1620.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/mark_70000-70500-lstm-bi-att-20-01-1620.jpg" alt=""></p>
<h5 id="Bi-LSTM-Only"><a href="#Bi-LSTM-Only" class="headerlink" title="Bi-LSTM Only"></a>Bi-LSTM Only</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">Epochs: 500</span><br><span class="line">Train-Data: 1111<span class="string">-1115</span></span><br><span class="line">Test-Data: 1116<span class="string">-1120</span></span><br><span class="line"><span class="keyword">Test </span>RMSE: 3.880</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.308</span><br></pre></td></tr></table></figure>
<p>Test Data: all-1116-1120<br><img src="https://www.guanacossj.com/media/articlebodypics/lstm-bi-500-all-1620.jpg" alt=""></p>
<p>Test Data: 50000-50500-1116-1120<br><img src="https://www.guanacossj.com/media/articlebodypics/lstm-bi-500-01-1620.jpg" alt=""></p>
<p>Test Data: 60000-60500-1116-1120<br><img src="https://www.guanacossj.com/media/articlebodypics/lstm-bi-500-02-1620.jpg" alt=""></p>
<p>Test Data: 30000-30500-1116-1120<br><img src="https://www.guanacossj.com/media/articlebodypics/lstm-bi-500-03-1620.jpg" alt=""></p>
<h4 id="Bi-LSTM-Attenion-amp-GRU-LSTM-Attenion-In-Stock-With-Pytorch"><a href="#Bi-LSTM-Attenion-amp-GRU-LSTM-Attenion-In-Stock-With-Pytorch" class="headerlink" title="Bi-LSTM-Attenion &amp; GRU-LSTM-Attenion In Stock With Pytorch"></a>Bi-LSTM-Attenion &amp; GRU-LSTM-Attenion In Stock With Pytorch</h4><h5 id="Bi-GRU"><a href="#Bi-GRU" class="headerlink" title="Bi-GRU"></a>Bi-GRU</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 66.403</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.077</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/pytorch-bi-gru-stock.png" alt=""></p>
<h5 id="Bi-LSTM"><a href="#Bi-LSTM" class="headerlink" title="Bi-LSTM"></a>Bi-LSTM</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 88.421</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.103</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/pytorch-bi-lstm-stock.png" alt=""></p>
<h5 id="Bi-GRU-Attention-1"><a href="#Bi-GRU-Attention-1" class="headerlink" title="Bi-GRU-Attention"></a>Bi-GRU-Attention</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 86.775</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.101</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/pytorch-bi-gru-att-stock.png" alt=""></p>
<h5 id="Bi-LSTM-Attention-1"><a href="#Bi-LSTM-Attention-1" class="headerlink" title="Bi-LSTM-Attention"></a>Bi-LSTM-Attention</h5><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Test </span>RMSE: 86.588</span><br><span class="line"><span class="keyword">Test </span>nRMSE: 0.101</span><br></pre></td></tr></table></figure>
<p><img src="https://www.guanacossj.com/media/articlebodypics/pytorch-bi-lstm-att-stock.png" alt=""></p>
]]></content>
      <categories>
        <category>周报</category>
      </categories>
  </entry>
  <entry>
    <title>Django个人博客搭建教程-Django-Rest-Framework外键与多对多序列化</title>
    <url>/2019/12/09/Django%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B-Django-Rest-Framework%E5%A4%96%E9%94%AE%E4%B8%8E%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%BA%8F%E5%88%97%E5%8C%96/</url>
    <content><![CDATA[<p>如果对一个含有多对多、外键的模型进行序列化，这时候这些关联的字段会只展示id，因此需要对外键或者多对多的字段进行序列化处理<br><a id="more"></a></p>
<h4 id="外键序列化（ForeignKey）-amp-多对多序列化（manytomany"><a href="#外键序列化（ForeignKey）-amp-多对多序列化（manytomany" class="headerlink" title="外键序列化（ForeignKey）&amp;多对多序列化（manytomany)"></a>外键序列化（ForeignKey）&amp;多对多序列化（manytomany)</h4><p>这里要序列化的模型是Articles,其中的authorname、tags、category用了外键或者多对多关联<br>关联的两个模型是Tag和Category<br>models.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Category</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        Django 要求模型必须继承 models.Model 类。</span></span><br><span class="line"><span class="string">        Category 只需要一个简单的分类名 name 就可以了。</span></span><br><span class="line"><span class="string">        CharField 指定了分类名 name 的数据类型，CharField 是字符型，</span></span><br><span class="line"><span class="string">        CharField 的 max_length 参数指定其最大长度，超过这个长度的分类名就不能被存入数据库。</span></span><br><span class="line"><span class="string">        当然 Django 还为我们提供了多种其它的数据类型，如日期时间类型 DateTimeField、整数类型 IntegerField 等等。</span></span><br><span class="line"><span class="string">        Django 内置的全部类型可查看文档：</span></span><br><span class="line"><span class="string">        https://docs.djangoproject.com/en/1.10/ref/models/fields/#field-types</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">    name = models.CharField(max_length=<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">catcount</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> Articles.objects.filter(category__name__exact=self.name).filter(status=<span class="string">'有效'</span>).count()</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tag</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        标签 Tag 也比较简单，和 Category 一样。</span></span><br><span class="line"><span class="string">        再次强调一定要继承 models.Model 类！</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">    name = models.CharField(max_length=<span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Articles</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    id = models.AutoField(primary_key=<span class="literal">True</span>)  <span class="comment"># id</span></span><br><span class="line">    title = models.CharField(max_length=<span class="number">150</span>)  <span class="comment"># 博客标题</span></span><br><span class="line">    body = models.TextField()  <span class="comment"># 博客正文</span></span><br><span class="line">    timestamp = models.DateTimeField()  <span class="comment"># 创建时间</span></span><br><span class="line">    authorname = models.ForeignKey(<span class="string">'JiaBlog.BlogUser'</span>, on_delete=models.CASCADE)  <span class="comment"># 作者姓名</span></span><br><span class="line">    views = models.PositiveIntegerField(default=<span class="number">0</span>)</span><br><span class="line">    category = models.ForeignKey(Category, on_delete=models.CASCADE, primary_key=<span class="literal">False</span>)</span><br><span class="line">    tags = models.ManyToManyField(Tag, blank=<span class="literal">True</span>, null=<span class="literal">True</span>)</span><br><span class="line">    greats = models.PositiveIntegerField(default=<span class="number">0</span>)</span><br><span class="line">    comments = models.IntegerField(default=<span class="number">0</span>)</span><br><span class="line">    status = models.CharField(max_length=<span class="number">20</span>, default=<span class="string">"DEL"</span>)</span><br><span class="line">    brief = models.CharField(max_length=<span class="number">200</span>, blank=<span class="literal">True</span>, null=<span class="literal">True</span>)</span><br><span class="line">    pic = models.ImageField(upload_to=<span class="string">'jiablogimages'</span>)</span><br><span class="line">    <span class="comment"># bodypic = models.ImageField(upload_to='jiablogimages', blank=True, null=True)</span></span><br><span class="line">    istop = models.CharField(max_length=<span class="number">5</span>, default=<span class="string">''</span>, null=<span class="literal">True</span>, blank=<span class="literal">True</span>)</span><br><span class="line">    articlebodybrief = models.TextField(blank=<span class="literal">True</span>, null=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>views.py<br>这里的source对应的是字段名<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticlesSerializers</span><span class="params">(serializers.ModelSerializer)</span>:</span></span><br><span class="line">    authorname = serializers.CharField(source=<span class="string">'authorname.name'</span>)</span><br><span class="line">    category = serializers.CharField(source=<span class="string">'category.name'</span>)</span><br><span class="line">    tags = serializers.StringRelatedField(many=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Meta</span>:</span></span><br><span class="line">        model = Articles  <span class="comment"># 指定的模型类</span></span><br><span class="line">        fields = (<span class="string">'id'</span>, <span class="string">'title'</span>, <span class="string">'body'</span>, <span class="string">'timestamp'</span>, <span class="string">'authorname'</span>, <span class="string">'views'</span>, <span class="string">'tags'</span>, <span class="string">'category'</span>)  <span class="comment"># 需要序列化的属性</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>python</tag>
        <tag>restframework</tag>
      </tags>
  </entry>
  <entry>
    <title>Learn-Pytorch-使用LSTM预测航班客流量</title>
    <url>/2019/12/08/Learn-Pytorch-%E4%BD%BF%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E8%88%AA%E7%8F%AD%E5%AE%A2%E6%B5%81%E9%87%8F/</url>
    <content><![CDATA[<p>本文会详细讲解如何使用Pytorch预测航班客流量，包括数据的处理、网络的结构<br><a id="more"></a></p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data_csv = pd.read_csv(<span class="string">'airline-passengers.csv'</span>,usecols=[<span class="number">1</span>])</span><br><span class="line">plt.plot(data_csv)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果如下<br><img src="https://www.guanacossj.com/media/articlebodypics/1575815313343.jpg" alt=""><br>这里是真实的数据，接下来我们对数据进行预处理<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">data_csv = data_csv.dropna()    <span class="comment"># 滤除缺失数据</span></span><br><span class="line">dataset = data_csv.values       <span class="comment"># 获得csv的值</span></span><br><span class="line">print((dataset,type(dataset),dataset.shape))</span><br><span class="line">dataset = dataset.astype(<span class="string">'float32'</span>)</span><br><span class="line">max_value = np.max(dataset)     <span class="comment"># 获得最大值</span></span><br><span class="line">min_value = np.min(dataset)     <span class="comment"># 获得最小值</span></span><br><span class="line">scalar = max_value - min_value  <span class="comment"># 获得间隔数量</span></span><br><span class="line">dataset = list(map(<span class="keyword">lambda</span> x: x / scalar, dataset)) <span class="comment"># 归一化</span></span><br></pre></td></tr></table></figure><br>可以看一下最后处理完成的dataset，是一个list<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[0.21621622] [0.22779922] [0.25482625]...</span><br></pre></td></tr></table></figure><br>创建输入输出，这里使用当前时间的前两个时刻<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(dataset, look_back=<span class="number">2</span>)</span>:</span></span><br><span class="line">    dataX, dataY = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset) - look_back):</span><br><span class="line">        a = dataset[i:(i + look_back)]</span><br><span class="line">        dataX.append(a)</span><br><span class="line">        dataY.append(dataset[i + look_back])</span><br><span class="line">    <span class="keyword">return</span> np.array(dataX), np.array(dataY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_X, data_Y = create_dataset(dataset)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>lstm</tag>
      </tags>
  </entry>
  <entry>
    <title>Learn-Pytorch-用Pytorch写一个神经网络</title>
    <url>/2019/12/07/Learn-Pytorch-%E7%94%A8Pytorch%E5%86%99%E4%B8%80%E4%B8%AA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p>本文将用Pytorch构建一个最简单的线性神经网络，练习Pytorch中神经网络模型的保存和重载<br><a id="more"></a></p>
<h4 id="定义一个线性神经网络"><a href="#定义一个线性神经网络" class="headerlink" title="定义一个线性神经网络"></a>定义一个线性神经网络</h4><script type="math/tex; mode=display">
y = wx + b</script><p>这是一个基本的网络Net，它只包含一个全连接层<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net,self).__init__()</span><br><span class="line">        self.layer = nn.Linear(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        self.layer.weight = nn.Parameter(torch.FloatTensor([[<span class="number">10</span>]]))</span><br><span class="line">        self.layer.bias = nn.Parameter(torch.FloatTensor([<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        y = self.layer(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>]])</span><br><span class="line">net = Net()</span><br><span class="line">linearout = net(x)</span><br><span class="line">print(linearout)</span><br></pre></td></tr></table></figure><br>这里假设输入x=1<br>y的值应为11<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tensor([[11.]], grad_fn=&lt;AddmmBackward&gt;)</span><br></pre></td></tr></table></figure></p>
<h4 id="保存Net的参数值"><a href="#保存Net的参数值" class="headerlink" title="保存Net的参数值"></a>保存Net的参数值</h4><p>查看网络的状态字典<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(net.state_dict())</span><br></pre></td></tr></table></figure><br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">OrderedDict([('layer.weight', tensor([[10.]])), ('layer.bias', tensor([1.]))])</span><br></pre></td></tr></table></figure><br>保存状态字典<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(obj=net.state_dict(), f=<span class="string">"models/net.pth"</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="加载Net参数值并用于新的模型"><a href="#加载Net参数值并用于新的模型" class="headerlink" title="加载Net参数值并用于新的模型"></a>加载Net参数值并用于新的模型</h4><p>重新定义一个相同结构的模型NewNet<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net,self).__init__()</span><br><span class="line">        self.layer = nn.Linear(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        self.layer.weight = nn.Parameter(torch.FloatTensor([[<span class="number">10</span>]]))</span><br><span class="line">        self.layer.bias = nn.Parameter(torch.FloatTensor([<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        y = self.layer(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NewNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(NewNet, self).__init__()</span><br><span class="line">        self.layer = nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.layer.weight = nn.Parameter(torch.FloatTensor([[<span class="number">0</span>]]))</span><br><span class="line">        self.layer.bias = nn.Parameter(torch.FloatTensor([<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.layer(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>]])</span><br><span class="line">net = NewNet()</span><br><span class="line">print(net.state_dict())                             <span class="comment"># 初始的NewNet的状态字典</span></span><br><span class="line">net.load_state_dict(torch.load(<span class="string">"models/net.pth"</span>))</span><br><span class="line">print(net.state_dict())                             <span class="comment"># 加载参数值的NewNet的状态字典</span></span><br></pre></td></tr></table></figure><br>net的w和b值就不再是0了，而是之前保存的模型中w和b对应的10和1<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">OrderedDict([('layer.weight', tensor([[0.]])), ('layer.bias', tensor([0.]))])</span><br><span class="line">OrderedDict([('layer.weight', tensor([[10.]])), ('layer.bias', tensor([1.]))])</span><br></pre></td></tr></table></figure></p>
<h4 id="优化器与epoch的保存"><a href="#优化器与epoch的保存" class="headerlink" title="优化器与epoch的保存"></a>优化器与epoch的保存</h4><p>保存优化器参数值和epoch值的主要目的是用于继续训练，保存的流程依旧是先“torch.save()”再“torch.load_state_dict()”<br>我们首先定义一个Adam优化器、一个任意的epoch值与net如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mport torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn,optim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net,self).__init__()</span><br><span class="line">        self.layer = nn.Linear(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        self.layer.weight = nn.Parameter(torch.FloatTensor([[<span class="number">10</span>]]))</span><br><span class="line">        self.layer.bias = nn.Parameter(torch.FloatTensor([<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        y = self.layer(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">Adam = optim.Adam(params=net.parameters(), lr=<span class="number">0.001</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">epoch = <span class="number">50</span></span><br><span class="line">all_states = &#123;<span class="string">"net"</span>: net.state_dict(), <span class="string">"Adam"</span>: Adam.state_dict(), <span class="string">"epoch"</span>: epoch&#125;</span><br><span class="line">torch.save(obj=all_states, f=<span class="string">"models/all_states.pth"</span>)</span><br></pre></td></tr></table></figure><br>查看模型所有的参数<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">all_states = torch.load(<span class="string">"models/all_states.pth"</span>)</span><br><span class="line">print(all_states)</span><br></pre></td></tr></table></figure><br><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	'net': OrderedDict([('layer.weight', tensor([[10.]])), ('layer.bias', tensor([1.]))]),</span><br><span class="line">	'Adam': &#123;</span><br><span class="line">		'state': &#123;&#125;,</span><br><span class="line">		'param_groups': [&#123;</span><br><span class="line">			'lr': 0.001,</span><br><span class="line">			'betas': (0.5, 0.999),</span><br><span class="line">			'eps': 1e-08,</span><br><span class="line">			'weight_decay': 0,</span><br><span class="line">			'amsgrad': False,</span><br><span class="line">			'params': [4660776392, 4559888248]</span><br><span class="line">		&#125;]</span><br><span class="line">	&#125;,</span><br><span class="line">	'epoch': 50</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>2019/12/06周报-单沙嘉</title>
    <url>/2019/12/06/2019-12-06%E5%91%A8%E6%8A%A5-%E5%8D%95%E6%B2%99%E5%98%89/</url>
    <content><![CDATA[<p>Nothing<br><a id="more"></a></p>
<h3 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h3><p>11.11-11.15<br>40万</p>
<h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cpu.all.usage.percent</span><br><span class="line">memory.used.percent</span><br><span class="line">interface.eth0.if_octets.rx</span><br><span class="line">interface.eth0.if_octets.tx</span><br><span class="line">disk.vda.disk_octets.write</span><br><span class="line">disk.vda.disk_octets.read</span><br></pre></td></tr></table></figure>
<h3 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h3><p>epoch = 200<br>bach_size = 72<br>BiLSTM + Attention</p>
<h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p><img src="https://www.guanacossj.com/media/articlebodypics/1575621413951.jpg" alt=""><br><img src="https://www.guanacossj.com/media/articlebodypics/1575621002903.jpg" alt=""><br><img src="https://www.guanacossj.com/media/articlebodypics/1575627714970.jpg" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>epoch 不够多</p>
]]></content>
      <categories>
        <category>周报</category>
      </categories>
  </entry>
  <entry>
    <title>Keras以及Tensorflow强制使用GPU</title>
    <url>/2019/12/06/Keras%E4%BB%A5%E5%8F%8ATensorflow%E5%BC%BA%E5%88%B6%E4%BD%BF%E7%94%A8GPU/</url>
    <content><![CDATA[<p>本文主要介绍在tensorflow2.0下如何强制使用GPU，方法一在tensorflow1.x版本中失效<br><a id="more"></a></p>
<h3 id="环境：python3-6-tensorflow-2-0-keras2-3-1"><a href="#环境：python3-6-tensorflow-2-0-keras2-3-1" class="headerlink" title="环境：python3.6+tensorflow==2.0+keras2.3.1"></a>环境：python3.6+tensorflow==2.0+keras2.3.1</h3><h3 id="方法一："><a href="#方法一：" class="headerlink" title="方法一："></a>方法一：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras.backend.tensorflow_backend <span class="keyword">as</span> KTF</span><br><span class="line"> </span><br><span class="line">KTF.set_session(tf.Session(config=tf.ConfigProto(device_count=&#123;<span class="string">'gpu'</span>:<span class="number">0</span>&#125;)))</span><br></pre></td></tr></table></figure>
<p>这里在tensorflow2.0中肯定报错<br>修改如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras.backend.tensorflow_backend <span class="keyword">as</span> KTF</span><br><span class="line"> </span><br><span class="line">KTF.set_session(tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(device_count=&#123;<span class="string">'gpu'</span>:<span class="number">0</span>&#125;)))</span><br></pre></td></tr></table></figure><br>然而这样还是不行，就是告诉你tensorflow2.0中不能这样用<br>遂放弃</p>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 python3 xxx.py</span><br></pre></td></tr></table></figure>
<p>貌似可行<br><img src="https://www.guanacossj.com/media/articlebodypics/1575618190733.jpg" alt=""></p>
]]></content>
      <tags>
        <tag>keras</tag>
        <tag>tensorflow</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode[840]Magic-Squares-In-Grid</title>
    <url>/2019/12/04/Leetcode840Magic-Squares-In-Grid/</url>
    <content><![CDATA[<p>python3暴力解，不难看懂<br><a id="more"></a><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numMagicSquaresInside</span><span class="params">(self, grid)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type grid: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        grids = self.generate_matrix(grid)</span><br><span class="line"></span><br><span class="line">        count  = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> grids:</span><br><span class="line">            <span class="keyword">if</span> self.checkmagic(i) == <span class="literal">True</span> <span class="keyword">and</span> self.checksame(i) == <span class="literal">True</span>:</span><br><span class="line">                count = count + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate_matrix</span><span class="params">(self, grid)</span>:</span></span><br><span class="line">        all = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成所有矩阵组合</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(len(grid[<span class="number">0</span>])<span class="number">-2</span>):</span><br><span class="line">            temmatrix = []</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> range(len(grid)<span class="number">-2</span>):</span><br><span class="line">                tem = []</span><br><span class="line">                tem.append(grid[m][n:n + <span class="number">3</span>])</span><br><span class="line">                tem.append(grid[m + <span class="number">1</span>][n:n + <span class="number">3</span>])</span><br><span class="line">                tem.append(grid[m + <span class="number">2</span>][n:n + <span class="number">3</span>])</span><br><span class="line">                temmatrix.append(tem)</span><br><span class="line">            <span class="keyword">for</span> o <span class="keyword">in</span> range(len(temmatrix)):</span><br><span class="line">                all.append(temmatrix[o])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> all</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">checksame</span><span class="params">(self,matrix)</span>:</span></span><br><span class="line">        l = len(matrix)</span><br><span class="line">        flag = <span class="literal">True</span></span><br><span class="line">        tem = []</span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> range(l):</span><br><span class="line">            <span class="keyword">for</span> h <span class="keyword">in</span> range(l):</span><br><span class="line">                tem.append(matrix[g][h])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> tem:</span><br><span class="line">            <span class="keyword">if</span> i &gt;= <span class="number">10</span>:</span><br><span class="line">                flag = <span class="literal">False</span>        </span><br><span class="line">        <span class="keyword">if</span> len(set(tem)) == <span class="number">1</span>:</span><br><span class="line">            flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> flag</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">checkmagic</span><span class="params">(self, matrix)</span>:</span></span><br><span class="line">        l = len(matrix)</span><br><span class="line"></span><br><span class="line">        flag = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 斜</span></span><br><span class="line">        tmp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(l):</span><br><span class="line">            tmp += matrix[i][i]</span><br><span class="line">        <span class="keyword">if</span> tmp != <span class="number">15</span>:</span><br><span class="line">            flag = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 行</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(l):</span><br><span class="line">            tmp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(l):</span><br><span class="line">                tmp += matrix[i][j]</span><br><span class="line">            <span class="keyword">if</span> tmp != <span class="number">15</span>:</span><br><span class="line">                flag = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 列</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(l):</span><br><span class="line">            tmp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(l):</span><br><span class="line">                tmp += matrix[j][i]</span><br><span class="line">            <span class="keyword">if</span> tmp != <span class="number">15</span>:</span><br><span class="line">                flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> flag</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    Solution().numMagicSquaresInside(</span><br><span class="line">        [[<span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">4</span>],</span><br><span class="line">         [<span class="number">9</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">9</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">2</span>]]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>Learn-Pytorch-基本数据类型</title>
    <url>/2019/12/03/Learn-Pytorch-%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<p>本文主要介绍pytoch和numpy的数据之间的转化和pytorch中张量tensor的使用<br><a id="more"></a></p>
<h4 id="使用numpy新建一个一维数组"><a href="#使用numpy新建一个一维数组" class="headerlink" title="使用numpy新建一个一维数组"></a>使用numpy新建一个一维数组</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np_data = np.arange(<span class="number">6</span>)</span><br><span class="line">print(np_data,type(np_data))</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[0 1 2 3 4 5] &lt;class 'numpy.ndarray'&gt;</span><br></pre></td></tr></table></figure>
<h4 id="把数组转化为二维"><a href="#把数组转化为二维" class="headerlink" title="把数组转化为二维"></a>把数组转化为二维</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np_data = np.arange(<span class="number">6</span>)</span><br><span class="line">print(np_data,type(np_data))</span><br><span class="line">np_data = np_data.reshape((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">print(np_data,type(np_data))</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[0 1 2 3 4 5] &lt;class 'numpy.ndarray'&gt;</span><br><span class="line">[[0 1 2]</span><br><span class="line"> [3 4 5]] &lt;class 'numpy.ndarray'&gt;</span><br></pre></td></tr></table></figure>
<p>这个时候可以看到，数组变为二维的了，两行三列</p>
<h4 id="把二维数组转化为tensor"><a href="#把二维数组转化为tensor" class="headerlink" title="把二维数组转化为tensor"></a>把二维数组转化为tensor</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np_data = np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">torch_data = torch.from_numpy(np_data)</span><br><span class="line">print(</span><br><span class="line">    <span class="string">'\nnumpy:'</span>, np_data,</span><br><span class="line">    <span class="string">'\ntorch:'</span>, torch_data,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">numpy: [[0 1 2]</span><br><span class="line"> [3 4 5]] </span><br><span class="line">torch: tensor([[0, 1, 2],</span><br><span class="line">        [3, 4, 5]])</span><br></pre></td></tr></table></figure>
<h4 id="把tensor转为数组"><a href="#把tensor转为数组" class="headerlink" title="把tensor转为数组"></a>把tensor转为数组</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np_data = np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">torch_data = torch.from_numpy(np_data)</span><br><span class="line">tensor2array = torch_data.numpy()</span><br><span class="line">print(</span><br><span class="line">    <span class="string">'\nnumpy:'</span>, np_data,</span><br><span class="line">    <span class="string">'\ntorch:'</span>, torch_data,</span><br><span class="line">    <span class="string">'\ntensor2array'</span>, tensor2array,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">numpy: [[0 1 2]</span><br><span class="line"> [3 4 5]] </span><br><span class="line">torch: tensor([[0, 1, 2],</span><br><span class="line">        [3, 4, 5]]) </span><br><span class="line">tensor2array [[0 1 2]</span><br><span class="line"> [3 4 5]]</span><br></pre></td></tr></table></figure>
<h4 id="随机创建一个二维tensor"><a href="#随机创建一个二维tensor" class="headerlink" title="随机创建一个二维tensor"></a>随机创建一个二维tensor</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch_data = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">print(</span><br><span class="line">    <span class="string">'\ntorch_data:'</span>,torch_data</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">torch_data: tensor([[ 0.1533, -0.1010,  1.8385],</span><br><span class="line">        [-1.0455,  0.3707,  0.0191]])</span><br></pre></td></tr></table></figure>
<h4 id="构造初始化为0，1的tensor"><a href="#构造初始化为0，1的tensor" class="headerlink" title="构造初始化为0，1的tensor"></a>构造初始化为0，1的tensor</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch_data_0 = torch.zeros(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">torch_data_1 = torch.ones(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">print(</span><br><span class="line">    <span class="string">'\ntorch_data_0:'</span>,torch_data_0,</span><br><span class="line">    <span class="string">'\ntorch_data_1:'</span>,torch_data_1,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">torch_data_0: tensor([[0., 0., 0.],</span><br><span class="line">        [0., 0., 0.]]) </span><br><span class="line">torch_data_1: tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]])</span><br></pre></td></tr></table></figure>
<h4 id="从python列表直接构造tensor"><a href="#从python列表直接构造tensor" class="headerlink" title="从python列表直接构造tensor"></a>从python列表直接构造tensor</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch_data_from_list = torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">print(</span><br><span class="line">    <span class="string">'\ntorch_data_from_list:'</span>,torch_data_from_list,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">torch_data_from_list: tensor([[1., 2., 3.],</span><br><span class="line">        [4., 5., 6.]])</span><br></pre></td></tr></table></figure>
<p>需要注意的是，在pytorch中，默认的数据类型就是torch.FloatTensor，所以在这里torch.FloatTensor就等于torch.Tensor<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch_data_from_list = torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">torch_data_from_list_32 = torch.FloatTensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">print(</span><br><span class="line">    <span class="string">'\ntorch_data_from_list:'</span>,torch_data_from_list,</span><br><span class="line">    <span class="string">'\ntorch_data_from_list_32'</span>,torch_data_from_list_32</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">torch_data_from_list: tensor([[1., 2., 3.],</span><br><span class="line">        [4., 5., 6.]]) </span><br><span class="line">torch_data_from_list_32 tensor([[1., 2., 3.],</span><br><span class="line">        [4., 5., 6.]])</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch中的LSTM的理解</title>
    <url>/2019/12/03/Pytorch%E4%B8%AD%E7%9A%84LSTM%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>本文转载于<a href="https://zhuanlan.zhihu.com/p/41261640" target="_blank" rel="noopener" title="https://zhuanlan.zhihu.com/p/41261640">https://zhuanlan.zhihu.com/p/41261640</a><br><a id="more"></a></p>
<h4 id="参数列表"><a href="#参数列表" class="headerlink" title="参数列表"></a>参数列表</h4><ul>
<li>input_size：x的特征维度</li>
<li>hidden_size：隐藏层的特征维度</li>
<li>num_layers：lstm隐层的层数，默认为1</li>
<li>bias：False则bih=0和bhh=0. 默认为True</li>
<li>batch_first：True则输入输出的数据格式为 (batch, seq, feature)</li>
<li>dropout：除最后一层，每一层的输出都进行dropout，默认为: 0</li>
<li>bidirectional：True则为双向lstm默认为False</li>
<li>输入：input, (h0, c0)</li>
<li>输出：output, (hn,cn)</li>
</ul>
<h4 id="输入数据格式"><a href="#输入数据格式" class="headerlink" title="输入数据格式"></a>输入数据格式</h4><ul>
<li>input(seq_len, batch, input_size)</li>
<li>h0(num_layers * num_directions, batch, hidden_size)</li>
<li>c0(num_layers * num_directions, batch, hidden_size)</li>
</ul>
<h4 id="输出数据格式："><a href="#输出数据格式：" class="headerlink" title="输出数据格式："></a>输出数据格式：</h4><ul>
<li>output(seq_len, batch, hidden_size * num_directions)</li>
<li>hn(num_layers * num_directions, batch, hidden_size)</li>
<li>cn(num_layers * num_directions, batch, hidden_size)</li>
</ul>
<p>Pytorch里的LSTM单元接受的输入都必须是3维的张量(Tensors).每一维代表的意思不能弄错。</p>
<p>第一维体现的是序列（sequence）结构,也就是序列的个数，用文章来说，就是每个句子的长度，因为是喂给网络模型，一般都设定为确定的长度，也就是我们喂给LSTM神经元的每个句子的长度，当然，如果是其他的带有带有序列形式的数据，则表示一个明确分割单位长度，</p>
<p>例如是如果是股票数据内，这表示特定时间单位内，有多少条数据。这个参数也就是明确这个层中有多少个确定的单元来处理输入的数据。</p>
<p>第二维度体现的是batch_size，也就是一次性喂给网络多少条句子，或者股票数据中的，一次性喂给模型多少是个时间单位的数据，具体到每个时刻，也就是一次性喂给特定时刻处理的单元的单词数或者该时刻应该喂给的股票数据的条数</p>
<p>第三位体现的是输入的元素（elements of input），也就是，每个具体的单词用多少维向量来表示，或者股票数据中 每一个具体的时刻的采集多少具体的值，比如最低价，最高价，均价，5日均价，10均价，等等</p>
<p>H0-Hn是什么意思呢？就是每个时刻中间神经元应该保存的这一时刻的根据输入和上一课的时候的中间状态值应该产生的本时刻的状态值，</p>
<p>这个数据单元是起的作用就是记录这一时刻之前考虑到所有之前输入的状态值，形状应该是和特定时刻的输出一致</p>
<p>c0-cn就是开关，决定每个神经元的隐藏状态值是否会影响的下一时刻的神经元的处理，形状应该和h0-hn一致。</p>
<p>当然如果是双向，和多隐藏层还应该考虑方向和隐藏层的层数。</p>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>lstm</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode[27]Remove Element</title>
    <url>/2019/12/02/Leetcode27Remove-Element/</url>
    <content><![CDATA[<p>leetcode上一道简单题27.移除元素，给定一个数组 nums 和一个值 val，你需要原地移除所有数值等于 val 的元素，返回移除后数组的新长度。<br><a id="more"></a><br>比较常规的想法<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeElement</span><span class="params">(self, nums, val)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type val: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        k = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> i != val:</span><br><span class="line">                nums[k] = i</span><br><span class="line">                k += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> k</span><br></pre></td></tr></table></figure><br>其实python自带的pop方法也很好用<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeElement</span><span class="params">(self, nums, val)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type val: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># k = 0</span></span><br><span class="line">        <span class="comment"># for i in nums:</span></span><br><span class="line">        <span class="comment">#     if i != val:</span></span><br><span class="line">        <span class="comment">#         nums[k] = i</span></span><br><span class="line">        <span class="comment">#         k += 1</span></span><br><span class="line">        <span class="comment"># return k</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == val:</span><br><span class="line">                nums.pop(i)</span><br><span class="line">        <span class="keyword">return</span> len(nums)</span><br></pre></td></tr></table></figure><br>那为啥一定要逆向呢？正向不可以么？还真不行，因为这个循环的i是固定的，假设列表为[3,2,3,1,4,6,3,1]，需要移除的元素是3，正向是从0,1,…,7,当移除至少一个元素后，就无法访问下标为7的元素，因为不存在了，而逆向是7,6,…0，这个时候，下标是递减的，即使被pop了，接下来访问的都是比它小的下标，一定存在。</p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>list</tag>
        <tag>pop</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>python列表推导式及其简单应用</title>
    <url>/2019/12/02/python%E5%88%97%E8%A1%A8%E6%8E%A8%E5%AF%BC%E5%BC%8F%E5%8F%8A%E5%85%B6%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<p>列表推导式（又称列表解析式）提供了一种简明扼要的方法来创建列表<br><a id="more"></a></p>
<h4 id="一个简单平方"><a href="#一个简单平方" class="headerlink" title="一个简单平方"></a>一个简单平方</h4><p>普通for循环<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">    print(i*i,end=<span class="string">''</span>)</span><br></pre></td></tr></table></figure><br>列表推导式<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = [x*x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>)]</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure></p>
<h4 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[x*y <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>) <span class="keyword">if</span> x &gt; <span class="number">2</span> <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">4</span>) <span class="keyword">if</span> y &lt; <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>等价于<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">4</span>):</span><br><span class="line">            <span class="keyword">if</span> y &lt; <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> x*y</span><br></pre></td></tr></table></figure></p>
<h4 id="leetcode17电话号码的字母组合"><a href="#leetcode17电话号码的字母组合" class="headerlink" title="leetcode17电话号码的字母组合"></a>leetcode17电话号码的字母组合</h4><p>给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。<br>给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。<br><img src="https://www.guanacossj.com/media/articlebodypics/17_telephone_keypad.png" alt=""><br>这题看起来递归比较合适，但是强行循环也不是不可以<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">letterCombinations</span><span class="params">(self, digits)</span>:</span></span><br><span class="line">        m = &#123;</span><br><span class="line">            <span class="string">'2'</span>: list(<span class="string">'abc'</span>),</span><br><span class="line">            <span class="string">'3'</span>: list(<span class="string">'def'</span>),</span><br><span class="line">            <span class="string">'4'</span>: list(<span class="string">'ghi'</span>),</span><br><span class="line">            <span class="string">'5'</span>: list(<span class="string">'jkl'</span>),</span><br><span class="line">            <span class="string">'6'</span>: list(<span class="string">'mno'</span>),</span><br><span class="line">            <span class="string">'7'</span>: list(<span class="string">'pqrs'</span>),</span><br><span class="line">            <span class="string">'8'</span>: list(<span class="string">'tuv'</span>),</span><br><span class="line">            <span class="string">'9'</span>: list(<span class="string">'wxyz'</span>),</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> digits:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        res = [<span class="string">''</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> digits:</span><br><span class="line">            res = [x + y <span class="keyword">for</span> x <span class="keyword">in</span> res <span class="keyword">for</span> y <span class="keyword">in</span> m[i]]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><br>这里的循环其实不止两层，取决于你输入的数字的位数。可以打印输出看一下，假设输入的数字是234<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">['a', 'b', 'c']</span><br><span class="line">['ad', 'ae', 'af', 'bd', 'be', 'bf', 'cd', 'ce', 'cf']</span><br><span class="line">['adg', 'adh', 'adi', 'aeg', 'aeh', 'aei', 'afg', 'afh', 'afi', 'bdg', 'bdh', 'bdi', 'beg', 'beh', 'bei', 'bfg', 'bfh', 'bfi', 'cdg', 'cdh', 'cdi', 'ceg', 'ceh', 'cei', 'cfg', 'cfh', 'cfi']</span><br></pre></td></tr></table></figure><br>第一个2对应的字母是[‘a’, ‘b’, ‘c’]<br>第二个3对于的字母是[‘d’, ‘e’, ‘f’]<br>第三个4对于的字母是[‘g’, ‘h’, ‘i’]<br>开始的时候res长度为1，可以理解为<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = [<span class="string">''</span>]</span><br><span class="line">m = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> res:</span><br><span class="line">    tem = []</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> m:</span><br><span class="line">        res = x + y</span><br><span class="line">        tem.append(res)</span><br><span class="line">    print(tem)</span><br></pre></td></tr></table></figure><br>当有两个数字时<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = [<span class="string">''</span>]</span><br><span class="line">m = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line">n = [<span class="string">'d'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>]</span><br><span class="line">tem = []</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> res:</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> m:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> n:</span><br><span class="line">            res = x + y + k</span><br><span class="line">            tem.append(res)</span><br><span class="line">    print(tem)</span><br></pre></td></tr></table></figure><br>这样一层一层加下去就可以，不过即使知道要循环几次，也很难表达出来，这个时候用列表推导式就很方便</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>列表推导式</tag>
      </tags>
  </entry>
  <entry>
    <title>Flask-Vue前后端分离（一）</title>
    <url>/2019/11/30/Flask-Vue%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>简单介绍下如何在Pycharm下集成Flask和Vue<br><a id="more"></a></p>
<h4 id="新建flask项目"><a href="#新建flask项目" class="headerlink" title="新建flask项目"></a>新建flask项目</h4><p>略<br>我这里是Jia-Prophet</p>
<h4 id="新建vue项目"><a href="#新建vue项目" class="headerlink" title="新建vue项目"></a>新建vue项目</h4><p>在Jia-Prophet目录下<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vue init webpack jia-vue</span><br></pre></td></tr></table></figure><br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Arithmetic@qingjiaowosuanshujiadeMacBook-Pro Jia-Prophet % vue init webpack jia-vue</span><br><span class="line"></span><br><span class="line">? Project name jia-vue</span><br><span class="line">? Project description A Vue.js project</span><br><span class="line">? Author ArithmeticJia &lt;1097197237@qq.com&gt;</span><br><span class="line">? Vue build standalone</span><br><span class="line">? Install vue-router? Yes</span><br><span class="line">? Use ESLint to lint your code? No</span><br><span class="line">? Set up unit tests No</span><br><span class="line">? Setup e2e tests with Nightwatch? No</span><br><span class="line">? Should we run `npm install` for you after the project has been created? (recommended) n</span><br><span class="line">pm</span><br><span class="line"></span><br><span class="line">   vue-cli · Generated "jia-vue".</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Installing project dependencies ...</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ========================</span></span><br><span class="line"></span><br><span class="line">npm WARN deprecated extract-text-webpack-plugin@3.0.2: Deprecated. Please use https://github.com/webpack-contrib/mini-css-extract-plugin</span><br><span class="line">npm WARN deprecated browserslist@2.11.3: Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.</span><br><span class="line">npm WARN deprecated bfj-node4@5.3.1: Switch to the `bfj` package for fixes and new features!</span><br><span class="line">npm WARN deprecated core-js@2.6.10: core-js@&lt;3.0 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.</span><br><span class="line">npm WARN deprecated fsevents@1.2.9: One of your dependencies needs to upgrade to fsevents v2: 1) Proper nodejs v10+ support 2) No more fetching binaries from AWS, smaller package size</span><br><span class="line">npm WARN deprecated browserslist@1.7.7: Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> fsevents@1.2.9 install /Users/Arithmetic/PycharmProjects/Jia/Jia-Prophet/jia-vue/node_modules/fsevents</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> node install</span></span><br><span class="line"></span><br><span class="line">node-pre-gyp WARN Using needle for node-pre-gyp https download </span><br><span class="line">[fsevents] Success: "/Users/Arithmetic/PycharmProjects/Jia/Jia-Prophet/jia-vue/node_modules/fsevents/lib/binding/Release/node-v72-darwin-x64/fse.node" is installed via remote</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> core-js@2.6.10 postinstall /Users/Arithmetic/PycharmProjects/Jia/Jia-Prophet/jia-vue/node_modules/core-js</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> node postinstall || <span class="built_in">echo</span> <span class="string">"ignore"</span></span></span><br><span class="line"></span><br><span class="line">Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library!</span><br><span class="line"></span><br><span class="line">The project needs your help! Please consider supporting of core-js on Open Collective or Patreon: </span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> https://opencollective.com/core-js </span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> https://www.patreon.com/zloirock </span></span><br><span class="line"></span><br><span class="line">Also, the author of core-js ( https://github.com/zloirock ) is looking for a good job -)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> ejs@2.7.4 postinstall /Users/Arithmetic/PycharmProjects/Jia/Jia-Prophet/jia-vue/node_modules/ejs</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> node ./postinstall.js</span></span><br><span class="line"></span><br><span class="line">Thank you for installing EJS: built with the Jake JavaScript build tool (https://jakejs.com/)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> uglifyjs-webpack-plugin@0.4.6 postinstall /Users/Arithmetic/PycharmProjects/Jia/Jia-Prophet/jia-vue/node_modules/webpack/node_modules/uglifyjs-webpack-plugin</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> node lib/post_install.js</span></span><br><span class="line"></span><br><span class="line">npm notice created a lockfile as package-lock.json. You should commit this file.</span><br><span class="line">npm WARN ajv-keywords@3.4.1 requires a peer of ajv@^6.9.1 but none is installed. You must install peer dependencies yourself.</span><br><span class="line"></span><br><span class="line">added 1284 packages from 686 contributors and audited 11868 packages in 47.259s</span><br><span class="line"></span><br><span class="line">11 packages are looking for funding</span><br><span class="line">  run `npm fund` for details</span><br><span class="line"></span><br><span class="line">found 11 vulnerabilities (1 low, 6 moderate, 4 high)</span><br><span class="line">  run `npm audit fix` to fix them, or `npm audit` for details</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Project initialization finished!</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ========================</span></span><br><span class="line"></span><br><span class="line">To get started:</span><br><span class="line"></span><br><span class="line">  cd jia-vue</span><br><span class="line">  npm run dev</span><br><span class="line">  </span><br><span class="line">Documentation can be found at https://vuejs-templates.github.io/webpack</span><br></pre></td></tr></table></figure><br>然后执行<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cnpm run build</span><br><span class="line">cnpm run dev</span><br></pre></td></tr></table></figure><br>这里我之前换成淘宝源了，详见之前的教程<br>如果没有问题的话，访问 <a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a><br><img src="https://www.guanacossj.com/media/articlebodypics/1575129241168.jpg" alt=""></p>
<h4 id="修改编译生成的静态文件"><a href="#修改编译生成的静态文件" class="headerlink" title="修改编译生成的静态文件"></a>修改编译生成的静态文件</h4><p>找到jia-vue/config/index.js文件，修改如下：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">build: &#123;</span><br><span class="line">    // Template for index.html</span><br><span class="line">    index: path.resolve(__dirname, '../../templates/index.html'), //这里是index.html生成的路径，在templates下</span><br><span class="line"></span><br><span class="line">    // Paths</span><br><span class="line">    assetsRoot: path.resolve(__dirname, '../../static'), //这里指定vue生成的js和css文件路径为/static/vue/</span><br><span class="line">    assetsSubDirectory: 'vue',</span><br><span class="line">    assetsPublicPath: '/static',</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Source Maps</span><br><span class="line">     */</span><br><span class="line"></span><br><span class="line">    productionSourceMap: true,</span><br><span class="line">    // https://webpack.js.org/configuration/devtool/#production</span><br><span class="line">    devtool: '#source-map',</span><br><span class="line"></span><br><span class="line">    // Gzip off by default as many popular static hosts such as</span><br><span class="line">    // Surge or Netlify already gzip all static assets for you.</span><br><span class="line">    // Before setting to `true`, make sure to:</span><br><span class="line">    // npm install --save-dev compression-webpack-plugin</span><br><span class="line">    productionGzip: false,</span><br><span class="line">    productionGzipExtensions: ['js', 'css'],</span><br><span class="line"></span><br><span class="line">    // Run the build command with an extra argument to</span><br><span class="line">    // View the bundle analyzer report after build finishes:</span><br><span class="line">    // `npm run build --report`</span><br><span class="line">    // Set to `true` or `false` to always turn it on or off</span><br><span class="line">    bundleAnalyzerReport: process.env.npm_config_report</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu16.04.5LTS安装SVN</title>
    <url>/2019/11/30/Ubuntu16.04.5LTS%E5%AE%89%E8%A3%85SVN/</url>
    <content><![CDATA[<p>本文简单介绍Ubuntu系统下SVN的搭建过程<br><a id="more"></a></p>
<h4 id="更新源"><a href="#更新源" class="headerlink" title="更新源"></a>更新源</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<h4 id="安装SVN"><a href="#安装SVN" class="headerlink" title="安装SVN"></a>安装SVN</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install subversion</span><br></pre></td></tr></table></figure>
<h4 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h4><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> /<span class="built_in">home</span>/svn</span><br><span class="line">sudo <span class="built_in">mkdir</span> /<span class="built_in">home</span>/svn/repository</span><br><span class="line">sudo chmod -R <span class="number">777</span> /<span class="built_in">home</span>/svn/repository</span><br><span class="line">sudo svnadmin create /<span class="built_in">home</span>/svn/repository</span><br><span class="line">cd /<span class="built_in">home</span>/svn/repository/</span><br><span class="line">sudo chmod -R <span class="number">777</span> db</span><br></pre></td></tr></table></figure>
<h4 id="修改svnserve-conf"><a href="#修改svnserve-conf" class="headerlink" title="修改svnserve.conf"></a>修改svnserve.conf</h4><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cd</span> /home/svn/repository/<span class="keyword">conf</span>/</span><br><span class="line">sudo <span class="keyword">vi</span> svnserve.<span class="keyword">conf</span></span><br></pre></td></tr></table></figure>
<p>修改这四行如下所示<br>anon-access = none 匿名用户不可读<br>auth-access = write 权限用户可写<br>password-db = passwd 密码文件为passwd<br>authz-db = authz 权限文件为authz<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## users have read and write access to the repository.</span></span></span><br><span class="line">anon-access = none</span><br><span class="line">auth-access = write</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## The password-db option controls the location of the password</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## database file.  Unless you specify a path starting with a /,</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## the file's location is relative to the directory containing</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## this configuration file.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## If SASL is enabled (see below), this file will NOT be used.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Uncomment the line below to use the default password file.</span></span></span><br><span class="line">password-db = passwd</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## The authz-db option controls the location of the authorization</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## rules for path-based access control.  Unless you specify a path</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## starting with a /, the file's location is relative to the</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## directory containing this file.  The specified path may be a</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## repository relative URL (^/) or an absolute file:// URL to a text</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## file in a Subversion repository.  If you don't specify an authz-db,</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## no path-based access control is done.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Uncomment the line below to use the default authorization file.</span></span></span><br><span class="line">authz-db = authz</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## The groups-db option controls the location of the groups file.</span></span></span><br></pre></td></tr></table></figure></p>
<h4 id="修改password文件，添加访问用户"><a href="#修改password文件，添加访问用户" class="headerlink" title="修改password文件，添加访问用户"></a>修改password文件，添加访问用户</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vi passwd</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[users]</span><br><span class="line"><span class="meta">#</span><span class="bash"> harry = harryssecret</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sally = sallyssecret</span></span><br><span class="line">lidata = lidata429</span><br></pre></td></tr></table></figure>
<h4 id="给用户增加目录权限"><a href="#给用户增加目录权限" class="headerlink" title="给用户增加目录权限"></a>给用户增加目录权限</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vi authz</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[groups]</span><br><span class="line"><span class="meta">#</span><span class="bash"> harry_and_sally = harry,sally</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> harry_sally_and_joe = harry,sally,&amp;joe</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> [/foo/bar]</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> harry = rw</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> &amp;joe = r</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> * =</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> [repository:/baz/fuz]</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> @harry_and_sally = rw</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> * = r</span></span><br><span class="line">[/]</span><br><span class="line">lidata=rw</span><br></pre></td></tr></table></figure>
<h4 id="启动服务，并且监听81端口"><a href="#启动服务，并且监听81端口" class="headerlink" title="启动服务，并且监听81端口"></a>启动服务，并且监听81端口</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo svnserve -d -r /home/svn --listen-port 81</span><br></pre></td></tr></table></figure>
<h4 id="查看svn是否启动"><a href="#查看svn是否启动" class="headerlink" title="查看svn是否启动"></a>查看svn是否启动</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps -ef | grep svnserve</span><br></pre></td></tr></table></figure>
<h4 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill all svnserve</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-next主题支持数学公式</title>
    <url>/2019/11/28/Hexo-next%E4%B8%BB%E9%A2%98%E6%94%AF%E6%8C%81%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</url>
    <content><![CDATA[<p>本文主要解决Hexo-next主题支持数学公式问题<br><a id="more"></a></p>
<h4 id="更换Hexo的markdown渲染引擎"><a href="#更换Hexo的markdown渲染引擎" class="headerlink" title="更换Hexo的markdown渲染引擎"></a>更换Hexo的markdown渲染引擎</h4><p>hexo-renderer-kramed引擎是在默认的渲染引擎，hexo-renderer-marked的基础上修改了一些bug，两者比较接近，也比较轻量级。<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure></p>
<h4 id="解决语义冲突"><a href="#解决语义冲突" class="headerlink" title="解决语义冲突"></a>解决语义冲突</h4><p>找到<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">node_modules\kramed\lib\rules\inline.js</span><br></pre></td></tr></table></figure><br>修改如下两处<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</span><br><span class="line">escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,</span><br></pre></td></tr></table></figure><br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br><span class="line">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></table></figure></p>
<h4 id="在next主题中开启mathJax开关"><a href="#在next主题中开启mathJax开关" class="headerlink" title="在next主题中开启mathJax开关"></a>在next主题中开启mathJax开关</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Math Formulas Render Support</span></span><br><span class="line">math:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Default (<span class="literal">true</span>) will load mathjax / katex script on demand.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> That is it only render those page <span class="built_in">which</span> has `mathjax: <span class="literal">true</span>` <span class="keyword">in</span> Front-matter.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> If you <span class="built_in">set</span> it to <span class="literal">false</span>, it will load mathjax / katex srcipt EVERY PAGE.</span></span><br><span class="line">  per_page: true</span><br><span class="line">  engine: mathjax   # 添加这个，反正我的主题默认没有这一行</span><br><span class="line"><span class="meta">  #</span><span class="bash"> hexo-renderer-pandoc (or hexo-renderer-kramed) required <span class="keyword">for</span> full MathJax support.</span></span><br><span class="line">  mathjax:</span><br><span class="line">    enable: true    # 这个改为true</span><br><span class="line">    # See: https://mhchem.github.io/MathJax-mhchem/</span><br><span class="line">    mhchem: true    # 这个改为true</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> hexo-renderer-markdown-it-plus (or hexo-renderer-markdown-it with markdown-it-katex plugin) required <span class="keyword">for</span> full Katex support.</span></span><br><span class="line">  katex:</span><br><span class="line">    enable: false</span><br><span class="line">    # See: https://github.com/KaTeX/KaTeX/tree/master/contrib/copy-tex</span><br><span class="line">    copy_tex: false</span><br></pre></td></tr></table></figure>
<h4 id="打开mathjax开关"><a href="#打开mathjax开关" class="headerlink" title="打开mathjax开关"></a>打开mathjax开关</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Using-Machine-Learning-for-Data-Center-Cooling-Infrastructure-Efficiency-Prediction</span><br><span class="line">date: 2019-11-28 22:53:32</span><br><span class="line">tags: [datacenter, machinelearning]</span><br><span class="line">category: DataCenter</span><br><span class="line">mathjax: true</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<h4 id="添加公式"><a href="#添加公式" class="headerlink" title="添加公式"></a>添加公式</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">$</span></span><br><span class="line">COP = \frac&#123;Q_&#123;CoolingCircuits&#125;&#125;&#123;P_&#123;CoolingCircuits&#125;&#125;</span><br><span class="line"><span class="meta">$</span><span class="bash">$</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>markdown</tag>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title>Using Machine Learning for Data Center Cooling Infrastructure Efficiency Prediction</title>
    <url>/2019/11/28/Using-Machine-Learning-for-Data-Center-Cooling-Infrastructure-Efficiency-Prediction/</url>
    <content><![CDATA[<p>Using Machine Learning for Data Center Cooling Infrastructure Efficiency Prediction<br><a id="more"></a></p>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>Power consumption continues to remain a critical aspect for High Performance Computing (HPC) data centers. It becomes even more crucial for Exascale computing since scaling today’s fastest system to an Exaflop level would consume more than 168 MW power which is 8 times higher than the 20 MW power consumption goal set, at the time of this publication, by the US Department of Energy.</p>
<p>This naturally leads to a necessity for energy efficiency improvement that will encompass the full chain of the power consumers, starting from the data center infrastructure, including cooling overheads and electrical losses, up to compute resource scheduling and application scaling.</p>
<p>In this paper a machine learning approach is proposed to model the Coefficient of Performance (COP) of HPC data center’s hot water cooling loop. The suggested model is validated on operational data obtained at Leibniz Supercomputing Centre (LRZ). The paper shows how this COP model can help to improve the energy efficiency of modern HPC data centers.</p>
<h4 id="PUE"><a href="#PUE" class="headerlink" title="PUE"></a>PUE</h4><script type="math/tex; mode=display">
PUE = \frac{P_{Tocal}}{P_{IT}} = \frac{P_{cooling}+P_{IT}+P_{electricalLosses}+P_{misc}}{P_{IT}}</script><h4 id="COP"><a href="#COP" class="headerlink" title="COP"></a>COP</h4><ul>
<li>COP: Coefficient of Performance<script type="math/tex; mode=display">
COP = \frac{Q_{CoolingCircuits}}{P_{CoolingCircuits}}</script></li>
<li>$Q_{CoolingCircuits}$ - is the aggregated amount of cold generated by the four cooling circuits (measured in watts)</li>
<li>$P_{CoolingCircuits}$ - is the aggregated amount of power consumed by the four cooling circuits (measured in watts)</li>
</ul>
<p><img src="https://www.guanacossj.com/media/articlebodypics/1575015799772.jpg" alt=""></p>
<ul>
<li>T(WB):the wet bulb temperature</li>
<li>P(DC):the complete power consumption of the data center</li>
<li>P(SuperMUC IT):the power consumption profile of the deployed HPC system SuperMUC-Phase1</li>
<li>P(DC KT+I):the power consumption of the cooling infrastructure</li>
<li>P(Cluster IT):the power profile of an old HPC cluster system installed at LRZ</li>
<li>P(DC EV):the power losses from electrical distribution and conversion</li>
</ul>
<h4 id="WHY-COP"><a href="#WHY-COP" class="headerlink" title="WHY COP?"></a>WHY COP?</h4><p>A similar study using neural networks for predicting a datacenter’s PUE was presented by Jim Gao from Google in [10].The study considered Google data centers where the author uses approximately 2 years of Google’s operational data for modeling the PUE. The main drawback of PUE is that it indicates the exact relation between the IT power consumption and the complete facility power consumption; implying that the more power is put into the IT equipment the better(optimal PUE is 1). If multiple cooling technologies are used(e.g. air cooling according to ASHRAE (American Society of Heating, Refrigerating and Air-Conditioning Engineers)[11] class A1 specifications (air cooling with 18 ◦C - 27 ◦C inlet temperature [12]), water cooling according to ASHRAE W1-W4 standards, etc.) PUE combines the COPs from all cooling technologies into one number. This makes it impossible to calculate cooling overheads for individual IT systems. This paper focuses on COP since COP reflects the impacts of various control parameters on the overall efficiency of the data center cooling infrastructure. This allows for the identification of key parameters and their optimal configuration for a given point in time.There are other studies that aim to model, simulate,and optimize the energy efficiency of modern HPC liquid cooled data centers with the help of multiphysical network simulators [13], [14], [15]. Using these studies, it might be 956 possible to formally describe the relationships in each part of the liquid cooling circuit and use statistical modeling for predicting the efficiency of the cooling infrastructure.These type of solutions can be: (a) time intensive and/or (b) erroneous since they could fail to completely capture the the complex interactions of various components affecting the overall efficiency of the cooling infrastructure. Examples of such complex interactions include the dynamic variation of ambient outside conditions combined with high fluctuating IT load on the cooling infrastructure.<br>This paper proposes a different approach - a neural network [16] based framework that learns from the actual operational data and aims to predict the impacts of various infrastructure configurations on the overall cooling efficiency of a typical HPC data center. With this approach, it is possible to capture the complex interactions of various aspects affecting the overall data center power/energy efficiency (as identified in Figure 4).</p>
<h4 id="SETUP-AT-LRZ"><a href="#SETUP-AT-LRZ" class="headerlink" title="SETUP AT LRZ"></a>SETUP AT LRZ</h4><h5 id="Hot-Water-Cooling-Circuit"><a href="#Hot-Water-Cooling-Circuit" class="headerlink" title="Hot Water Cooling Circuit"></a>Hot Water Cooling Circuit</h5><p>Figure 5 illustrates the schematic overview of LRZ’s chiller-less (also called hot water) cooling infrastructure, consisting of four identical cooling circuits. In this paper, the term ”hot water” refers to ASHRAEs W4 specification [11]. Each cooling circuit has a 2 MW wet cooling tower (KLT11, KLT12, KLT13, and KLT14). On average, at least two cooling circuits are active, the third and the fourth are added depending on the load.</p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/1575008791198.jpg" alt=""></p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/1575002886514.jpg" alt=""></p>
<ul>
<li>Subcircuit I: The water enters the cooling circuit from the distribution bar via a hydraulic gate. The water then flows with the help of a redundant pump pair to the heat exchanger and back again via a hydraulic gate to the distribution bar.</li>
<li>Subcircuit II: The ethylene glycol water mix (this mixture prevents the water from freezing) is pumped to the corresponding cooling tower (connection A) by two redundant pumps.</li>
</ul>
<p><img src="https://www.guanacossj.com/media/articlebodypics/1575002918635.jpg" alt=""></p>
<h4 id="The-COP-Network-Model-Design"><a href="#The-COP-Network-Model-Design" class="headerlink" title="The COP Network Model Design"></a>The COP Network Model Design</h4><p>Recurrent neural networks [19] are a special class of artificial neural networks where neuron-like units form directed cycles - introducing feedback and thus memory to the network. This allows a better capturing of the time evolution of the underlying discrete time random signals. The Long Short-Term Memory (LSTM) [20] networks, used in this paper, are a special class of recurrent neural networks that are capable of capturing behaviors having relatively long timelags.</p>
<h5 id="Inputs-to-the-model"><a href="#Inputs-to-the-model" class="headerlink" title="Inputs to the model:"></a>Inputs to the model:</h5><ul>
<li>aggregated amount of cold generated by each cooling circuit</li>
<li>aggregated amount of power consumed by the fans of each cooling tower </li>
<li>number of active cooling towers</li>
<li>wet bulb temperature<br>  湿球温度是指同等焓值空气状态下，空气中水蒸汽达到饱和时的空气温度，在空气焓湿图上是由空气状态点沿等焓线下降至100%相对湿度线上，对应点的干球温度。   </li>
<li>inlet water temperature (to the distribution bar) from each cooling circuit (Figure 6) (×4)</li>
<li>return water temperature (to the distribution bar) to each cooling circuit (Figure 6) (×4)</li>
</ul>
<h5 id="Output-of-the-model"><a href="#Output-of-the-model" class="headerlink" title="Output of the model:"></a>Output of the model:</h5><ul>
<li>COP of the hot water cooling loop</li>
</ul>
<p>And so, depending on the inlet temperature of the cooling towers, the fan speeds have to be adjusted to create the desired outlet temperature from the cooling tower. The efficiency of the cooling infrastructure will vary with fan speeds which leads to differences in the power consumption. This is why fan power is considered as an affecting factor to the COP of the cooling infrastructure.</p>
<h4 id="COP-Prediction-Results"><a href="#COP-Prediction-Results" class="headerlink" title="COP Prediction Results"></a>COP Prediction Results</h4><p>A network, with two hidden LSTM recurrent layers and a linear output layer, was created using Adam [23] as an optimizer. Figure 8 shows the COP prediction results for the complete year 2016 when the data for the complete year 2015 was learned.<br><img src="https://www.guanacossj.com/media/articlebodypics/1575005434173.jpg" alt=""></p>
<h4 id="REFINING-THE-INPUT-SET"><a href="#REFINING-THE-INPUT-SET" class="headerlink" title="REFINING THE INPUT SET"></a>REFINING THE INPUT SET</h4><p>Having shown that the neural network based COP prediction is possible, the follow up work focused on the improvement of its useability. The usage of the shown network is not very practical since a change in one of the input parameters (e.g. inlet water temperature entering the cooling circuit from the distribution bar) directly affects other input parameters (e.g. the amount of power consumed by the fans of the cooling towers).</p>
<h5 id="The-improved-COP-prediction-network"><a href="#The-improved-COP-prediction-network" class="headerlink" title="The improved COP prediction network"></a>The improved COP prediction network</h5><p>The list below indicates the refined set of input parameters:</p>
<ul>
<li>aggregated amount of cold generated by each cooling circuit</li>
<li>number of active cooling towers</li>
<li>inlet water temperature from each cooling circuit (Figure 6) (×4)</li>
<li>return water temperature to each cooling circuit (Figure 6) (×4)</li>
</ul>
<p>A. Deriving Wet Bulb Temperature<br>Wet bulb temperature can be derived analytically using the dry bulb temperature and the relative humidity using the formula presented in [24], which in their turn can also be made accessible from weather forecast frameworks.</p>
<p>B. Deriving Power of Cooling Tower Fans<br>In order to predict the power consumption of the cooling tower fans (each cooling tower in our case has two fans, Figure 7) the estimation of the water flow rates (before entering the hydraulic gate) is required in advance. This can be determined analytically via the following equation:</p>
<script type="math/tex; mode=display">
flowRate_{KLT_{i}} = \frac{Q_{KLT_{i}}}{c_{p}*\rho *\Delta{T_{KLT_{i}}}}</script><ul>
<li><p><script type="math/tex">QKLT_{i}</script>- is the amount of cold generated by the cooling circuit connected to $KLT_{i}$</p>
</li>
<li><p>$\Delta T_{KLT_{i}}$- is the temperature difference between inlet and return water (from and to the distribution bar correspondingly) for the cooling circuit connected to $KLT_{i}$</p>
</li>
<li><p>$c_{p}$- is the water specific heat capacity;</p>
</li>
<li><p>$\rho$- is the water density.</p>
</li>
</ul>
<p>Having estimated the water flow rates, a network with two hidden LSTM layers using Stochastic Gradient Decent [25] as an optimizer was built taking the following inputs:</p>
<ul>
<li>$QKLT_{i}$amount of generated cold for a given cooling circuit (1≤ i ≤4)<script type="math/tex">KLT_{i}</script></li>
<li>$flowRate_{KLT_{i}}$ water flow rate (before entering the hydraulic gate) for a given cooling circuit (1≤ i ≤4)<script type="math/tex">KLT_{i}</script></li>
</ul>
<p>C. Deriving Cold Generation from HPC System’s Power Profile</p>
<p>Figure 13 shows the prediction results for the linear regression model that takes as an input the power consumption data of SuperMUC and outputs the aggregated amount of cold generated by all four cooling circuits. The power data for 2015 was learned and the amount of heat was predicted for 2016. As can be seen, the prediction has a relatively high accuracy.</p>
<p><img src="https://www.guanacossj.com/media/articlebodypics/1575010626556.jpg" alt=""></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>datacenter</tag>
        <tag>machinelearning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning Applications for Data Center Optimization</title>
    <url>/2019/11/28/Machine-Learning-Applications-for-Data-Center-Optimization/</url>
    <content><![CDATA[<p>Machine Learning Applications for Data Center Optimization<br><a id="more"></a></p>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>The modern data center (DC) is a complex interaction of multiple mechanical, electrical and controls systems. The sheer number of possible operating configurations and nonlinear interdependencies make it difficult to understand and optimize energy efficiency. We develop a neural network framework that learns from actual operations data to model plant performance and predict PUE within a range of 0.004 +/­ 0.005 (mean absolute error +/­ 1 standard deviation), or 0.4% error for a PUE of 1.1. The model has been extensively tested and validated at Google DCs. The results demonstrate that machine learning is an effective way of leveraging existing sensor data to model DC performance and improve energy efficiency.</p>
<h4 id="Model-Implementation"><a href="#Model-Implementation" class="headerlink" title="Model Implementation"></a>Model Implementation</h4><p>A generic three­layered neural network is illustrated in Figure 2. In this study, the input matrix is an (m x n) array where is the number of training examples and is the number of features (DC input variables) including the IT load, weather conditions, number of chillers and cooling towers running, equipment setpoints, etc. The input matrix is then multiplied by the model parameters matrix θ 1 to produce the hidden state matrix [6]. In practice, acts as an intermediary state that interacts with the second parameters matrix θ 2 to calculate the output (x) [6]. The size and number of hidden layers can be varied to model systems of varying complexity.xmnxaahθ<br>Note that (x) is the output variable of interest and can represent a range of metrics that we wish to optimize. PUE is selected here to represent DC operational efficiency, with recognition that the metric is a ratio and not indicative of total facility­level energy consumption. Other examples include using server utilization data to maximize machine productivity, or equipment failure data to understand how the DC environment impacts reliability. The neural network will search for relationships between data features to generate a mathematical model that describes (x) as a function of the inputs. Understanding the underlying mathematical behavior of (x) allows us to control and optimize it.hθhθhθ<br><img src="https://www.guanacossj.com/media/articlebodypics/1574950962566.jpg" alt=""><br>The process of training a neural network model can be broken down into four steps, each of which are covered in greater detail below: </p>
<ul>
<li>Randomly initialize the model parameters θ </li>
<li>Implement the forward propagation algorithm,</li>
<li>Compute the cost function (θ)</li>
<li>Implement the back propagation algorithm and (5) Repeat steps 2 ­ 4 until convergence or the desired number of iterations</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>datacenter</tag>
        <tag>machinelearning</tag>
      </tags>
  </entry>
  <entry>
    <title>Django个人博客搭建教程-登录登出模块</title>
    <url>/2019/11/28/Django%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B-%E7%99%BB%E5%BD%95%E7%99%BB%E5%87%BA%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<p>本文主要讲解自定义的登录登出模块，不涉及Django自带的认证模块，包括登录检查装饰器、链接自动跳转登录前url等<br><a id="more"></a></p>
<h4 id="models-py"><a href="#models-py" class="headerlink" title="models.py"></a>models.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BlogUser</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    <span class="string">'''用户表'''</span></span><br><span class="line"></span><br><span class="line">    gender = (</span><br><span class="line">        (<span class="string">'male'</span>,<span class="string">'男'</span>),</span><br><span class="line">        (<span class="string">'female'</span>,<span class="string">'女'</span>),</span><br><span class="line">    )</span><br><span class="line">    status = (</span><br><span class="line">        (<span class="string">'active'</span>,<span class="string">'有效'</span>),</span><br><span class="line">        (<span class="string">'disabled'</span>,<span class="string">'无效'</span>),</span><br><span class="line">    )</span><br><span class="line">    id = models.AutoField(primary_key=<span class="literal">True</span>)</span><br><span class="line">    name = models.CharField(max_length=<span class="number">128</span>,unique=<span class="literal">True</span>)</span><br><span class="line">    password = models.CharField(max_length=<span class="number">256</span>)</span><br><span class="line">    email = models.EmailField(unique=<span class="literal">True</span>)</span><br><span class="line">    sex = models.CharField(max_length=<span class="number">32</span>,choices=gender,default=<span class="string">'男'</span>)</span><br><span class="line">    c_time = models.DateTimeField(auto_now_add=<span class="literal">True</span>)</span><br><span class="line">    userpic = models.ImageField(upload_to=<span class="string">'userpic'</span>,blank=<span class="literal">True</span>,null=<span class="literal">True</span>)</span><br><span class="line">    status = models.CharField(max_length=<span class="number">32</span>,choices=status,default=<span class="string">'有效'</span>)</span><br><span class="line">    brief = models.CharField(max_length=<span class="number">1024</span>,blank=<span class="literal">True</span>,null=<span class="literal">True</span>)</span><br><span class="line">    role = models.ManyToManyField(BlogRole, blank=<span class="literal">True</span>,null=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="views-py"><a href="#views-py" class="headerlink" title="views.py"></a>views.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_login</span><span class="params">(f)</span>:</span></span><br><span class="line"><span class="meta">    @wraps(f)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inner</span><span class="params">(request, *arg, **kwargs)</span>:</span></span><br><span class="line">        next_url = request.path_info</span><br><span class="line">        print(next_url)</span><br><span class="line">        <span class="keyword">if</span> request.session.get(<span class="string">'is_login'</span>) == <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">return</span> f(request, *arg, **kwargs)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> redirect(<span class="string">'/JiaBlog/login/?next=%s'</span> % next_url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login_view</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="comment"># 当前端点击登录按钮时，提交数据到后端，进入该POST方法</span></span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">"POST"</span>:</span><br><span class="line">        <span class="comment"># 获取用户名和密码</span></span><br><span class="line">        username = request.POST.get(<span class="string">"username"</span>)</span><br><span class="line">        password = request.POST.get(<span class="string">"password"</span>)</span><br><span class="line">        <span class="comment"># 在前端传回时也将跳转链接传回来</span></span><br><span class="line">        next_url = request.POST.get(<span class="string">"next_url"</span>)</span><br><span class="line">        print(next_url)</span><br><span class="line">        <span class="comment"># 对用户进行验证</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            user = models.BlogUser.objects.get(name=username)</span><br><span class="line">            <span class="keyword">if</span> user.status == <span class="string">'active'</span> <span class="keyword">or</span> user.status == <span class="string">'有效'</span>:</span><br><span class="line">                <span class="keyword">if</span> user.password == password:</span><br><span class="line">                    request.session[<span class="string">'is_login'</span>] = <span class="literal">True</span></span><br><span class="line">                    request.session[<span class="string">'user_id'</span>] = user.id</span><br><span class="line">                    request.session[<span class="string">'user_name'</span>] = user.name</span><br><span class="line">                    <span class="comment"># 如果跳转链接不为空并且跳转页面不是登出页面，则登录成功后跳转，否则直接进入主页</span></span><br><span class="line">                    <span class="keyword">if</span> next_url <span class="keyword">and</span> next_url != <span class="string">"/JiaBlog/logout/"</span>:</span><br><span class="line">                        response = redirect(next_url)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        response = redirect(<span class="string">"/JiaBlog/index/"</span>)</span><br><span class="line">                    <span class="keyword">return</span> response</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    message = <span class="string">"密码不正确！"</span></span><br><span class="line">            <span class="comment"># 若用户名或密码失败,则将提示语与跳转链接继续传递到前端</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                message = <span class="string">"用户状态信息异常，请联系管理员(18351922995)! "</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            message = <span class="string">"用户不存在！"</span></span><br><span class="line">        <span class="keyword">return</span> render(request, <span class="string">'login.html'</span>, locals())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        next_url = request.GET.get(<span class="string">"next"</span>, <span class="string">''</span>)</span><br><span class="line">        <span class="keyword">return</span> render(request, <span class="string">"login.html"</span>, &#123;<span class="string">'next_url'</span>: next_url&#125;,locals())</span><br></pre></td></tr></table></figure>
<h4 id="urls-py"><a href="#urls-py" class="headerlink" title="urls.py"></a>urls.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url(<span class="string">r'^login/$'</span>, views.login_view,name=<span class="string">'login'</span>),</span><br></pre></td></tr></table></figure>
<h4 id="login-html"><a href="#login-html" class="headerlink" title="login.html"></a>login.html</h4><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">form</span> <span class="attr">class</span>=<span class="string">"form-signin"</span> <span class="attr">method</span>=<span class="string">"post"</span> <span class="attr">action</span>=<span class="string">"&#123;% url 'JiaBlog:login' %&#125;"</span>&gt;</span></span><br><span class="line">          &#123;% if message %&#125;</span><br><span class="line">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"alert alert-warning"</span>&gt;</span>&#123;&#123; message &#125;&#125;<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">          &#123;% endif %&#125;</span><br><span class="line">          &#123;% csrf_token %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">h2</span> <span class="attr">class</span>=<span class="string">"form-signin-heading"</span> <span class="attr">style</span>=<span class="string">"text-align: center"</span>&gt;</span>Sign In<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"inputEmail"</span> <span class="attr">class</span>=<span class="string">"sr-only"</span>&gt;</span>Email address<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">id</span>=<span class="string">"inputUsername"</span> <span class="attr">name</span>=<span class="string">'username'</span> <span class="attr">class</span>=<span class="string">"form-control"</span> <span class="attr">placeholder</span>=<span class="string">"Username"</span> <span class="attr">required</span> <span class="attr">autofocus</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"inputPassword"</span> <span class="attr">class</span>=<span class="string">"sr-only"</span>&gt;</span>Password<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">id</span>=<span class="string">"inputPassword"</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">class</span>=<span class="string">"form-control"</span> <span class="attr">placeholder</span>=<span class="string">"Password"</span> <span class="attr">required</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"display: none;"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"next"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"next_url"</span> <span class="attr">value</span>=<span class="string">"&#123;&#123; next_url &#125;&#125;"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"checkbox"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">label</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">value</span>=<span class="string">"remember-me"</span>&gt;</span> Remember me</span><br><span class="line">          <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">class</span>=<span class="string">"btn btn-lg btn-primary btn-block"</span> <span class="attr">type</span>=<span class="string">"submit"</span>&gt;</span>Sign in<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"form-signin"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">button</span> <span class="attr">class</span>=<span class="string">"btn btn-lg btn-primary btn-block"</span> <span class="attr">onclick</span>=<span class="string">"window.location.href = '/JiaBlog/register'"</span>&gt;</span>Register in<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"text-align: center"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"display:inline-block;"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"iconfont icon-github"</span>&gt;</span>&amp;nbsp;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">style</span>=<span class="string">"color: black;text-decoration: none;"</span> <span class="attr">href</span>=<span class="string">"&#123;% url "</span><span class="attr">social:begin</span>" "<span class="attr">github</span>" %&#125;"&gt;</span>GitHub<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span>&amp;nbsp;&amp;nbsp;&amp;nbsp;</span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"display:inline-block;"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"iconfont icon-weibo"</span>&gt;</span>&amp;nbsp;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">style</span>=<span class="string">"color: black;text-decoration: none;"</span> <span class="attr">href</span>=<span class="string">"&#123;% url "</span><span class="attr">social:begin</span>" "<span class="attr">weibo</span>" %&#125;"&gt;</span>Weibo<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span>&amp;nbsp;&amp;nbsp;&amp;nbsp;</span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"display:inline-block;"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"iconfont icon-Facebook"</span>&gt;</span>&amp;nbsp;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">style</span>=<span class="string">"color: black;text-decoration: none;"</span> <span class="attr">href</span>=<span class="string">"&#123;% url "</span><span class="attr">social:begin</span>" "<span class="attr">facebook</span>" %&#125;"&gt;</span>Facebook<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span>&amp;nbsp;&amp;nbsp;&amp;nbsp;</span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"display:inline-block;"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"iconfont icon-google"</span>&gt;</span>&amp;nbsp;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">style</span>=<span class="string">"color: black;text-decoration: none;"</span> <span class="attr">href</span>=<span class="string">"&#123;% url "</span><span class="attr">social:begin</span>" "<span class="attr">google-oauth2</span>" %&#125;"&gt;</span>Google<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">&#123;#          <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"text-align: center"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"iconfont icon-github"</span>&gt;</span>&amp;nbsp;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">style</span>=<span class="string">"color: black;text-decoration: none;"</span> <span class="attr">href</span>=<span class="string">"&#123;% url "</span><span class="attr">social:begin</span>" "<span class="attr">facebook</span>" %&#125;"&gt;</span>Facebook Login<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span>#&#125;</span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"fb-root"</span> <span class="attr">style</span>=<span class="string">"text-align: center"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">defer</span> <span class="attr">crossorigin</span>=<span class="string">"anonymous"</span> <span class="attr">src</span>=<span class="string">"https://connect.facebook.net/zh_CN/sdk.js#xfbml=1&amp;version=v5.0&amp;appId=2513272488741954&amp;autoLogAppEvents=1"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"fb-login-button"</span> <span class="attr">data-width</span>=<span class="string">""</span> <span class="attr">data-size</span>=<span class="string">"medium"</span> <span class="attr">data-button-type</span>=<span class="string">"continue_with"</span> <span class="attr">data-auto-logout-link</span>=<span class="string">"true"</span> <span class="attr">data-use-continue-as</span>=<span class="string">"true"</span> <span class="attr">data-onlogin</span>=<span class="string">"checkLoginState()"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"status"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">&#123;#            <span class="tag">&lt;<span class="name">fb:login-button</span> <span class="attr">scope</span>=<span class="string">"public_profile,email"</span> <span class="attr">onlogin</span>=<span class="string">"checkLoginState();"</span>&gt;</span><span class="tag">&lt;/<span class="name">fb:login-button</span>&gt;</span>#&#125;</span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="comment">&lt;!-- /container --&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title>Flask入门教程-数据库连接与数据模型拆分</title>
    <url>/2019/11/27/Flask%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E6%8B%86%E5%88%86/</url>
    <content><![CDATA[<p>flask-SQLAlchemy是一套ORM(Object Relationship Mapping)框架，中文翻译就是模型关系映射，将数据库表映射成python中的对象，非常方便，创建一个模型，来通过模型来增删改数据库<br><a id="more"></a></p>
<h4 id="安装flask-SQLAlchemy"><a href="#安装flask-SQLAlchemy" class="headerlink" title="安装flask-SQLAlchemy"></a>安装flask-SQLAlchemy</h4><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">pip3 install flask-SQLalchemy</span><br></pre></td></tr></table></figure>
<h4 id="安装flask-mysqldb"><a href="#安装flask-mysqldb" class="headerlink" title="安装flask-mysqldb"></a>安装flask-mysqldb</h4><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">pip3 install flask-mysqldb</span><br></pre></td></tr></table></figure>
<p>ps: 貌似不装也可以，我发现我就没装</p>
<h4 id="安装pymysql"><a href="#安装pymysql" class="headerlink" title="安装pymysql"></a>安装pymysql</h4><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">pip3 install pymysql</span><br></pre></td></tr></table></figure>
<h4 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h4><p>app.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,render_template</span><br><span class="line"><span class="keyword">from</span> flask_sqlalchemy <span class="keyword">import</span> SQLAlchemy</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"> </span><br><span class="line">app = Flask(__name__)</span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_DATABASE_URI'</span>] = <span class="string">"mysql+pymysql://root:123@127.0.0.1:3306/JiaBlog"</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_COMMIT_TEARDOWN'</span>] = <span class="literal">True</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_TRACK_MODIFICATIONS'</span>] = <span class="literal">False</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_COMMIT_ON_TEARDOWN'</span>] = <span class="literal">True</span></span><br><span class="line">app.config[<span class="string">'JSON_AS_ASCII'</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello_world</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'Hello World!'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/index')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">'index.html'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run(debug=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="新建数据库"><a href="#新建数据库" class="headerlink" title="新建数据库"></a>新建数据库</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create database JiaBlog</span><br></pre></td></tr></table></figure>
<h4 id="拆分models"><a href="#拆分models" class="headerlink" title="拆分models"></a>拆分models</h4><p>在app.py同级目录下新建models.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> app <span class="keyword">import</span> db</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Article</span><span class="params">(db.Model)</span>:</span></span><br><span class="line">    <span class="comment"># 定义表名</span></span><br><span class="line">    __tablename__ = <span class="string">'article'</span></span><br><span class="line">    <span class="comment"># 定义字段</span></span><br><span class="line">    <span class="comment"># db.Column 表示是一个字段</span></span><br><span class="line">    id = db.Column(db.Integer, primary_key=<span class="literal">True</span>)</span><br><span class="line">    title = db.Column(db.String(<span class="number">50</span>), unique=<span class="literal">True</span>)</span><br><span class="line">    content = db.Column(db.Text)</span><br><span class="line">    timestamp = db.Column(db.DateTime, default=datetime.utcnow)</span><br></pre></td></tr></table></figure><br>修改app.py代码如下<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> models <span class="keyword">import</span> Article</span><br><span class="line"><span class="keyword">from</span> flask_sqlalchemy <span class="keyword">import</span> SQLAlchemy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_DATABASE_URI'</span>] = <span class="string">"mysql+pymysql://root:980612ssj@%@101.132.70.184:3306/JiaBlog"</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_COMMIT_TEARDOWN'</span>] = <span class="literal">True</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_TRACK_MODIFICATIONS'</span>] = <span class="literal">False</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_COMMIT_ON_TEARDOWN'</span>] = <span class="literal">True</span></span><br><span class="line">app.config[<span class="string">'JSON_AS_ASCII'</span>] = <span class="literal">False</span></span><br><span class="line">db.SQLAlchemy(app)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello_world</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'Hello World!'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure><br>启动报错<br><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">ImportError: cannot import name 'db'</span><br></pre></td></tr></table></figure><br>这是因为在app文件中，咱们引入了from models import Article，在models.py中咱们引入了from app import db，两个文件相互引用了，这个就是循环引用。出现循坏引用，代码就无法正常执行了。<br>为了解决循环引用，那么只需要保证两个文件不相互都需要对方就行了，这时候咱们可以加入第三个文件，让两个文件都需要第三个文件</p>
<h4 id="解决循环引用"><a href="#解决循环引用" class="headerlink" title="解决循环引用"></a>解决循环引用</h4><p>在app.py同级目录下新增exts.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask_sqlalchemy <span class="keyword">import</span> SQLAlchemy</span><br><span class="line"><span class="comment"># 此时先不传入app</span></span><br><span class="line">db = SQLAlchemy()</span><br></pre></td></tr></table></figure><br>修改model.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask_sqlalchemy <span class="keyword">import</span> SQLAlchemy</span><br><span class="line"><span class="keyword">from</span> exts <span class="keyword">import</span> db</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Article</span><span class="params">(db.Model)</span>:</span></span><br><span class="line">    <span class="comment"># 定义表名</span></span><br><span class="line">    __tablename__ = <span class="string">'article'</span></span><br><span class="line">    <span class="comment"># 定义字段</span></span><br><span class="line">    <span class="comment"># db.Column 表示是一个字段</span></span><br><span class="line">    id = db.Column(db.Integer, primary_key=<span class="literal">True</span>)</span><br><span class="line">    title = db.Column(db.String(<span class="number">50</span>), unique=<span class="literal">True</span>)</span><br><span class="line">    content = db.Column(db.Text)</span><br><span class="line">    timestamp = db.Column(db.DateTime, default=datetime.utcnow)</span><br></pre></td></tr></table></figure><br>修改app.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> exts <span class="keyword">import</span> db</span><br><span class="line"><span class="keyword">from</span> models <span class="keyword">import</span> Article</span><br><span class="line"><span class="keyword">from</span> flask_sqlalchemy <span class="keyword">import</span> SQLAlchemy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_DATABASE_URI'</span>] = <span class="string">"mysql+pymysql://root:980612ssj@%@101.132.70.184:3306/JiaBlog"</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_COMMIT_TEARDOWN'</span>] = <span class="literal">True</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_TRACK_MODIFICATIONS'</span>] = <span class="literal">False</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_COMMIT_ON_TEARDOWN'</span>] = <span class="literal">True</span></span><br><span class="line">app.config[<span class="string">'JSON_AS_ASCII'</span>] = <span class="literal">False</span></span><br><span class="line">db.init_app(app)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello_world</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'Hello World!'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title>Flask入门教程-你的第一个flask程序</title>
    <url>/2019/11/27/Flask%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AAflask%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<p>Flask是由python实现的一个web微框架，让我们可以使用Python语言快速实现一个网站或Web服务<br><a id="more"></a></p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install flask</span><br></pre></td></tr></table></figure>
<h4 id="工程目录示例"><a href="#工程目录示例" class="headerlink" title="工程目录示例"></a>工程目录示例</h4><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── <span class="selector-tag">app</span><span class="selector-class">.py</span></span><br><span class="line">├── <span class="selector-tag">exts</span><span class="selector-class">.py</span></span><br><span class="line">├── <span class="selector-tag">manage</span><span class="selector-class">.py</span></span><br><span class="line">├── <span class="selector-tag">migrations</span></span><br><span class="line">│   ├── <span class="selector-tag">README</span></span><br><span class="line">│   ├── __<span class="selector-tag">pycache__</span></span><br><span class="line">│   ├── <span class="selector-tag">alembic</span><span class="selector-class">.ini</span></span><br><span class="line">│   ├── <span class="selector-tag">env</span><span class="selector-class">.py</span></span><br><span class="line">│   ├── <span class="selector-tag">script</span><span class="selector-class">.py</span><span class="selector-class">.mako</span></span><br><span class="line">│   └── <span class="selector-tag">versions</span></span><br><span class="line">├── <span class="selector-tag">models</span><span class="selector-class">.py</span></span><br><span class="line">├── <span class="selector-tag">prophet</span><span class="selector-class">.py</span></span><br><span class="line">├── <span class="selector-tag">static</span></span><br><span class="line">│   ├── <span class="selector-tag">css</span></span><br><span class="line">│   ├── <span class="selector-tag">data</span></span><br><span class="line">│   ├── <span class="selector-tag">img</span></span><br><span class="line">│   └── <span class="selector-tag">js</span></span><br><span class="line">└── <span class="selector-tag">templates</span></span><br><span class="line">    ├── <span class="selector-tag">imageinfo</span><span class="selector-class">.html</span></span><br><span class="line">    ├── <span class="selector-tag">imageinfogengduo</span><span class="selector-class">.html</span></span><br><span class="line">    ├── <span class="selector-tag">index</span><span class="selector-class">.html</span></span><br><span class="line">    ├── <span class="selector-tag">login</span><span class="selector-class">.html</span></span><br><span class="line">    ├── <span class="selector-tag">mp3info</span><span class="selector-class">.html</span></span><br><span class="line">    ├── <span class="selector-tag">test</span><span class="selector-class">.html</span></span><br><span class="line">    └── <span class="selector-tag">videoinfo</span><span class="selector-class">.html</span></span><br></pre></td></tr></table></figure>
<h4 id="返回你的第一个页面"><a href="#返回你的第一个页面" class="headerlink" title="返回你的第一个页面"></a>返回你的第一个页面</h4><p>app.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,render_template</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello_world</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'Hello World!'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/index')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">'index.html'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure><br>在static目录下配置对于的js、css文件</p>
]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title>Django2.1.7集成Celery4.3.0任务队列路由</title>
    <url>/2019/11/26/Django2-1-7%E9%9B%86%E6%88%90Celery4-3-0%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%E8%B7%AF%E7%94%B1/</url>
    <content><![CDATA[<p>Celery 是一个简单、灵活且可靠的，处理大量消息的分布式系统，并且提供维护这样一个系统的必需工具。它是一个专注于实时处理的任务队列，同时也支持任务调度。本文演示了如何在Django中集成Celery<br><a id="more"></a></p>
<h4 id="依赖安装"><a href="#依赖安装" class="headerlink" title="依赖安装"></a>依赖安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install celery</span><br><span class="line">pip3 install django-celery</span><br></pre></td></tr></table></figure>
<h4 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">celery                             4.3.0            </span><br><span class="line">django-celery                      3.3.1</span><br></pre></td></tr></table></figure>
<h4 id="celery名词"><a href="#celery名词" class="headerlink" title="celery名词"></a>celery名词</h4><ul>
<li>任务task：就是一个Python函数。</li>
<li>队列queue：将需要执行的任务加入到队列中。</li>
<li>工人worker：在一个新进程中，负责执行队列中的任务。</li>
<li>代理人broker：负责调度，需要提前部署好redis。</li>
</ul>
<h4 id="工程目录结构"><a href="#工程目录结构" class="headerlink" title="工程目录结构"></a>工程目录结构</h4><h4 id="新建app"><a href="#新建app" class="headerlink" title="新建app"></a>新建app</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python3 manage.py startapp jia_celery</span><br></pre></td></tr></table></figure>
<h4 id="在项目-settings-py中安装"><a href="#在项目-settings-py中安装" class="headerlink" title="在项目/settings.py中安装"></a>在项目/settings.py中安装</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">INSTALLED_APPS = (</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">'jia_celery'</span></span><br><span class="line">  <span class="string">'djcelery'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="在jia-celery目录下创建tasks-py文件"><a href="#在jia-celery目录下创建tasks-py文件" class="headerlink" title="在jia_celery目录下创建tasks.py文件"></a>在jia_celery目录下创建tasks.py文件</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create your tasks here</span></span><br><span class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery</span><br><span class="line"><span class="keyword">from</span> jia_celery.celery <span class="keyword">import</span> app <span class="keyword">as</span> celery_app</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建任务函数</span></span><br><span class="line"><span class="meta">@celery_app.task</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_task1</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"任务函数(my_task1)正在执行...."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@celery_app.task</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_task2</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"任务函数(my_task2)正在执行...."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@celery_app.task</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_task3</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"任务函数(my_task3)正在执行...."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@celery_app.task</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_task4</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"任务函数(my_task4)正在执行...."</span>)</span><br></pre></td></tr></table></figure>
<h4 id="在jia-celery目录下创建celery-py文件"><a href="#在jia-celery目录下创建celery-py文件" class="headerlink" title="在jia_celery目录下创建celery.py文件"></a>在jia_celery目录下创建celery.py文件</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery</span><br><span class="line"><span class="keyword">from</span> jia_celery <span class="keyword">import</span> celeryconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用增加配置的方式创建celery app</span></span><br><span class="line">app = Celery(<span class="string">'jia_celery.tasks'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从单独的配置模块中加载配置</span></span><br><span class="line">app.config_from_object(celeryconfig)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动搜索任务</span></span><br><span class="line">app.autodiscover_tasks([<span class="string">'jia_celery'</span>])</span><br></pre></td></tr></table></figure>
<h4 id="在jia-celery目录下创建celeryconfig-py"><a href="#在jia-celery目录下创建celeryconfig-py" class="headerlink" title="在jia_celery目录下创建celeryconfig.py"></a>在jia_celery目录下创建celeryconfig.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> kombu <span class="keyword">import</span> Exchange, Queue</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置结果存储</span></span><br><span class="line">CELERY_RESULT_BACKEND = <span class="string">'redis://127.0.0.1:6379/9'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置代理人broker</span></span><br><span class="line">BROKER_URL = <span class="string">'redis://127.0.0.1:6379/8'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置任务路由</span></span><br><span class="line">CELERY_ROUTES = (&#123;</span><br><span class="line">    <span class="string">'jia_celery.tasks.my_task1'</span>: &#123;<span class="string">'queue'</span>: <span class="string">'queue1'</span>&#125;,</span><br><span class="line">    <span class="string">'jia_celery.tasks.my_task2'</span>: &#123;<span class="string">'queue'</span>: <span class="string">'queue1'</span>&#125;,</span><br><span class="line">    <span class="string">'jia_celery.tasks.my_task3'</span>: &#123;<span class="string">'queue'</span>: <span class="string">'queue2'</span>&#125;,</span><br><span class="line">    <span class="string">'jia_celery.tasks.my_task4'</span>: &#123;<span class="string">'queue'</span>: <span class="string">'queue2'</span>&#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="迁移数据库"><a href="#迁移数据库" class="headerlink" title="迁移数据库"></a>迁移数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python3 manage.py migrate</span><br></pre></td></tr></table></figure>
<h4 id="启动redis"><a href="#启动redis" class="headerlink" title="启动redis"></a>启动redis</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-server</span><br></pre></td></tr></table></figure>
<h4 id="启动worker"><a href="#启动worker" class="headerlink" title="启动worker"></a>启动worker</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">celery -A jia_celery worker -l info -Q queue1</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Arithmetic@qingjiajiadeMBP MyBlog % celery -A jia_celery worker -l info -Q queue1</span><br><span class="line"> </span><br><span class="line"> -------------- celery@qingjiaowosuanshujiadeMacBook-Pro.local v4.3.0 (rhubarb)</span><br><span class="line">---- **** ----- </span><br><span class="line">--- * ***  * -- Darwin-19.0.0-x86_64-i386-64bit 2019-11-26 21:39:22</span><br><span class="line">-- * - **** --- </span><br><span class="line">- ** ---------- [config]</span><br><span class="line">- ** ---------- .&gt; app:         jia_celery.tasks:0x10823a9b0</span><br><span class="line">- ** ---------- .&gt; transport:   redis://127.0.0.1:6379/8</span><br><span class="line">- ** ---------- .&gt; results:     redis://127.0.0.1:6379/9</span><br><span class="line">- *** --- * --- .&gt; concurrency: 8 (prefork)</span><br><span class="line">-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)</span><br><span class="line">--- ***** ----- </span><br><span class="line"> -------------- [queues]</span><br><span class="line">                .&gt; queue1           exchange=queue1(direct) key=queue1</span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">[tasks]</span><br><span class="line">  . jia_celery.tasks.my_task1</span><br><span class="line">  . jia_celery.tasks.my_task2</span><br><span class="line">  . jia_celery.tasks.my_task3</span><br><span class="line">  . jia_celery.tasks.my_task4</span><br><span class="line"></span><br><span class="line">[2019-11-26 21:39:22,382: INFO/MainProcess] Connected to redis://127.0.0.1:6379/8</span><br><span class="line">[2019-11-26 21:39:22,392: INFO/MainProcess] mingle: searching for neighbors</span><br><span class="line">[2019-11-26 21:39:23,416: INFO/MainProcess] mingle: all alone</span><br><span class="line">[2019-11-26 21:39:23,432: INFO/MainProcess] celery@qingjiaowosuanshujiadeMacBook-Pro.local ready.</span><br><span class="line">^C</span><br><span class="line">worker: Hitting Ctrl+C again will terminate all running tasks!</span><br><span class="line"></span><br><span class="line">worker: Warm shutdown (MainProcess)</span><br><span class="line">Arithmetic@qingjiajiadeMBP MyBlog % celery -A jia_celery worker -l info -Q queue1</span><br><span class="line"> </span><br><span class="line"> -------------- celery@qingjiaowosuanshujiadeMacBook-Pro.local v4.3.0 (rhubarb)</span><br><span class="line">---- **** ----- </span><br><span class="line">--- * ***  * -- Darwin-19.0.0-x86_64-i386-64bit 2019-11-26 21:41:26</span><br><span class="line">-- * - **** --- </span><br><span class="line">- ** ---------- [config]</span><br><span class="line">- ** ---------- .&gt; app:         jia_celery.tasks:0x10d626940</span><br><span class="line">- ** ---------- .&gt; transport:   redis://127.0.0.1:6379/8</span><br><span class="line">- ** ---------- .&gt; results:     redis://127.0.0.1:6379/9</span><br><span class="line">- *** --- * --- .&gt; concurrency: 8 (prefork)</span><br><span class="line">-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)</span><br><span class="line">--- ***** ----- </span><br><span class="line"> -------------- [queues]</span><br><span class="line">                .&gt; queue1           exchange=queue1(direct) key=queue1</span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">[tasks]</span><br><span class="line">  . jia_celery.tasks.my_task1</span><br><span class="line">  . jia_celery.tasks.my_task2</span><br><span class="line">  . jia_celery.tasks.my_task3</span><br><span class="line">  . jia_celery.tasks.my_task4</span><br><span class="line"></span><br><span class="line">[2019-11-26 21:41:27,005: INFO/MainProcess] Connected to redis://127.0.0.1:6379/8</span><br><span class="line">[2019-11-26 21:41:27,017: INFO/MainProcess] mingle: searching for neighbors</span><br><span class="line">[2019-11-26 21:41:28,043: INFO/MainProcess] mingle: all alone</span><br><span class="line">[2019-11-26 21:41:28,062: INFO/MainProcess] celery@qingjiaowosuanshujiadeMacBook-Pro.local ready.</span><br></pre></td></tr></table></figure>
<h4 id="测试任务1、2"><a href="#测试任务1、2" class="headerlink" title="测试任务1、2"></a>测试任务1、2</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Arithmetic@qingjiajiadeMBP MyBlog % python3</span><br><span class="line">Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 26 2018, 19:50:54) </span><br><span class="line">[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; from jia_celery.tasks import *</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; my_task1.delay()</span></span><br><span class="line">&lt;AsyncResult: 7bce3af5-5d5f-4b45-b317-7c47b81c4391&gt;</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; my_task2.delay()</span></span><br><span class="line">&lt;AsyncResult: 6879f8e9-8bdc-4d47-9baf-5aa7e3c303af&gt;</span><br></pre></td></tr></table></figure>
<h4 id="查看queue1-的-worker-执行日志"><a href="#查看queue1-的-worker-执行日志" class="headerlink" title="查看queue1 的 worker 执行日志"></a>查看queue1 的 worker 执行日志</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[2019-11-26 21:42:02,424: INFO/MainProcess] Received task: jia_celery.tasks.my_task1[7bce3af5-5d5f-4b45-b317-7c47b81c4391]  </span><br><span class="line">[2019-11-26 21:42:02,426: WARNING/ForkPoolWorker-8] 任务函数(my_task1)正在执行....</span><br><span class="line">[2019-11-26 21:42:02,430: INFO/ForkPoolWorker-8] Task jia_celery.tasks.my_task1[7bce3af5-5d5f-4b45-b317-7c47b81c4391] succeeded in 0.00366099600068992s: None</span><br><span class="line">[2019-11-26 21:42:21,639: INFO/MainProcess] Received task: jia_celery.tasks.my_task2[6879f8e9-8bdc-4d47-9baf-5aa7e3c303af]  </span><br><span class="line">[2019-11-26 21:42:21,642: WARNING/ForkPoolWorker-2] 任务函数(my_task2)正在执行....</span><br><span class="line">[2019-11-26 21:42:21,646: INFO/ForkPoolWorker-2] Task jia_celery.tasks.my_task2[6879f8e9-8bdc-4d47-9baf-5aa7e3c303af] succeeded in 0.0050763219987857156s: None</span><br></pre></td></tr></table></figure>
<p>如果此时测试task3、4，查看queue1 的 worker 执行日志是不会有对应任务执行的，因为不同任务指定了不同的队列处理</p>
]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>celery</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub博客Hexo配合next主题增加搜索引擎验证</title>
    <url>/2019/11/24/GitHub%E5%8D%9A%E5%AE%A2Hexo%E9%85%8D%E5%90%88next%E4%B8%BB%E9%A2%98%E5%A2%9E%E5%8A%A0%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E9%AA%8C%E8%AF%81/</url>
    <content><![CDATA[<p>GitHub博客Hexo配合next主题增加搜索引擎验证，Github 上利用 hexo 建立的博客是无法被搜索引擎搜索到的。<br><a id="more"></a><br>Github 本身也不会将信息提交给引擎。所以，为了让博客信息被检索到，我们需要手动将博客网站提交给搜索引擎并验证，实际上就是验证网站是我们自己的</p>
<h3 id="提交Google站点"><a href="#提交Google站点" class="headerlink" title="提交Google站点"></a>提交Google站点</h3><p><a href="https://www.google.com/webmasters/tools/home?hl=zh-CN" target="_blank" rel="noopener">Google</a></p>
<h3 id="选择HTML-meta-标签验证"><a href="#选择HTML-meta-标签验证" class="headerlink" title="选择HTML meta 标签验证"></a>选择HTML meta 标签验证</h3><p>Next 主题下，页面的 header 设置在<br><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/themes/</span>hexo-theme-<span class="keyword">next</span><span class="regexp">/layout/</span>_partials<span class="regexp">/head/</span>head.swig</span><br></pre></td></tr></table></figure><br><figure class="highlight django"><table><tr><td class="code"><pre><span class="line"><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> theme.google_site_verification %&#125;</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"google-site-verification"</span> <span class="attr">content</span>=<span class="string">"RkRVaaOa4vX520pamxy6ip0HfuaQ-NCyM1SvGbzqUFA"</span>&gt;</span></span></span><br><span class="line"><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span></span><br></pre></td></tr></table></figure><br>这里的content从Google控制台获取</p>
<h3 id="提交Baidu站点"><a href="#提交Baidu站点" class="headerlink" title="提交Baidu站点"></a>提交Baidu站点</h3><p><a href="http://www.baidu.com/search/url_submit.htm" target="_blank" rel="noopener">Baidu</a></p>
<h3 id="选择HTML-meta-标签验证-1"><a href="#选择HTML-meta-标签验证-1" class="headerlink" title="选择HTML meta 标签验证"></a>选择HTML meta 标签验证</h3><p>Next 主题下，页面的 header 设置在<br><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/themes/</span>hexo-theme-<span class="keyword">next</span><span class="regexp">/layout/</span>_partials<span class="regexp">/head/</span>head.swig</span><br></pre></td></tr></table></figure><br><figure class="highlight django"><table><tr><td class="code"><pre><span class="line"><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> theme.baidu_site_verification %&#125;</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"baidu-site-verification"</span> <span class="attr">content</span>=<span class="string">"es0rExrlvZ"</span>&gt;</span></span></span><br><span class="line"><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span></span><br></pre></td></tr></table></figure><br>这里的content从Baidu控制台获取</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>github</tag>
        <tag>baidu</tag>
        <tag>google</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS下Git与GitHub</title>
    <url>/2019/11/24/MacOS%E4%B8%8BGit%E4%B8%8EGitHub/</url>
    <content><![CDATA[<p>还是不知道写啥，本文是有关Mac OS上Git与GitHub相关配置的介绍说明<br><a id="more"></a></p>
<h4 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h4><p>该命令也可以升级最新的git<br><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">brew install git</span><br></pre></td></tr></table></figure></p>
<h4 id="查看git指向和版本信息"><a href="#查看git指向和版本信息" class="headerlink" title="查看git指向和版本信息"></a>查看git指向和版本信息</h4><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">which git</span><br><span class="line">/usr/bin/git</span><br><span class="line">git --version</span><br><span class="line">git version 2.21.0 (Apple Git-122.2)</span><br></pre></td></tr></table></figure>
<h4 id="配置github用户名和邮箱"><a href="#配置github用户名和邮箱" class="headerlink" title="配置github用户名和邮箱"></a>配置github用户名和邮箱</h4><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">git config --global user.name "ArithmeticJia"</span><br><span class="line">git config --global user.email "1097197237@qq.com"</span><br></pre></td></tr></table></figure>
<h4 id="生成ssh密钥"><a href="#生成ssh密钥" class="headerlink" title="生成ssh密钥"></a>生成ssh密钥</h4><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C "1097197237@qq.com"</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/Users/Arithmetic/.ssh/id_rsa): </span><br><span class="line">/Users/Arithmetic/.ssh/id_rsa already exists.</span><br><span class="line">Overwrite (y/n)? y</span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /Users/Arithmetic/.ssh/id_rsa.</span><br></pre></td></tr></table></figure>
<h4 id="在GitHub上新增ssh密钥"><a href="#在GitHub上新增ssh密钥" class="headerlink" title="在GitHub上新增ssh密钥"></a>在GitHub上新增ssh密钥</h4><p>复制密钥<br><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">cat .ssh/id_rsa.pub</span><br></pre></td></tr></table></figure><br>路径一般是<br><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">/User/ArithmeticJia/.ssh</span><br></pre></td></tr></table></figure><br>登录GitHub（默认你已经注册了GitHub账号），添加ssh key，点击Settings，如图<br><img src="https://www.guanacossj.com/media/articlebodypics/E901D42E-753A-4E46-BC71-05C54C555B0D.png" alt=""></p>
<h4 id="链接验证"><a href="#链接验证" class="headerlink" title="链接验证"></a>链接验证</h4><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="code"><pre><span class="line">Hi Arithmeticjia! You've successfully authenticated, but GitHub does not provide shell access.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Django个人博客搭建教程-阿里云部署(Ubuntu+Nginx+uwsgi)升级https</title>
    <url>/2019/11/24/Django%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B-%E9%98%BF%E9%87%8C%E4%BA%91%E9%83%A8%E7%BD%B2(Ubuntu+Nginx+uwsgi)%E5%8D%87%E7%BA%A7https/</url>
    <content><![CDATA[<p>更安全的https<br><a id="more"></a></p>
<h4 id="一、阿里云申请SSL证书"><a href="#一、阿里云申请SSL证书" class="headerlink" title="一、阿里云申请SSL证书"></a>一、阿里云申请SSL证书</h4><p>略</p>
<h4 id="二、将pem和key放在nginx目录下"><a href="#二、将pem和key放在nginx目录下" class="headerlink" title="二、将pem和key放在nginx目录下"></a>二、将pem和key放在nginx目录下</h4><p>仅供参考<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/etc/nginx/cert/1831344_www.guanacossj.com.pem;      # 路径/pem文件</span><br><span class="line">/etc/nginx/cert/1831344_www.guanacossj.com.key;      # 路径/key文件</span><br></pre></td></tr></table></figure></p>
<h4 id="三、修改nginx-conf"><a href="#三、修改nginx-conf" class="headerlink" title="三、修改nginx.conf"></a>三、修改nginx.conf</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">  server &#123;</span><br><span class="line">      listen 80;</span><br><span class="line">      server_name  _;</span><br><span class="line">      return 301 https://www.guanacossj.com$request_uri;</span><br><span class="line">   &#125; </span><br><span class="line"> </span><br><span class="line">  server &#123;</span><br><span class="line">      listen       443 default_server;</span><br><span class="line">      listen       [::]:443 default_server;</span><br><span class="line">      server_name  _;</span><br><span class="line">      ssl on;</span><br><span class="line">      ssl_certificate   /etc/nginx/cert/1831344_www.guanacossj.com.pem;     # 路径/pem文件</span><br><span class="line">      ssl_certificate_key  /etc/nginx/cert/1831344_www.guanacossj.com.key;  # 路径/key文件</span><br><span class="line">      ssl_session_timeout 5m;</span><br><span class="line">      ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">      ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">      ssl_prefer_server_ciphers on;</span><br><span class="line">      charset     utf-8;</span><br><span class="line">      client_max_body_size 1000M;   # adjust to taste</span><br><span class="line">      include /etc/nginx/default.d/*.conf;</span><br><span class="line">      location /static &#123;</span><br><span class="line">      alias /home/MyBlog/static; # ָÏdjangoµÄtaticĿ¼</span><br><span class="line">      &#125;</span><br><span class="line">      location /static/rest_framework/ &#123;</span><br><span class="line">      alias /usr/local/lib/python3.6/dist-packages/rest_framework/static/rest_framework/</span><br><span class="line">    ;&#125;</span><br><span class="line"> </span><br><span class="line">    # Finally, send all non-media requests to the Django server.</span><br><span class="line">    location / &#123;</span><br><span class="line">        uwsgi_pass  127.0.0.1:8000;</span><br><span class="line">        #uwsgi_pass  django;</span><br><span class="line">        include     uwsgi_params; 	# the uwsgi_params file you installed           </span><br><span class="line">        proxy_redirect off;</span><br><span class="line">	      proxy_http_version 1.1;</span><br><span class="line">        proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">        proxy_set_header Connection "upgrade";</span><br><span class="line">	      uwsgi_send_timeout 600;</span><br><span class="line">        uwsgi_connect_timeout 600;  </span><br><span class="line">        uwsgi_read_timeout 600; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里把你原来的监听80端口改为监听443端口即可，我之前一直不成功主要是我试图再加一个443端口的监听，应该也可以吧，不管了，反正这样肯定没问题，然后如果还想让http能购访问，就做个重定向。</p>
<h4 id="四、重启nginx"><a href="#四、重启nginx" class="headerlink" title="四、重启nginx"></a>四、重启nginx</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service nginx restart</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>阿里云</tag>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title>Django个人博客搭建教程-REST风格API</title>
    <url>/2019/11/24/Django%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B-REST%E9%A3%8E%E6%A0%BCAPI/</url>
    <content><![CDATA[<p>Django REST Framework 是一个强大且灵活的工具包，用以构建Web API<br>Django REST Framework可以在Django的基础上迅速实现API，并且自身还带有WEB的测试页面，可以方便的测试自己的API<br><a id="more"></a></p>
<h4 id="一、安装依赖"><a href="#一、安装依赖" class="headerlink" title="一、安装依赖"></a>一、安装依赖</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install djangorestframework</span><br></pre></td></tr></table></figure>
<h4 id="二、在settings-py中添加应用"><a href="#二、在settings-py中添加应用" class="headerlink" title="二、在settings.py中添加应用"></a>二、在settings.py中添加应用</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">INSTALLED_APPS = [</span><br><span class="line">    ....</span><br><span class="line"> </span><br><span class="line"><span class="string">'rest_framework'</span>,    <span class="comment"># 加上这句，加在api的前面</span></span><br><span class="line">    ....             <span class="comment"># 后面是你的应用名称</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h4 id="三、路由注册"><a href="#三、路由注册" class="headerlink" title="三、路由注册"></a>三、路由注册</h4><p>子urls.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> url,include</span><br><span class="line"><span class="keyword">from</span> JiaBlog <span class="keyword">import</span> views</span><br><span class="line"><span class="keyword">from</span> rest_framework <span class="keyword">import</span> routers</span><br><span class="line"> </span><br><span class="line">app_name = <span class="string">'JiaBlog'</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 定义路由地址</span></span><br><span class="line">route = routers.DefaultRouter()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 注册新的路由地址</span></span><br><span class="line">route.register(<span class="string">r'getarticleinfo'</span> , views.GetArticleInfo)</span><br><span class="line"> </span><br><span class="line">urlpatterns = [</span><br><span class="line">    ...</span><br><span class="line">    url(<span class="string">'api/'</span>, include(route.urls)),</span><br><span class="line">]</span><br></pre></td></tr></table></figure><br>主urls.py<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">"""MyBlog URL Configuration</span></span><br><span class="line"><span class="string">The `urlpatterns` list routes URLs to views. For more information please see:</span></span><br><span class="line"><span class="string">    https://docs.djangoproject.com/en/2.1/topics/http/urls/</span></span><br><span class="line"><span class="string">Examples:</span></span><br><span class="line"><span class="string">Function views</span></span><br><span class="line"><span class="string">    1. Add an import:  from my_app import views</span></span><br><span class="line"><span class="string">    2. Add a URL to urlpatterns:  path('', views.home, name='home')</span></span><br><span class="line"><span class="string">Class-based views</span></span><br><span class="line"><span class="string">    1. Add an import:  from other_app.views import Home</span></span><br><span class="line"><span class="string">    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')</span></span><br><span class="line"><span class="string">Including another URLconf</span></span><br><span class="line"><span class="string">    1. Import the include() function: from django.urls import include, path</span></span><br><span class="line"><span class="string">    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> include</span><br><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> url</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">from</span> django.conf <span class="keyword">import</span> settings</span><br><span class="line"><span class="keyword">from</span> MyBlog.settings <span class="keyword">import</span> MEDIA_ROOT</span><br><span class="line"><span class="keyword">from</span> django.conf.urls.static <span class="keyword">import</span> static</span><br><span class="line"><span class="keyword">from</span> JiaBlog <span class="keyword">import</span> views</span><br><span class="line"><span class="keyword">from</span> haystack.views <span class="keyword">import</span> SearchView</span><br><span class="line"><span class="keyword">from</span> django.views.static <span class="keyword">import</span> serve</span><br><span class="line"><span class="comment">#from django.views import static</span></span><br><span class="line"> </span><br><span class="line">urlpatterns = [</span><br><span class="line">    url(<span class="string">r'^$'</span>, views.blog_index),</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">    path(<span class="string">'JiaBlog/'</span>, include(<span class="string">'JiaBlog.urls'</span>, namespace=<span class="string">"JiaBlog"</span>)),</span><br><span class="line">]+static(settings.MEDIA_URL,document_root=settings.MEDIA_ROOT)</span><br></pre></td></tr></table></figure></p>
<h4 id="四、视图函数"><a href="#四、视图函数" class="headerlink" title="四、视图函数"></a>四、视图函数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> rest_framework <span class="keyword">import</span> serializers,viewsets</span><br><span class="line"><span class="keyword">from</span> JiaBlog.models <span class="keyword">import</span> Articles</span><br><span class="line"><span class="comment"># Create your views here.</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticlesSerializers</span><span class="params">(serializers.ModelSerializer)</span>:</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Meta</span>:</span></span><br><span class="line">        model = Articles                        <span class="comment"># 指定的模型类</span></span><br><span class="line">        fields = (<span class="string">'id'</span>, <span class="string">'title'</span>, <span class="string">'body'</span>, <span class="string">'timestamp'</span>,<span class="string">'authorname'</span>,<span class="string">'views'</span>,<span class="string">'tags'</span>,<span class="string">'category'</span>)  <span class="comment"># 需要序列化的属性</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GetArticleInfo</span><span class="params">(viewsets.ModelViewSet)</span>:</span></span><br><span class="line">    queryset = Articles.objects.all().order_by(<span class="string">'-id'</span>)</span><br><span class="line">    serializer_class = ArticlesSerializers</span><br></pre></td></tr></table></figure>
<h4 id="五、数据模型"><a href="#五、数据模型" class="headerlink" title="五、数据模型"></a>五、数据模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Articles</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    id = models.AutoField(primary_key=<span class="literal">True</span>)                         <span class="comment"># id</span></span><br><span class="line">    title = models.CharField(max_length = <span class="number">150</span>)                      <span class="comment"># 博客标题</span></span><br><span class="line">    body = models.TextField()                                       <span class="comment"># 博客正文</span></span><br><span class="line">    timestamp = models.DateTimeField()                              <span class="comment"># 创建时间</span></span><br><span class="line">    authorname = models.ForeignKey(<span class="string">'JiaBlog.BlogUser'</span>,on_delete=models.CASCADE)        <span class="comment"># 作者姓名</span></span><br><span class="line">    views = models.PositiveIntegerField(default=<span class="number">0</span>)</span><br><span class="line">    category = models.ForeignKey(Category,on_delete=models.CASCADE,primary_key=<span class="literal">False</span>)</span><br><span class="line">    tags = models.ManyToManyField(Tag, blank=<span class="literal">True</span>,null=<span class="literal">True</span>)</span><br><span class="line">    greats = models.PositiveIntegerField(default=<span class="number">0</span>)</span><br><span class="line">    comments = models.IntegerField(default=<span class="number">0</span>)</span><br><span class="line">    status = models.CharField(max_length=<span class="number">20</span>, default=<span class="string">"DEL"</span>)</span><br><span class="line">    brief = models.CharField(max_length=<span class="number">200</span>,blank=<span class="literal">True</span>,null=<span class="literal">True</span>)</span><br><span class="line">    pic = models.ImageField(upload_to=<span class="string">'jiablogimages'</span>)</span><br><span class="line">    <span class="comment"># bodypic = models.ImageField(upload_to='jiablogimages',blank=True,null=True)</span></span><br><span class="line">    istop = models.CharField(max_length=<span class="number">5</span>,default=<span class="string">''</span>,null=<span class="literal">True</span>,blank=<span class="literal">True</span>)</span><br><span class="line">    articlebodybrief = models.TextField(blank=<span class="literal">True</span>,null=<span class="literal">True</span>)</span><br><span class="line">    last_edit_timestamp = models.DateTimeField(auto_now=<span class="literal">True</span>,verbose_name=<span class="string">"更新时间"</span>,editable=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h4><figure class="highlight taggerscript"><table><tr><td class="code"><pre><span class="line">GET /JiaBlog/api/getarticleinfo/</span><br><span class="line">HTTP 200 OK</span><br><span class="line">Allow: GET, POST, HEAD, OPTIONS</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Vary: Accept</span><br><span class="line"> </span><br><span class="line">[</span><br><span class="line">&#123;</span><br><span class="line">        "id": 3,</span><br><span class="line">        "title": "python中的GIL锁",</span><br><span class="line">        "body": "为什么我们说python中无法实现真正的多线程呢，这是因为在C语言写的python解释器中存在全局解释器锁，由于全局解释器锁的存在，在同一时间内，python解释器只能运行一个线程的代码，这大大影响了python多线程的性能。而这个解释器锁由于历史原因，现在几乎无法消除。<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>python GIL 之所以会影响多线程等性能，是因为在多线程的情况下，只有当线程获得了一个全局锁的时候，那么该线程的代码才能运行，而全局锁只有一个，所以使用python多线程，在同一时刻也只有一个线程在运行，因此在即使在多核的情况下也只能发挥出单核的性能。<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>对于有io操作的线程，当一个线程在做io操作的时候，因为io操作不需要cpu，所以，这个时候，python会释放python全局锁，这样其他需要运行的线程就会使用该锁。",</span><br><span class="line">        "timestamp": "2019-02-21T22:01:52",</span><br><span class="line">        "authorname": 1,</span><br><span class="line">        "views": 2249,</span><br><span class="line">        "tags": [</span><br><span class="line">            3</span><br><span class="line">        ],</span><br><span class="line">        "category": 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        "id": 2,</span><br><span class="line">        "title": "Django和Flask的区别",</span><br><span class="line">        "body": "##写在最前面：<span class="symbol">\r</span><span class="symbol">\n</span>python web开发有很多常用的框架，主要包括Django，Flask，Tornado，Diesel，Cubes，Pulsar，Falcon，webpy，大家最熟知的还是Django和Flask，今天就来简单介绍一下Django和Flask的区别，本博客就是使用Django开发的，Flask不是很了解，因为没有用过，今天就借花献佛，简单介绍一下。<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>##Flask<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>Flask确实很“轻”，不愧是Micro Framework，从Django转向Flask的开发者一定会如此感慨，除非二者均为深入使用过<span class="symbol">\r</span><span class="symbol">\n</span>Flask自由、灵活，可扩展性强，第三方库的选择面广，开发时可以结合自己最喜欢用的轮子，也能结合最流行最强大的Python库<span class="symbol">\r</span><span class="symbol">\n</span>    入门简单，即便没有多少web开发经验，也能很快做出网站<span class="symbol">\r</span><span class="symbol">\n</span>    非常适用于小型网站<span class="symbol">\r</span><span class="symbol">\n</span>    非常适用于开发web服务的API<span class="symbol">\r</span><span class="symbol">\n</span>    开发大型网站无压力，但代码架构需要自己设计，开发成本取决于开发者的能力和经验<span class="symbol">\r</span><span class="symbol">\n</span>    各方面性能均等于或优于Django<span class="symbol">\r</span><span class="symbol">\n</span>    Django自带的或第三方的好评如潮的功能，Flask上总会找到与之类似第三方库<span class="symbol">\r</span><span class="symbol">\n</span>    Flask灵活开发，Python高手基本都会喜欢Flask，但对Django却可能褒贬不一<span class="symbol">\r</span><span class="symbol">\n</span>    Flask与关系型数据库的配合使用不弱于Django，而其与NoSQL数据库的配合远远优于Django<span class="symbol">\r</span><span class="symbol">\n</span>    Flask比Django更加Pythonic，与Python的philosophy更加吻合<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>##Django<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>Django太重了，除了web框架，自带ORM和模板引擎，灵活和自由度不够高<span class="symbol">\r</span><span class="symbol">\n</span>    Django能开发小应用，但总会有“杀鸡焉用牛刀”的感觉<span class="symbol">\r</span><span class="symbol">\n</span>    Django的自带ORM非常优秀，综合评价略高于SQLAlchemy<span class="symbol">\r</span><span class="symbol">\n</span>    Django自带的模板引擎简单好用，但其强大程度和综合评价略低于Jinja<span class="symbol">\r</span><span class="symbol">\n</span>    Django自带ORM也使Django与关系型数据库耦合度过高，如果想使用MongoDB等NoSQL数据，需要选取合适的第三方库，且总感觉Django+SQL才是天生一对的搭配，Django+NoSQL砍掉了Django的半壁江山<span class="symbol">\r</span><span class="symbol">\n</span>    Django目前支持Jinja等非官方模板引擎<span class="symbol">\r</span><span class="symbol">\n</span>    Django自带的数据库管理app好评如潮<span class="symbol">\r</span><span class="symbol">\n</span>    Django非常适合企业级网站的开发：快速、靠谱、稳定<span class="symbol">\r</span><span class="symbol">\n</span>    Django成熟、稳定、完善，但相比于Flask，Django的整体生态相对封闭<span class="symbol">\r</span><span class="symbol">\n</span>    Django是Python web框架的先驱，用户多，第三方库最丰富，最好的Python库，如果不能直接用到Django中，也一定能找到与之对应的移植<span class="symbol">\r</span><span class="symbol">\n</span>    Django上手也比较容易，开发文档详细、完善，相关资料丰富",</span><br><span class="line">        "timestamp": "2019-02-21T21:25:28",</span><br><span class="line">        "authorname": 1,</span><br><span class="line">        "views": 2599,</span><br><span class="line">        "tags": [</span><br><span class="line">            1,</span><br><span class="line">            2</span><br><span class="line">        ],</span><br><span class="line">        "category": 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        "id": 1,</span><br><span class="line">        "title": "用Django写一个自己的博客网站",</span><br><span class="line">        "body": "##写在最前面：<span class="symbol">\r</span><span class="symbol">\n</span>想用Django写网站很久了，本地也建立过很多demo，对于整个框架的入门算是熟练了。用pycharm可 <span class="symbol">\r</span><span class="symbol">\n</span>以很方便的新建一个Django工程。专业版的Pycharm是自带Django的，目前Diango的最新版本应该是2.1。<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>IDE:Pycharm<span class="symbol">\r</span><span class="symbol">\n</span>python版本：3.6<span class="symbol">\r</span><span class="symbol">\n</span>操作系统：macOS Mojave<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>![图片](/media/images/blog1body1.png)<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>这是用Django2.1写的一个个人博客的展示，还有一个含有带登录、注册、登出的session控制的监控系统，博客本身内置下载、天气查询、Google在线翻译，还可以发送QQ邮件。<span class="symbol">\r</span><span class="symbol">\n</span>下面先贴一下目录结构：<span class="symbol">\r</span><span class="symbol">\n</span><span class="symbol">\r</span><span class="symbol">\n</span>![图片](/static/images/blog1body2.jpg)",</span><br><span class="line">        "timestamp": "2019-02-21T21:20:23",</span><br><span class="line">        "authorname": 1,</span><br><span class="line">        "views": 2657,</span><br><span class="line">        "tags": [</span><br><span class="line">            1</span><br><span class="line">        ],</span><br><span class="line">        "category": 1</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>restframework</tag>
      </tags>
  </entry>
  <entry>
    <title>Vue.js入门（四）---用Pycharm创建你的第一个完整的HelloVue</title>
    <url>/2019/11/23/Vue-js%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89-%E7%94%A8Pycharm%E5%88%9B%E5%BB%BA%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84HelloVue/</url>
    <content><![CDATA[<p>本文主要介绍了如何在Pycharm中构建一个简单的vue应用,摘要要写50个字，不然markdown格式会很丑，我也不知道要写啥，感觉没啥好写的，现在应该差不多了<br><a id="more"></a></p>
<h4 id="一、在Pycharm中下载Vue-js插件"><a href="#一、在Pycharm中下载Vue-js插件" class="headerlink" title="一、在Pycharm中下载Vue.js插件"></a>一、在Pycharm中下载Vue.js插件</h4><p><img src="https://www.guanacossj.com/media/articlebodypics/1571819210811.jpg" alt=""></p>
<h4 id="二、新建一个Vue-js项目"><a href="#二、新建一个Vue-js项目" class="headerlink" title="二、新建一个Vue.js项目"></a>二、新建一个Vue.js项目</h4><p><img src="https://www.guanacossj.com/media/articlebodypics/1571819312914.jpg" alt=""><br>然后等待安装启动完成，这里提示我要不要用淘宝源，我果断同意啊</p>
<h4 id="三、项目启动"><a href="#三、项目启动" class="headerlink" title="三、项目启动"></a>三、项目启动</h4><p><img src="https://www.guanacossj.com/media/articlebodypics/1571819476507.jpg" alt=""></p>
<h4 id="四、项目目录结构"><a href="#四、项目目录结构" class="headerlink" title="四、项目目录结构"></a>四、项目目录结构</h4><p><img src="https://www.guanacossj.com/media/articlebodypics/1571819572736.jpg" alt=""><br><figure class="highlight haml"><table><tr><td class="code"><pre><span class="line">'''</span><br><span class="line">-<span class="ruby">node_modules：项目的依赖</span></span><br><span class="line"><span class="ruby">-public</span></span><br><span class="line"><span class="ruby">    -favicon.ico  网页的图标</span></span><br><span class="line"><span class="ruby">    -index.html   主页面</span></span><br><span class="line"><span class="ruby">-src：我们需要关注的</span></span><br><span class="line"><span class="ruby">    -assets：方静态文件</span></span><br><span class="line"><span class="ruby">    -components：小组件</span></span><br><span class="line"><span class="ruby">    -views  ：页面组件</span></span><br><span class="line"><span class="ruby">    -App.vue ：主组件</span></span><br><span class="line"><span class="ruby">    -main.js ：项目主入口js</span></span><br><span class="line"><span class="ruby">    -router.js： 路由相关，以后配置路由，都在这里配置</span></span><br><span class="line"><span class="ruby">    -store.js  ：vuex相关，状态管理器</span></span><br><span class="line"><span class="ruby">-package.json   项目的依赖文件</span></span><br><span class="line"><span class="ruby"><span class="string">''</span><span class="string">'</span></span></span><br></pre></td></tr></table></figure></p>
<h4 id="五、修改默认的启动页"><a href="#五、修改默认的启动页" class="headerlink" title="五、修改默认的启动页"></a>五、修改默认的启动页</h4><p>在components下新建一个HelloVue<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"hello"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>&#123;&#123;msg&#125;&#125;<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="actionscript">        name: <span class="string">"HelloVue"</span>,</span></span><br><span class="line">        data () &#123;</span><br><span class="line"><span class="actionscript">        <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="actionscript">            msg: <span class="string">'HelloVue'</span></span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">style</span> <span class="attr">scoped</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure><br>修改App.vue<br><figure class="highlight clean"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> HelloWorld <span class="keyword">from</span> <span class="string">'./components/HelloVue.vue'</span></span><br></pre></td></tr></table></figure><br>效果图<br><img src="https://www.guanacossj.com/media/articlebodypics/1571819861870.jpg" alt=""></p>
]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯云Ubuntu下Collectd+Grafana+Influxdb的搭建教程</title>
    <url>/2019/11/23/%E8%85%BE%E8%AE%AF%E4%BA%91Ubuntu%E4%B8%8BCollectd-Grafana-Influxdb%E7%9A%84%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>本文介绍了腾讯云服务器Ubuntu下监控平台的搭建教程，主要组件分为三个部分，grafana、collectd、influxdb。grafana主要用来作为监控的前端展示，collectd负责采集服务器性能指标，influxdb则是一款开源的时序数据库，负责采集数据的存储<br><a id="more"></a></p>
<h2 id="一、安装Collectd"><a href="#一、安装Collectd" class="headerlink" title="一、安装Collectd"></a>一、安装Collectd</h2><h3 id="1、安装"><a href="#1、安装" class="headerlink" title="1、安装"></a>1、安装</h3><p><code>sudo apt install collectd collectd-utils</code></p>
<h3 id="2、修改collectd-conf"><a href="#2、修改collectd-conf" class="headerlink" title="2、修改collectd.conf"></a>2、修改collectd.conf</h3><p>开启常用插件<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LoadPlugin cpu</span><br><span class="line">LoadPlugin df</span><br><span class="line">LoadPlugin disk</span><br><span class="line">LoadPlugin interface</span><br><span class="line">LoadPlugin irq</span><br><span class="line">LoadPlugin load</span><br><span class="line">LoadPlugin memory</span><br><span class="line">LoadPlugin mysql</span><br><span class="line">LoadPlugin network</span><br><span class="line">LoadPlugin processes</span><br><span class="line">LoadPlugin rrdtool</span><br><span class="line"> </span><br><span class="line">&lt;Plugin cpu&gt;</span><br><span class="line">	ReportByCpu true</span><br><span class="line">	ReportByState true</span><br><span class="line">	ValuesPercentage false</span><br><span class="line">&lt;/Plugin&gt;</span><br><span class="line"> </span><br><span class="line">&lt;Plugin interface&gt;</span><br><span class="line">	Interface "eth0"</span><br><span class="line">	IgnoreSelected false</span><br><span class="line"><span class="meta">#</span><span class="bash">	ReportInactive <span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">	UniqueName <span class="literal">false</span></span></span><br><span class="line">&lt;/Plugin&gt;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">&lt;Plugin network&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash">	<span class="comment"># client setup:</span></span></span><br><span class="line">Server "127.0.0.1" "25826"</span><br><span class="line"><span class="meta">#</span><span class="bash">	&lt;Server <span class="string">"239.192.74.66"</span> <span class="string">"25826"</span>&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash">		SecurityLevel Encrypt</span></span><br><span class="line"><span class="meta">#</span><span class="bash">		Username <span class="string">"user"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">		Password <span class="string">"secret"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">		Interface <span class="string">"eth0"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">		ResolveInterval 14400</span></span><br><span class="line"><span class="meta">#</span><span class="bash">	&lt;/Server&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash">	TimeToLive 128</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span><span class="bash">	<span class="comment"># server setup:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">	Listen <span class="string">"ff18::efc0:4a42"</span> <span class="string">"25826"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">	&lt;Listen <span class="string">"239.192.74.66"</span> <span class="string">"25826"</span>&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash">		SecurityLevel Sign</span></span><br><span class="line"><span class="meta">#</span><span class="bash">		AuthFile <span class="string">"/etc/collectd/passwd"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">		Interface <span class="string">"eth0"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">	&lt;/Listen&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash">	MaxPacketSize 1452</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span><span class="bash">	<span class="comment"># proxy setup (client and server as above):</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">	Forward <span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span><span class="bash">	<span class="comment"># statistics about the network plugin itself</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">	ReportStats <span class="literal">false</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span><span class="bash">	<span class="comment"># "garbage collection"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">	CacheFlush 1800</span></span><br><span class="line">&lt;/Plugin&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="3、常用命令"><a href="#3、常用命令" class="headerlink" title="3、常用命令"></a>3、常用命令</h3><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">sudo <span class="meta-keyword">/etc/</span>init.d/collectd start</span><br><span class="line">sudo <span class="meta-keyword">/etc/</span>init.d/collectd restart</span><br></pre></td></tr></table></figure>
<h2 id="二、-安装Influxdb"><a href="#二、-安装Influxdb" class="headerlink" title="二、 安装Influxdb"></a>二、 安装Influxdb</h2><h3 id="1、安装-1"><a href="#1、安装-1" class="headerlink" title="1、安装"></a>1、安装</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> influxdb</span><br><span class="line">sudo apt <span class="keyword">install</span> influxdb-<span class="keyword">client</span></span><br></pre></td></tr></table></figure>
<h3 id="2、修改influxdb-conf"><a href="#2、修改influxdb-conf" class="headerlink" title="2、修改influxdb.conf"></a>2、修改influxdb.conf</h3><figure class="highlight nix"><table><tr><td class="code"><pre><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="comment">### [collectd]</span></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="comment">### Controls one or many listeners for collectd data.</span></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"> </span><br><span class="line">  [[collectd]]</span><br><span class="line">  <span class="attr">enabled</span> = <span class="literal">true</span></span><br><span class="line">  <span class="attr">bind-address</span> = <span class="string">"127.0.0.1:25826"</span></span><br><span class="line">  <span class="attr">database</span> = <span class="string">"collectdb"</span></span><br><span class="line">  <span class="comment"># retention-policy = ""</span></span><br><span class="line">  <span class="attr">typesdb</span> = <span class="string">"/usr/share/collectd/types.db"</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment"># These next lines control how batching works. You should have this enabled</span></span><br><span class="line">  <span class="comment"># otherwise you could get dropped metrics or poor performance. Batching</span></span><br><span class="line">  <span class="comment"># will buffer points in memory if you have many coming in.</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment"># Flush if this many points get buffered</span></span><br><span class="line">  <span class="attr">batch-size</span> = <span class="number">5000</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment"># Number of batches that may be pending in memory</span></span><br><span class="line">  <span class="comment"># batch-pending = 10</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment"># Flush at least this often even if we haven't hit buffer limit</span></span><br><span class="line">  <span class="attr">batch-timeout</span> = <span class="string">"10s"</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment"># UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.</span></span><br><span class="line">  <span class="attr">read-buffer</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h3 id="3、常用命令-1"><a href="#3、常用命令-1" class="headerlink" title="3、常用命令"></a>3、常用命令</h3><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">sudo<span class="built_in"> service </span>influxdb status</span><br><span class="line"> </span><br><span class="line">sudo<span class="built_in"> service </span>influxdb start</span><br></pre></td></tr></table></figure>
<h3 id="4、新建数据库"><a href="#4、新建数据库" class="headerlink" title="4、新建数据库"></a>4、新建数据库</h3><figure class="highlight n1ql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> collectdb</span><br></pre></td></tr></table></figure>
<h3 id="5、查看端口是否监听成功"><a href="#5、查看端口是否监听成功" class="headerlink" title="5、查看端口是否监听成功"></a>5、查看端口是否监听成功</h3><figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">netstat -anp<span class="string">| grep 25826</span></span><br></pre></td></tr></table></figure>
<h3 id="6、查看数据"><a href="#6、查看数据" class="headerlink" title="6、查看数据"></a>6、查看数据</h3><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">root@VM<span class="number">-0</span><span class="number">-16</span>-ubuntu:~# influx</span><br><span class="line">Visit https://enterprise.influxdata.com <span class="keyword">to</span> register <span class="keyword">for</span> updates, InfluxDB <span class="keyword">server</span> management, <span class="keyword">and</span> monitoring.</span><br><span class="line">Connected <span class="keyword">to</span> http://localhost:<span class="number">8086</span> <span class="keyword">version</span> <span class="number">1.1</span><span class="number">.1</span></span><br><span class="line">InfluxDB shell <span class="keyword">version</span>: <span class="number">1.1</span><span class="number">.1</span></span><br><span class="line">&gt; use collectdb</span><br><span class="line"><span class="keyword">Using</span> <span class="keyword">database</span> collectdb</span><br><span class="line">&gt; <span class="keyword">show</span> field keys;</span><br><span class="line"><span class="type">name</span>: cpu_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: df_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: disk_io_time</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: disk_read</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: disk_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: disk_weighted_io_time</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: disk_write</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: entropy_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: interface_rx</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: interface_tx</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: irq_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: load_longterm</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: load_midterm</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: load_shortterm</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: memory_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: processes_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: swap_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line"><span class="type">name</span>: users_value</span><br><span class="line">fieldKey	fieldType</span><br><span class="line"><span class="comment">--------	---------</span></span><br><span class="line"><span class="keyword">value</span>		<span class="type">float</span></span><br><span class="line"> </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<h3 id="7、通过sql显示15条cpu-value的信息"><a href="#7、通过sql显示15条cpu-value的信息" class="headerlink" title="7、通过sql显示15条cpu_value的信息"></a>7、通过sql显示15条cpu_value的信息</h3><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">&gt; select * <span class="keyword">from</span> cpu_value limit 15;</span><br><span class="line">name: cpu_value</span><br><span class="line">time			host		<span class="built_in">	instance	type	</span>type_instance	value</span><br><span class="line">----			----			--------	----	-------------	-----</span><br><span class="line">1573975276185910000	localhost.localdomain	0		cpu<span class="built_in">	user	</span>3429</span><br><span class="line">1573975276185917000	localhost.localdomain	0		cpu<span class="built_in">	system	</span>2646</span><br><span class="line">1573975276185920000	localhost.localdomain	0		cpu	wait	4424</span><br><span class="line">1573975276185936000	localhost.localdomain	0		cpu	nice	149</span><br><span class="line">1573975276185939000	localhost.localdomain	0		cpu	interrupt	0</span><br><span class="line">1573975276185942000	localhost.localdomain	0		cpu	softirq17</span><br><span class="line">1573975276185945000	localhost.localdomain	0		cpu	steal	0</span><br><span class="line">1573975276185947000	localhost.localdomain	0		cpu	idle	122528</span><br><span class="line">1573975286185912000	localhost.localdomain	0		cpu<span class="built_in">	user	</span>3443</span><br><span class="line">1573975286185919000	localhost.localdomain	0		cpu<span class="built_in">	system	</span>2658</span><br><span class="line">1573975286185923000	localhost.localdomain	0		cpu	wait	4428</span><br><span class="line">1573975286185927000	localhost.localdomain	0		cpu	nice	149</span><br><span class="line">1573975286185931000	localhost.localdomain	0		cpu	interrupt	0</span><br><span class="line">1573975286185935000	localhost.localdomain	0		cpu	softirq17</span><br><span class="line">1573975286185937000	localhost.localdomain	0		cpu	steal	0</span><br><span class="line"> </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<h2 id="三、安装Grafana"><a href="#三、安装Grafana" class="headerlink" title="三、安装Grafana"></a>三、安装Grafana</h2><h3 id="1、安装grafana"><a href="#1、安装grafana" class="headerlink" title="1、安装grafana"></a>1、安装grafana</h3><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">wget http<span class="variable">s:</span>//<span class="keyword">dl</span>.grafana.<span class="keyword">com</span>/oss/release/grafana_6.<span class="number">4.4</span>_amd64.<span class="keyword">deb</span></span><br><span class="line">sudo dpkg -i grafana_6.<span class="number">4.4</span>_amd64.<span class="keyword">deb</span></span><br></pre></td></tr></table></figure>
<h3 id="2、启动"><a href="#2、启动" class="headerlink" title="2、启动"></a>2、启动</h3><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">sudo<span class="built_in"> service </span>grafana-server start</span><br></pre></td></tr></table></figure>
<h3 id="3、配置grafana"><a href="#3、配置grafana" class="headerlink" title="3、配置grafana"></a>3、配置grafana</h3><p><code>访问http://127.0.0.1:3000，如果是腾讯云就是你的ip:3000</code></p>
]]></content>
      <categories>
        <category>Collectd</category>
      </categories>
      <tags>
        <tag>grafana</tag>
        <tag>collectd</tag>
        <tag>influxdb</tag>
      </tags>
  </entry>
  <entry>
    <title>Welcome to my new blog</title>
    <url>/2019/11/23/Welcome-to-my-new-blog/</url>
    <content><![CDATA[<p>欢迎来到我的博客，更多精彩请点进来<br><a id="more"></a></p>
<h3 id="我的主页"><a href="#我的主页" class="headerlink" title="我的主页"></a>我的主页</h3><p><a href="https://www.guanacossj.com" target="_blank" rel="noopener" title="https://www.guanacossj.com">https://www.guanacossj.com</a></p>
<h3 id="Github-Page"><a href="#Github-Page" class="headerlink" title="Github Page"></a>Github Page</h3><p><a href="https://www.guanacossj.com" target="_blank" rel="noopener" title="https://arithmeticjia.github.io/">https://arithmeticjia.github.io/</a></p>
]]></content>
      <categories>
        <category>Welcome</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/11/23/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
